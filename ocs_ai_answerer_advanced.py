#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
OCSè„šæœ¬æ™ºèƒ½ç­”é¢˜API - å¤šæ¨¡å‹æ”¯æŒç‰ˆæœ¬
æ”¯æŒï¼šDeepSeekã€è±†åŒ…(Doubao)ç­‰å¤šä¸ªå¤§è¯­è¨€æ¨¡å‹
æ”¯æŒï¼šæ€è€ƒæ¨¡å¼ã€è‡ªå®šä¹‰é…ç½®
"""

from flask import Flask, request, jsonify, make_response
from flask_cors import CORS
from openai import OpenAI
import os
from typing import List, Dict, Any, Optional, Tuple
import logging
from dotenv import load_dotenv
import re
import time
import csv
from datetime import datetime
import base64
from io import BytesIO
import threading

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# ==================== é…ç½®åŒºåŸŸ ====================

# æ¨¡å‹é…ç½®
MODEL_PROVIDER = os.getenv('MODEL_PROVIDER', 'deepseek')  # deepseek, doubao æˆ– autoï¼ˆæ™ºèƒ½é€‰æ‹©ï¼‰
MODEL_NAME = os.getenv('MODEL_NAME', 'deepseek-chat')     # æ¨¡å‹åç§°

# æ™ºèƒ½æ¨¡å‹é€‰æ‹©é…ç½®
AUTO_MODEL_SELECTION = os.getenv('AUTO_MODEL_SELECTION', 'true').lower() == 'true'  # æ˜¯å¦å¯ç”¨æ™ºèƒ½é€‰æ‹©
PREFER_MODEL = os.getenv('PREFER_MODEL', 'deepseek')  # çº¯æ–‡æœ¬é¢˜ç›®é¦–é€‰æ¨¡å‹
IMAGE_MODEL = os.getenv('IMAGE_MODEL', 'doubao')       # å›¾ç‰‡é¢˜ç›®ä½¿ç”¨çš„æ¨¡å‹

# DeepSeeké…ç½®
DEEPSEEK_API_KEY = os.getenv('DEEPSEEK_API_KEY', '')
DEEPSEEK_BASE_URL = os.getenv('DEEPSEEK_BASE_URL', 'https://api.deepseek.com')
DEEPSEEK_MODEL = os.getenv('DEEPSEEK_MODEL', 'deepseek-chat')  # deepseek-chat æˆ– deepseek-reasoner

# è±†åŒ…é…ç½®
DOUBAO_API_KEY = os.getenv('DOUBAO_API_KEY', '')
DOUBAO_BASE_URL = os.getenv('DOUBAO_BASE_URL', 'https://ark.cn-beijing.volces.com/api/v3')
DOUBAO_MODEL = os.getenv('DOUBAO_MODEL', 'doubao-seed-1-6-251015')

# æ€è€ƒæ¨¡å¼é…ç½®
ENABLE_REASONING = os.getenv('ENABLE_REASONING', 'false').lower() == 'true'
REASONING_EFFORT = os.getenv('REASONING_EFFORT', 'medium')  # low, medium, high
AUTO_REASONING_FOR_MULTIPLE = os.getenv('AUTO_REASONING_FOR_MULTIPLE', 'true').lower() == 'true'
AUTO_REASONING_FOR_IMAGES = os.getenv('AUTO_REASONING_FOR_IMAGES', 'true').lower() == 'true'  # å¸¦å›¾ç‰‡é¢˜ç›®è‡ªåŠ¨å¯ç”¨æ·±åº¦æ€è€ƒ

# AIå‚æ•°é…ç½®
TEMPERATURE = float(os.getenv('TEMPERATURE', '0.1'))

# max_tokens é™åˆ¶:
# - deepseek-chat: [1, 8192] (æœ€å¤§8K)
# - deepseek-reasoner: [1, 65536] (æœ€å¤§64K)
# æ™®é€šæ¨¡å¼çš„ max_tokensï¼ˆé»˜è®¤500ï¼‰
MAX_TOKENS_RAW = int(os.getenv('MAX_TOKENS', '500'))
MAX_TOKENS = max(1, min(8192, MAX_TOKENS_RAW))  # é»˜è®¤é™åˆ¶åˆ°8Kï¼ˆdeepseek-chatçš„é™åˆ¶ï¼‰

# æ€è€ƒæ¨¡å¼çš„ max_tokensï¼ˆé»˜è®¤4096ï¼Œå¯ä»¥æ›´å¤§ä»¥æ”¯æŒå¤æ‚æ¨ç†ï¼‰
REASONING_MAX_TOKENS_RAW = int(os.getenv('REASONING_MAX_TOKENS', '4096'))
REASONING_MAX_TOKENS = max(1, min(65536, REASONING_MAX_TOKENS_RAW))  # é™åˆ¶åˆ°64Kï¼ˆdeepseek-reasonerçš„é™åˆ¶ï¼‰

TOP_P = float(os.getenv('TOP_P', '0.95'))

# ç½‘ç»œé…ç½®
HTTP_PROXY = os.getenv('HTTP_PROXY', '')
HTTPS_PROXY = os.getenv('HTTPS_PROXY', '')
TIMEOUT = float(os.getenv('TIMEOUT', '1200.0'))
MAX_RETRIES = int(os.getenv('MAX_RETRIES', '3'))

# æœåŠ¡é…ç½®
HOST = os.getenv('HOST', '0.0.0.0')
PORT = int(os.getenv('PORT', 5000))
DEBUG = os.getenv('DEBUG', 'False').lower() == 'true'

# ==================== é…ç½®åŒºåŸŸç»“æŸ ====================

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

app = Flask(__name__)
CORS(app)

# CSVæ–‡ä»¶å†™å…¥é”ï¼ˆæ”¯æŒå¹¶å‘ï¼‰
csv_write_lock = threading.Lock()

# é¢˜å‹æ˜ å°„
QUESTION_TYPES = {
    0: "single",
    1: "multiple",
    3: "completion",
    4: "judgement"
}


class ModelClient:
    """ç»Ÿä¸€çš„æ¨¡å‹å®¢æˆ·ç«¯ï¼ˆæ”¯æŒæ™ºèƒ½æ¨¡å‹é€‰æ‹©ï¼‰"""
    
    def __init__(self, provider: str = MODEL_PROVIDER):
        """
        åˆå§‹åŒ–æ¨¡å‹å®¢æˆ·ç«¯
        
        Args:
            provider: æ¨¡å‹æä¾›å•† (deepseek/doubao/auto)
        """
        self.provider = provider.lower()
        self.enable_reasoning = ENABLE_REASONING
        self.reasoning_effort = REASONING_EFFORT
        self.auto_reasoning_for_multiple = AUTO_REASONING_FOR_MULTIPLE
        self.auto_reasoning_for_images = AUTO_REASONING_FOR_IMAGES
        
        # æ™ºèƒ½æ¨¡å¼ç›¸å…³
        self.is_auto_mode = (self.provider == 'auto')
        self.prefer_model = PREFER_MODEL.lower()
        self.image_model = IMAGE_MODEL.lower()
        
        # å­˜å‚¨å¤šä¸ªå®¢æˆ·ç«¯ï¼ˆç”¨äºautoæ¨¡å¼ï¼‰
        self.clients = {}
        self.models = {}
        
        # é…ç½®HTTPå®¢æˆ·ç«¯ï¼ˆä»£ç†ã€è¶…æ—¶ç­‰ï¼‰
        import httpx
        
        # è®¾ç½®è¶…æ—¶
        try:
            timeout = httpx.Timeout(TIMEOUT, connect=10.0)
        except Exception:
            # å…¼å®¹æ—§ç‰ˆæœ¬httpx
            timeout = TIMEOUT
        
        # åˆ›å»ºhttpxå®¢æˆ·ç«¯ï¼ˆæœ€ç®€æ–¹å¼ï¼Œé¿å…ç‰ˆæœ¬å…¼å®¹é—®é¢˜ï¼‰
        if HTTP_PROXY or HTTPS_PROXY:
            # æœ‰ä»£ç†æ—¶é…ç½®ä»£ç†
            proxies = HTTPS_PROXY if HTTPS_PROXY else HTTP_PROXY
            logger.info(f"âœ… å·²é…ç½®ä»£ç†: {proxies}")
            try:
                http_client = httpx.Client(timeout=timeout, proxies=proxies)
            except TypeError:
                # å¦‚æœhttpxç‰ˆæœ¬ä¸æ”¯æŒproxieså‚æ•°ï¼Œä½¿ç”¨ç¯å¢ƒå˜é‡æ–¹å¼
                import os
                if HTTPS_PROXY:
                    os.environ['HTTPS_PROXY'] = HTTPS_PROXY
                if HTTP_PROXY:
                    os.environ['HTTP_PROXY'] = HTTP_PROXY
                http_client = httpx.Client(timeout=timeout)
        else:
            # æ— ä»£ç†æ—¶ç›´æ¥åˆ›å»º
            http_client = httpx.Client(timeout=timeout)
        
        # æ ¹æ®provideråˆå§‹åŒ–å¯¹åº”çš„å®¢æˆ·ç«¯
        if self.provider == 'auto':
            # æ™ºèƒ½æ¨¡å¼ï¼šåˆå§‹åŒ–æ‰€æœ‰å·²é…ç½®çš„å®¢æˆ·ç«¯
            logger.info("ğŸ¤– å¯ç”¨æ™ºèƒ½æ¨¡å‹é€‰æ‹©æ¨¡å¼")
            
            # å°è¯•åˆå§‹åŒ–DeepSeek
            if DEEPSEEK_API_KEY:
                try:
                    self.clients['deepseek'] = OpenAI(
                        api_key=DEEPSEEK_API_KEY,
                        base_url=DEEPSEEK_BASE_URL,
                        http_client=http_client,
                        max_retries=MAX_RETRIES
                    )
                    self.models['deepseek'] = DEEPSEEK_MODEL
                    logger.info("âœ… DeepSeekå®¢æˆ·ç«¯å·²å°±ç»ª")
                except Exception as e:
                    logger.warning(f"âš ï¸  DeepSeekåˆå§‹åŒ–å¤±è´¥: {str(e)}")
            else:
                logger.warning("âš ï¸  DeepSeek APIå¯†é’¥æœªé…ç½®ï¼Œçº¯æ–‡æœ¬é¢˜ç›®å¯èƒ½æ— æ³•ä½¿ç”¨")
            
            # å°è¯•åˆå§‹åŒ–è±†åŒ…
            if DOUBAO_API_KEY and DOUBAO_MODEL:
                try:
                    self.clients['doubao'] = OpenAI(
                        api_key=DOUBAO_API_KEY,
                        base_url=DOUBAO_BASE_URL,
                        http_client=http_client,
                        max_retries=MAX_RETRIES
                    )
                    self.models['doubao'] = DOUBAO_MODEL
                    logger.info("âœ… è±†åŒ…å®¢æˆ·ç«¯å·²å°±ç»ª")
                except Exception as e:
                    logger.warning(f"âš ï¸  è±†åŒ…åˆå§‹åŒ–å¤±è´¥: {str(e)}")
            else:
                logger.warning("âš ï¸  è±†åŒ… APIå¯†é’¥æˆ–æ¨¡å‹IDæœªé…ç½®ï¼Œå›¾ç‰‡é¢˜ç›®å¯èƒ½æ— æ³•ä½¿ç”¨")
            
            if not self.clients:
                raise ValueError("æ™ºèƒ½æ¨¡å¼éœ€è¦è‡³å°‘é…ç½®ä¸€ä¸ªæ¨¡å‹çš„APIå¯†é’¥ï¼ˆDeepSeekæˆ–è±†åŒ…ï¼‰")
            
            # è®¾ç½®é»˜è®¤å®¢æˆ·ç«¯å’Œæ¨¡å‹ï¼ˆç”¨äºæ˜¾ç¤ºï¼‰
            if self.prefer_model in self.clients:
                self.client = self.clients[self.prefer_model]
                self.model = self.models[self.prefer_model]
            else:
                # ä½¿ç”¨ç¬¬ä¸€ä¸ªå¯ç”¨çš„å®¢æˆ·ç«¯
                first_provider = list(self.clients.keys())[0]
                self.client = self.clients[first_provider]
                self.model = self.models[first_provider]
            
            logger.info(f"âœ… æ™ºèƒ½æ¨¡å¼å·²å¯ç”¨ - å·²é…ç½® {len(self.clients)} ä¸ªæ¨¡å‹")
            logger.info(f"   é»˜è®¤é¦–é€‰: {self.prefer_model} (çº¯æ–‡æœ¬)")
            logger.info(f"   å›¾ç‰‡æ¨¡å‹: {self.image_model}")
            
        elif self.provider == 'deepseek':
            if not DEEPSEEK_API_KEY:
                logger.warning("âš ï¸  DeepSeek APIå¯†é’¥æœªé…ç½®")
            
            self.client = OpenAI(
                api_key=DEEPSEEK_API_KEY,
                base_url=DEEPSEEK_BASE_URL,
                http_client=http_client,
                max_retries=MAX_RETRIES
            )
            
            # å¦‚æœå¯ç”¨æ€è€ƒæ¨¡å¼ï¼Œä½¿ç”¨deepseek-reasoner
            if self.enable_reasoning:
                self.model = 'deepseek-reasoner'
                logger.info("âœ… DeepSeekæ€è€ƒæ¨¡å¼å·²å¯ç”¨ï¼ˆæœ€å¤§64K tokensï¼‰")
            else:
                self.model = DEEPSEEK_MODEL
                logger.info("âœ… DeepSeekæ™®é€šæ¨¡å¼ï¼ˆæœ€å¤§8K tokensï¼‰")
            
        elif self.provider == 'doubao':
            if not DOUBAO_API_KEY:
                logger.warning("âš ï¸  è±†åŒ… APIå¯†é’¥æœªé…ç½®")
            
            self.client = OpenAI(
                api_key=DOUBAO_API_KEY,
                base_url=DOUBAO_BASE_URL,
                http_client=http_client,
                max_retries=MAX_RETRIES
            )
            self.model = DOUBAO_MODEL
            
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ¨¡å‹æä¾›å•†: {provider}")
        
        if not self.is_auto_mode:
            logger.info(f"âœ… å·²åˆå§‹åŒ– {self.provider} å®¢æˆ·ç«¯ï¼Œæ¨¡å‹: {self.model}, è¶…æ—¶: {TIMEOUT}ç§’, æœ€å¤§é‡è¯•: {MAX_RETRIES}æ¬¡")
    
    def download_image_as_base64(self, image_url: str) -> Optional[str]:
        """
        ä¸‹è½½å›¾ç‰‡å¹¶è½¬æ¢ä¸ºbase64æ ¼å¼ï¼ˆä½¿ç”¨ä¼ªè£…è¯·æ±‚å¤´ï¼‰
        
        Args:
            image_url: å›¾ç‰‡URL
            
        Returns:
            base64ç¼–ç çš„data URIï¼Œæ ¼å¼: data:image/xxx;base64,xxxxx
            å¦‚æœä¸‹è½½å¤±è´¥è¿”å›None
        """
        try:
            import httpx
            
            # ä¼ªè£…æˆæµè§ˆå™¨çš„è¯·æ±‚å¤´
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                'Referer': 'https://mooc1.chaoxing.com/',
                'Accept': 'image/avif,image/webp,image/apng,image/svg+xml,image/*,*/*;q=0.8',
                'Accept-Encoding': 'gzip, deflate, br',
                'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
                'Connection': 'keep-alive',
                'Sec-Fetch-Dest': 'image',
                'Sec-Fetch-Mode': 'no-cors',
                'Sec-Fetch-Site': 'cross-site',
            }
            
            # åˆ›å»ºHTTPå®¢æˆ·ç«¯ï¼ˆå¸¦è¶…æ—¶ï¼‰
            with httpx.Client(timeout=10.0, follow_redirects=True) as client:
                logger.info(f"ğŸ“¥ ä¸‹è½½å›¾ç‰‡: {image_url}")
                response = client.get(image_url, headers=headers)
                response.raise_for_status()
                
                # è·å–å›¾ç‰‡å†…å®¹
                image_data = response.content
                
                # æ ¹æ®Content-Typeåˆ¤æ–­å›¾ç‰‡ç±»å‹
                content_type = response.headers.get('Content-Type', 'image/jpeg')
                if 'image/' not in content_type:
                    content_type = 'image/jpeg'  # é»˜è®¤JPEG
                
                # è½¬æ¢ä¸ºbase64
                base64_data = base64.b64encode(image_data).decode('utf-8')
                data_uri = f"data:{content_type};base64,{base64_data}"
                
                logger.info(f"âœ… å›¾ç‰‡ä¸‹è½½æˆåŠŸï¼Œå¤§å°: {len(image_data)} bytes")
                return data_uri
                
        except Exception as e:
            logger.error(f"âŒ å›¾ç‰‡ä¸‹è½½å¤±è´¥: {image_url}")
            logger.error(f"   é”™è¯¯: {str(e)}")
            return None
    
    def chat(self, prompt: str, force_reasoning: bool = False, image_urls: List[str] = None) -> Tuple[Optional[str], Optional[str], Optional[Dict[str, int]]]:
        """
        è°ƒç”¨æ¨¡å‹è¿›è¡Œå¯¹è¯ï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼Œæ”¯æŒæ™ºèƒ½æ¨¡å‹é€‰æ‹©ï¼‰
        
        Args:
            prompt: æç¤ºè¯
            force_reasoning: æ˜¯å¦å¼ºåˆ¶å¯ç”¨æ€è€ƒæ¨¡å¼ï¼ˆç”¨äºå¤šé€‰é¢˜ç­‰ï¼‰
            image_urls: å›¾ç‰‡URLåˆ—è¡¨ï¼ˆä»…è±†åŒ…æ”¯æŒï¼‰
        
        Returns:
            (æ¨ç†è¿‡ç¨‹, æœ€ç»ˆç­”æ¡ˆ, tokenä½¿ç”¨é‡) æˆ– (None, ç­”æ¡ˆ, tokenä½¿ç”¨é‡)
            tokenä½¿ç”¨é‡æ ¼å¼: {"prompt_tokens": int, "completion_tokens": int, "total_tokens": int}
        """
        # ç¡®å®šæ˜¯å¦ä½¿ç”¨æ€è€ƒæ¨¡å¼
        use_reasoning = self.enable_reasoning or force_reasoning
        
        # æ™ºèƒ½é€‰æ‹©æ¨¡å‹ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if self.is_auto_mode:
            selected_provider, selected_client, selected_model = self._select_model(image_urls)
            if not selected_client:
                return None, None, None
        else:
            selected_provider = self.provider
            selected_client = self.client
            selected_model = self.model
        
        # æ ¹æ®æ˜¯å¦ä½¿ç”¨æ€è€ƒæ¨¡å¼é€‰æ‹©æ¨¡å‹å’Œmax_tokensé™åˆ¶
        if selected_provider == 'deepseek':
            if use_reasoning and not self.enable_reasoning:
                # ä¸´æ—¶å¯ç”¨æ€è€ƒæ¨¡å¼ï¼Œéœ€è¦åˆ‡æ¢åˆ°reasoneræ¨¡å‹
                actual_model = 'deepseek-reasoner'
                # ä½¿ç”¨æ€è€ƒæ¨¡å¼ä¸“ç”¨çš„ max_tokensï¼ˆæ”¯æŒæ›´å¤§çš„è¾“å‡ºï¼‰
                max_tokens_limit = REASONING_MAX_TOKENS
                logger.debug(f"æ€è€ƒæ¨¡å¼ä½¿ç”¨ max_tokens: {max_tokens_limit}")
            elif self.enable_reasoning:
                # å…¨å±€å¯ç”¨æ€è€ƒæ¨¡å¼
                actual_model = selected_model
                max_tokens_limit = REASONING_MAX_TOKENS
                logger.debug(f"æ€è€ƒæ¨¡å¼ä½¿ç”¨ max_tokens: {max_tokens_limit}")
            else:
                # æ™®é€šæ¨¡å¼
                actual_model = selected_model
                max_tokens_limit = MAX_TOKENS
        else:
            # è±†åŒ…æ¨¡å‹
            actual_model = selected_model
            if use_reasoning:
                # è±†åŒ…çš„æ€è€ƒæ¨¡å¼ä¹Ÿä½¿ç”¨æ›´å¤§çš„ token
                max_tokens_limit = REASONING_MAX_TOKENS
                logger.debug(f"è±†åŒ…æ€è€ƒæ¨¡å¼ä½¿ç”¨ max_tokens: {max_tokens_limit}")
            else:
                max_tokens_limit = MAX_TOKENS
        
        # æ„å»ºæ¶ˆæ¯ï¼ˆæ”¯æŒåŠ¨æ€åˆ‡æ¢ï¼šé¦–æ¬¡å°è¯•ä½¿ç”¨å›¾ç‰‡ï¼Œå¤±è´¥åé™çº§ä¸ºçº¯æ–‡æœ¬ï¼‰
        # æ³¨æ„ï¼šåœ¨æ™ºèƒ½æ¨¡å¼ä¸‹ï¼Œselected_provider å·²ç»ç¡®å®šï¼Œæ‰€ä»¥ç”¨å®ƒåˆ¤æ–­è€Œä¸æ˜¯ self.provider
        use_images = selected_provider == 'doubao' and image_urls
        
        # å¦‚æœéœ€è¦ä½¿ç”¨å›¾ç‰‡ï¼Œå…ˆä¸‹è½½å¹¶è½¬æ¢ä¸ºbase64
        base64_images = []
        if use_images and image_urls:
            logger.info(f"ğŸ”„ å¼€å§‹ä¸‹è½½ {len(image_urls)} å¼ å›¾ç‰‡...")
            for img_url in image_urls:
                base64_data = self.download_image_as_base64(img_url)
                if base64_data:
                    base64_images.append(base64_data)
                else:
                    logger.warning(f"âš ï¸  è·³è¿‡æ— æ³•ä¸‹è½½çš„å›¾ç‰‡: {img_url}")
            
            if not base64_images:
                logger.warning("âš ï¸  æ‰€æœ‰å›¾ç‰‡ä¸‹è½½å¤±è´¥ï¼Œå°†ä½¿ç”¨çº¯æ–‡æœ¬æ¨¡å¼")
                use_images = False
            else:
                logger.info(f"âœ… æˆåŠŸä¸‹è½½ {len(base64_images)}/{len(image_urls)} å¼ å›¾ç‰‡")
        
        # æ„å»ºæ¶ˆæ¯çš„å‡½æ•°
        def build_messages(use_image_urls: bool):
            if use_image_urls and selected_provider == 'doubao' and base64_images:
                # è±†åŒ…æ”¯æŒå›¾æ–‡æ··æ’ï¼ˆå¤šæ¨¡æ€ï¼‰- æ”¯æŒæ–‡æœ¬å’Œå›¾ç‰‡äº¤æ›¿æ’åˆ—
                user_content = []
                
                # å›¾æ–‡æ··æ’ç­–ç•¥:
                # 1. å¦‚æœé¢˜ç›®/é€‰é¡¹ä¸­æœ‰å›¾ç‰‡URL,å°†å®ƒä»¬æŒ‰å‡ºç°é¡ºåºæ’å…¥åˆ°å¯¹åº”ä½ç½®
                # 2. å¦åˆ™,å…ˆæ·»åŠ æ‰€æœ‰å›¾ç‰‡,å†æ·»åŠ æ–‡æœ¬
                
                # åˆ›å»ºå›¾ç‰‡URLåˆ°base64çš„æ˜ å°„
                url_to_base64 = {}
                if image_urls and len(image_urls) == len(base64_images):
                    url_to_base64 = dict(zip(image_urls, base64_images))
                
                # æ£€æŸ¥promptä¸­æ˜¯å¦åŒ…å«å›¾ç‰‡URL(éœ€è¦æ··æ’)
                has_embedded_images = any(url in prompt for url in image_urls) if image_urls else False
                
                if has_embedded_images and url_to_base64:
                    # å›¾æ–‡æ··æ’æ¨¡å¼:å°†promptåˆ†å‰²,åœ¨å›¾ç‰‡URLä½ç½®æ’å…¥å›¾ç‰‡
                    logger.info("ğŸ“ ä½¿ç”¨å›¾æ–‡æ··æ’æ¨¡å¼")
                    
                    # æ„å»ºæ­£åˆ™è¡¨è¾¾å¼åŒ¹é…æ‰€æœ‰å›¾ç‰‡URL
                    import re
                    # è½¬ä¹‰URLä¸­çš„ç‰¹æ®Šå­—ç¬¦å¹¶æ„å»ºpattern
                    url_patterns = [re.escape(url) for url in image_urls]
                    pattern = '|'.join(url_patterns)
                    
                    # åˆ†å‰²æ–‡æœ¬,ä¿ç•™åˆ†éš”ç¬¦(å›¾ç‰‡URL)
                    parts = re.split(f'({pattern})', prompt)
                    
                    for part in parts:
                        part = part.strip()
                        if not part:
                            continue
                        
                        if part in url_to_base64:
                            # è¿™æ˜¯å›¾ç‰‡URL,æ’å…¥å›¾ç‰‡
                            user_content.append({
                                "type": "image_url",
                                "image_url": {"url": url_to_base64[part]}
                            })
                        else:
                            # è¿™æ˜¯æ–‡æœ¬,æ’å…¥æ–‡æœ¬
                            if part:  # ç¡®ä¿ä¸æ˜¯ç©ºå­—ç¬¦ä¸²
                                user_content.append({
                                    "type": "text",
                                    "text": part
                                })
                else:
                    # ä¼ ç»Ÿæ¨¡å¼:å…ˆæ·»åŠ æ‰€æœ‰å›¾ç‰‡,å†æ·»åŠ æ–‡æœ¬
                    logger.info("ğŸ“ ä½¿ç”¨ä¼ ç»Ÿæ¨¡å¼(å…ˆå›¾ç‰‡åæ–‡æœ¬)")
                    for base64_data in base64_images:
                        user_content.append({
                            "type": "image_url",
                            "image_url": {"url": base64_data}
                        })
                    # å†æ·»åŠ æ–‡æœ¬
                    user_content.append({"type": "text", "text": prompt})
                
                return [
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šã€ä¸¥è°¨çš„ç­”é¢˜åŠ©æ‰‹ã€‚ä½ å¿…é¡»æ ¹æ®é¢˜ç›®ã€å›¾ç‰‡å’Œé€‰é¡¹ç»™å‡ºå‡†ç¡®çš„ç­”æ¡ˆï¼Œä¸¥æ ¼æŒ‰ç…§è¦æ±‚çš„æ ¼å¼è¾“å‡ºï¼Œä¸è¦æœ‰ä»»ä½•å¤šä½™çš„å†…å®¹ã€‚"},
                    {"role": "user", "content": user_content}
                ]
            else:
                # çº¯æ–‡æœ¬æ ¼å¼ï¼ˆDeepSeekæˆ–æ— å›¾ç‰‡ï¼‰
                if image_urls and selected_provider == 'deepseek':
                    logger.warning("âš ï¸  DeepSeekä¸æ”¯æŒå›¾ç‰‡è¾“å…¥ï¼Œå·²å¿½ç•¥å›¾ç‰‡")
                return [
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šã€ä¸¥è°¨çš„ç­”é¢˜åŠ©æ‰‹ã€‚ä½ å¿…é¡»æ ¹æ®é¢˜ç›®å’Œé€‰é¡¹ç»™å‡ºå‡†ç¡®çš„ç­”æ¡ˆï¼Œä¸¥æ ¼æŒ‰ç…§è¦æ±‚çš„æ ¼å¼è¾“å‡ºï¼Œä¸è¦æœ‰ä»»ä½•å¤šä½™çš„å†…å®¹ã€‚"},
                    {"role": "user", "content": prompt}
                ]
        
        # æ„å»ºè¯·æ±‚å‚æ•°
        request_params = {
            "model": actual_model,
            "messages": build_messages(use_images),
            "temperature": TEMPERATURE,
            "max_tokens": max_tokens_limit,
            "top_p": TOP_P,
            "stream": False
        }
        
        # è±†åŒ…æ¨¡å‹æ”¯æŒreasoning_effort
        if selected_provider == 'doubao' and use_reasoning:
            request_params["reasoning_effort"] = self.reasoning_effort
        
        reasoning_status = "ï¼ˆæ€è€ƒæ¨¡å¼ï¼‰" if use_reasoning else ""
        image_status = f"ï¼Œ{len(base64_images)}å¼ å›¾ç‰‡(base64)" if use_images and base64_images else ""
        auto_status = "ğŸ¤–æ™ºèƒ½é€‰æ‹©-" if self.is_auto_mode else ""
        logger.info(f"è°ƒç”¨{auto_status}{selected_provider}æ¨¡å‹ - {actual_model}{reasoning_status}{image_status}")
        
        # é‡è¯•æœºåˆ¶
        last_error = None
        retry_without_images = False  # æ ‡è®°æ˜¯å¦åº”è¯¥ä¸ä½¿ç”¨å›¾ç‰‡é‡è¯•
        
        for attempt in range(1, MAX_RETRIES + 1):
            try:
                # å¦‚æœä¹‹å‰æ£€æµ‹åˆ°å›¾ç‰‡URLé—®é¢˜ï¼Œä½¿ç”¨çº¯æ–‡æœ¬æ¨¡å¼
                if retry_without_images:
                    request_params["messages"] = build_messages(False)
                    logger.info("ğŸ”„ ä½¿ç”¨çº¯æ–‡æœ¬æ¨¡å¼é‡è¯•ï¼ˆä¸ä½¿ç”¨å›¾ç‰‡ï¼‰")
                
                # è°ƒç”¨APIï¼ˆä½¿ç”¨é€‰å®šçš„å®¢æˆ·ç«¯ï¼‰
                response = selected_client.chat.completions.create(**request_params)
                
                # æå–æ¨ç†è¿‡ç¨‹å’Œç­”æ¡ˆ
                reasoning_content = None
                if hasattr(response.choices[0].message, 'reasoning_content'):
                    reasoning_content = response.choices[0].message.reasoning_content
                    if reasoning_content:
                        logger.info(f"æ¨ç†è¿‡ç¨‹: {reasoning_content[:100]}...")
                
                answer = response.choices[0].message.content.strip()
                logger.info(f"æ¨¡å‹è¿”å›ç­”æ¡ˆ: {answer}")
                
                # æå–tokenä½¿ç”¨é‡
                usage_info = None
                if hasattr(response, 'usage'):
                    usage_info = {
                        'prompt_tokens': response.usage.prompt_tokens if hasattr(response.usage, 'prompt_tokens') else 0,
                        'completion_tokens': response.usage.completion_tokens if hasattr(response.usage, 'completion_tokens') else 0,
                        'total_tokens': response.usage.total_tokens if hasattr(response.usage, 'total_tokens') else 0
                    }
                    logger.info(f"ğŸ’° Tokenä½¿ç”¨é‡: è¾“å…¥={usage_info['prompt_tokens']}, è¾“å‡º={usage_info['completion_tokens']}, æ€»è®¡={usage_info['total_tokens']}")
                else:
                    logger.warning("âš ï¸  å“åº”ä¸­æ²¡æœ‰usageä¿¡æ¯ï¼Œtokenç”¨é‡å°†è®°å½•ä¸º0")
                    usage_info = {'prompt_tokens': 0, 'completion_tokens': 0, 'total_tokens': 0}
                
                return reasoning_content, answer, usage_info
                
            except Exception as e:
                last_error = e
                error_msg = str(e)
                error_type = type(e).__name__
                
                # è®°å½•è¯¦ç»†é”™è¯¯ä¿¡æ¯
                logger.error(f"APIè°ƒç”¨å¤±è´¥ (å°è¯• {attempt}/{MAX_RETRIES}): {error_type}: {error_msg[:300]}")
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯å‚æ•°é”™è¯¯ï¼ˆ400ï¼‰ï¼Œè¿™ç§é”™è¯¯é‡è¯•ä¹Ÿæ²¡ç”¨
                is_param_error = (
                    "400" in error_msg or 
                    "Invalid" in error_msg or 
                    "invalid_request_error" in error_msg.lower() or
                    "max_tokens" in error_msg.lower()
                )
                
                if is_param_error:
                    logger.error(f"å‚æ•°é”™è¯¯ï¼ˆæ— éœ€é‡è¯•ï¼‰: {error_msg}")
                    print(f"\nâŒ APIå‚æ•°é”™è¯¯: {error_msg[:200]}")
                    if "max_tokens" in error_msg.lower():
                        print("ğŸ’¡ æç¤º: max_tokenså¿…é¡»åœ¨[1, 8192]èŒƒå›´å†…ï¼Œå·²è‡ªåŠ¨é™åˆ¶")
                    return None, None, None
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯å›¾ç‰‡ç›¸å…³çš„é”™è¯¯ï¼ˆå³ä½¿ä½¿ç”¨äº†base64ï¼Œä¹Ÿå¯èƒ½å› ä¸ºå›¾ç‰‡è¿‡å¤§æˆ–æ ¼å¼é—®é¢˜å¤±è´¥ï¼‰
                # å¦‚æœä½¿ç”¨äº†å›¾ç‰‡ä¸”å‡ºç°è¿æ¥/è¶…æ—¶é”™è¯¯ï¼Œä¸”æ˜¯ç¬¬ä¸€æ¬¡å°è¯•ï¼Œå°è¯•ä¸ä½¿ç”¨å›¾ç‰‡é‡è¯•
                is_image_error = (
                    "connection" in error_msg.lower() or
                    "Connection" in error_type or
                    "timeout" in error_msg.lower() or
                    "image" in error_msg.lower() or
                    "base64" in error_msg.lower()
                ) and base64_images  # åªæœ‰åœ¨å®é™…ä½¿ç”¨äº†å›¾ç‰‡æ—¶æ‰è€ƒè™‘æ˜¯å›¾ç‰‡é—®é¢˜
                
                # å¦‚æœæ˜¯å›¾ç‰‡ç›¸å…³é”™è¯¯ï¼Œä¸”æ˜¯ç¬¬ä¸€æ¬¡å°è¯•ï¼Œæ ‡è®°ä¸ºä¸ä½¿ç”¨å›¾ç‰‡é‡è¯•
                if is_image_error and attempt == 1 and selected_provider == 'doubao' and base64_images and not retry_without_images:
                    logger.warning(f"âš ï¸  æ£€æµ‹åˆ°å¯èƒ½çš„å›¾ç‰‡å¤„ç†é—®é¢˜")
                    logger.warning(f"   é”™è¯¯ç±»å‹: {error_type}")
                    logger.warning(f"   å·²å‘é€ {len(base64_images)} å¼ base64å›¾ç‰‡")
                    logger.warning(f"   å¯èƒ½åŸå› : 1) å›¾ç‰‡è¿‡å¤§ 2) å›¾ç‰‡æ ¼å¼ä¸æ”¯æŒ 3) ç½‘ç»œè¿æ¥é—®é¢˜")
                    print(f"\nâš ï¸  æ£€æµ‹åˆ°å›¾ç‰‡å¤„ç†é—®é¢˜ï¼Œå°†å°è¯•ä¸ä½¿ç”¨å›¾ç‰‡é‡è¯•...")
                    print(f"   é”™è¯¯ç±»å‹: {error_type}")
                    print(f"   å›¾ç‰‡æ•°é‡: {len(base64_images)} å¼ ")
                    
                    # æ ‡è®°ä¸ºä¸ä½¿ç”¨å›¾ç‰‡é‡è¯•
                    retry_without_images = True
                    # ç»§ç»­é‡è¯•ï¼Œä½†è¿™æ¬¡ä¸ä½¿ç”¨å›¾ç‰‡
                    continue
                
                # å¦‚æœæ˜¯æœ€åä¸€æ¬¡å°è¯•ï¼Œç›´æ¥è¿”å›å¤±è´¥
                if attempt >= MAX_RETRIES:
                    logger.error(f"æ¨¡å‹è°ƒç”¨å¤±è´¥ (å·²é‡è¯•{MAX_RETRIES}æ¬¡): {error_msg}")
                    print(f"\nâš ï¸  ç½‘ç»œé”™è¯¯ï¼Œå·²é‡è¯• {MAX_RETRIES} æ¬¡")
                    print(f"é”™è¯¯ç±»å‹: {error_type}")
                    print(f"é”™è¯¯ä¿¡æ¯: {error_msg[:200]}")
                    if "Connection" in error_msg or "timeout" in error_msg.lower():
                        print("ğŸ’¡ æç¤º: æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–é…ç½®HTTP_PROXY/HTTPS_PROXYç¯å¢ƒå˜é‡")
                        if image_urls:
                            print("ğŸ’¡ æç¤º: å›¾ç‰‡URLå¯èƒ½æ— æ³•è®¿é—®ï¼Œå·²å°è¯•ä¸ä½¿ç”¨å›¾ç‰‡")
                    return None, None, None
                
                # ç­‰å¾…åé‡è¯•ï¼ˆä»…å¯¹ç½‘ç»œé”™è¯¯ï¼‰
                wait_time = min(2 ** attempt, 10)  # æŒ‡æ•°é€€é¿ï¼Œæœ€å¤š10ç§’
                logger.warning(f"æ¨¡å‹è°ƒç”¨å¤±è´¥ (ç¬¬{attempt}æ¬¡å°è¯•)ï¼Œ{wait_time}ç§’åé‡è¯•: {error_msg[:100]}")
                print(f"âš ï¸  è¯·æ±‚å¤±è´¥ï¼Œ{wait_time}ç§’åé‡è¯• ({attempt}/{MAX_RETRIES})...")
                time.sleep(wait_time)
        
        # ç†è®ºä¸Šä¸ä¼šæ‰§è¡Œåˆ°è¿™é‡Œ
        logger.error(f"æ¨¡å‹è°ƒç”¨å¤±è´¥: {last_error}")
        return None, None, None
    
    def _select_model(self, image_urls: List[str] = None) -> Tuple[str, Optional[Any], Optional[str]]:
        """
        æ™ºèƒ½é€‰æ‹©æ¨¡å‹
        
        Args:
            image_urls: å›¾ç‰‡URLåˆ—è¡¨
        
        Returns:
            (provider, client, model) æˆ– (provider, None, None)
        """
        has_images = image_urls and len(image_urls) > 0
        
        if has_images:
            # æœ‰å›¾ç‰‡ï¼šä¼˜å…ˆä½¿ç”¨è±†åŒ…
            if self.image_model in self.clients:
                logger.info(f"ğŸ’¡ æ™ºèƒ½é€‰æ‹©: æ£€æµ‹åˆ°å›¾ç‰‡ï¼Œä½¿ç”¨ {self.image_model}")
                return self.image_model, self.clients[self.image_model], self.models[self.image_model]
            else:
                # è±†åŒ…æœªé…ç½®ï¼Œå°è¯•é™çº§
                logger.warning(f"âš ï¸  {self.image_model} æœªé…ç½®ï¼Œä½†é¢˜ç›®åŒ…å«å›¾ç‰‡")
                
                # å°è¯•ä½¿ç”¨å·²é…ç½®çš„å…¶ä»–æ¨¡å‹
                if self.clients:
                    fallback_provider = list(self.clients.keys())[0]
                    logger.warning(f"âš ï¸  é™çº§ä½¿ç”¨ {fallback_provider}ï¼ˆè¯¥æ¨¡å‹å¯èƒ½ä¸æ”¯æŒå›¾ç‰‡ï¼‰")
                    print(f"\nâš ï¸  è­¦å‘Š: {self.image_model} æœªé…ç½®ï¼Œé™çº§ä½¿ç”¨ {fallback_provider}")
                    print(f"   è¯¥æ¨¡å‹å¯èƒ½ä¸æ”¯æŒå›¾ç‰‡è¾“å…¥ï¼Œç­”é¢˜å‡†ç¡®ç‡å¯èƒ½é™ä½")
                    print(f"   å»ºè®®é…ç½® {self.image_model.upper()}_API_KEY ä»¥è·å¾—æœ€ä½³æ•ˆæœ\n")
                    return fallback_provider, self.clients[fallback_provider], self.models[fallback_provider]
                else:
                    logger.error("âŒ æ²¡æœ‰å¯ç”¨çš„æ¨¡å‹å®¢æˆ·ç«¯")
                    print("\nâŒ é”™è¯¯: æ²¡æœ‰å¯ç”¨çš„æ¨¡å‹å®¢æˆ·ç«¯")
                    print("   è¯·è‡³å°‘é…ç½®ä¸€ä¸ªæ¨¡å‹çš„APIå¯†é’¥\n")
                    return 'none', None, None
        else:
            # æ— å›¾ç‰‡ï¼šä¼˜å…ˆä½¿ç”¨é¦–é€‰æ¨¡å‹ï¼ˆé€šå¸¸æ˜¯DeepSeekï¼Œæˆæœ¬æ›´ä½ï¼‰
            if self.prefer_model in self.clients:
                logger.info(f"ğŸ’¡ æ™ºèƒ½é€‰æ‹©: çº¯æ–‡æœ¬é¢˜ç›®ï¼Œä½¿ç”¨ {self.prefer_model}ï¼ˆæˆæœ¬æ›´ä½ï¼‰")
                return self.prefer_model, self.clients[self.prefer_model], self.models[self.prefer_model]
            else:
                # é¦–é€‰æ¨¡å‹æœªé…ç½®ï¼Œä½¿ç”¨å…¶ä»–å¯ç”¨æ¨¡å‹
                if self.clients:
                    fallback_provider = list(self.clients.keys())[0]
                    logger.info(f"ğŸ’¡ {self.prefer_model} æœªé…ç½®ï¼Œä½¿ç”¨ {fallback_provider}")
                    return fallback_provider, self.clients[fallback_provider], self.models[fallback_provider]
                else:
                    logger.error("âŒ æ²¡æœ‰å¯ç”¨çš„æ¨¡å‹å®¢æˆ·ç«¯")
                    print("\nâŒ é”™è¯¯: æ²¡æœ‰å¯ç”¨çš„æ¨¡å‹å®¢æˆ·ç«¯")
                    print("   è¯·è‡³å°‘é…ç½®ä¸€ä¸ªæ¨¡å‹çš„APIå¯†é’¥\n")
                    return 'none', None, None


class PromptBuilder:
    """æ™ºèƒ½Promptæ„å»ºå™¨"""
    
    @staticmethod
    def _is_image_url(text: str) -> bool:
        """åˆ¤æ–­æ–‡æœ¬æ˜¯å¦ä¸ºå›¾ç‰‡URL"""
        if not text:
            return False
        text = str(text).strip().lower()
        # æ£€æŸ¥æ˜¯å¦ä»¥httpå¼€å¤´ä¸”åŒ…å«å›¾ç‰‡æ‰©å±•å
        return (text.startswith('http://') or text.startswith('https://')) and \
               any(ext in text for ext in ['.jpg', '.jpeg', '.png', '.gif', '.bmp', '.webp'])
    
    @staticmethod
    def build_prompt(question: str, options: List[str], q_type: str) -> str:
        """æ ¹æ®é¢˜å‹æ„å»ºprompt"""
        
        if q_type == "single":
            return PromptBuilder._build_single_choice_prompt(question, options)
        elif q_type == "multiple":
            return PromptBuilder._build_multiple_choice_prompt(question, options)
        elif q_type == "judgement":
            return PromptBuilder._build_judgement_prompt(question, options)
        elif q_type == "completion":
            return PromptBuilder._build_completion_prompt(question)
        else:
            return PromptBuilder._build_default_prompt(question, options)
    
    @staticmethod
    def _build_single_choice_prompt(question: str, options: List[str]) -> str:
        """æ„å»ºå•é€‰é¢˜prompt"""
        # æ£€æŸ¥é€‰é¡¹ä¸­æ˜¯å¦æœ‰å›¾ç‰‡URL
        has_image_options = any(PromptBuilder._is_image_url(opt) for opt in options)
        
        options_text = "\n".join([f"{chr(65+i)}. {opt}" for i, opt in enumerate(options)])
        
        base_prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„åœ¨çº¿è€ƒè¯•ç­”é¢˜åŠ©æ‰‹ï¼Œè¯·ä¸¥æ ¼æŒ‰ç…§è¦æ±‚å›ç­”ã€‚

ã€é¢˜ç›®ç±»å‹ã€‘å•é€‰é¢˜ï¼ˆåªèƒ½é€‰æ‹©ä¸€ä¸ªæ­£ç¡®ç­”æ¡ˆï¼‰

ã€é¢˜ç›®ã€‘
{question}

ã€é€‰é¡¹ã€‘
{options_text}

ã€å›ç­”è¦æ±‚ã€‘
1. ä»”ç»†åˆ†æé¢˜ç›®å’Œæ‰€æœ‰é€‰é¡¹
2. åªé€‰æ‹©ä¸€ä¸ªæœ€æ­£ç¡®çš„ç­”æ¡ˆ
3. å¿…é¡»ä»ç»™å®šçš„é€‰é¡¹ä¸­é€‰æ‹©ï¼Œä¸èƒ½è‡ªå·±ç¼–é€ 
4. å›ç­”æ ¼å¼ï¼šç›´æ¥è¾“å‡ºé€‰é¡¹çš„å®Œæ•´åŸå§‹å†…å®¹ï¼Œä¸è¦åŒ…å«Aã€Bã€Cç­‰æ ‡è¯†ç¬¦
5. åªè¾“å‡ºç­”æ¡ˆçš„åŸå§‹å†…å®¹ï¼Œä¸è¦æœ‰ä»»ä½•è§£é‡Šã€åˆ†ææˆ–é¢å¤–æ–‡å­—"""
        
        if has_image_options:
            base_prompt += """
6. **å¦‚æœé€‰é¡¹æ˜¯å›¾ç‰‡URLï¼ˆhttp://æˆ–https://å¼€å¤´ï¼‰ï¼Œå¿…é¡»åŸæ ·è¾“å‡ºå®Œæ•´çš„URLåœ°å€**
7. **ä¸è¦å°è¯•æè¿°å›¾ç‰‡å†…å®¹ï¼Œç›´æ¥è¾“å‡ºURLå­—ç¬¦ä¸²**"""
        
        base_prompt += """

ã€ç¤ºä¾‹ã€‘
å¦‚æœæ­£ç¡®ç­”æ¡ˆæ˜¯é€‰é¡¹"åŒ—äº¬"ï¼Œåˆ™åªè¾“å‡ºï¼šåŒ—äº¬"""
        
        if has_image_options:
            base_prompt += """
å¦‚æœæ­£ç¡®ç­”æ¡ˆæ˜¯å›¾ç‰‡é€‰é¡¹"https://example.com/image.jpg"ï¼Œåˆ™åªè¾“å‡ºï¼šhttps://example.com/image.jpg"""
        
        base_prompt += """

ç°åœ¨è¯·å›ç­”ä¸Šè¿°é¢˜ç›®ï¼š"""
        
        return base_prompt

    @staticmethod
    def _build_multiple_choice_prompt(question: str, options: List[str]) -> str:
        """æ„å»ºå¤šé€‰é¢˜prompt"""
        # æ£€æŸ¥é€‰é¡¹ä¸­æ˜¯å¦æœ‰å›¾ç‰‡URL
        has_image_options = any(PromptBuilder._is_image_url(opt) for opt in options)
        
        options_text = "\n".join([f"{chr(65+i)}. {opt}" for i, opt in enumerate(options)])
        
        # åŸºç¡€è¯´æ˜
        base_instruction = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„åœ¨çº¿è€ƒè¯•ç­”é¢˜åŠ©æ‰‹ï¼Œè¯·ä¸¥æ ¼æŒ‰ç…§è¦æ±‚å›ç­”ã€‚

ã€é¢˜ç›®ç±»å‹ã€‘å¤šé€‰é¢˜ï¼ˆå¯èƒ½æœ‰å¤šä¸ªæ­£ç¡®ç­”æ¡ˆï¼‰

ã€é¢˜ç›®ã€‘
{question}

ã€é€‰é¡¹ã€‘
{options_text}

ã€å›ç­”è¦æ±‚ - éå¸¸é‡è¦ã€‘
1. ä»”ç»†åˆ†æé¢˜ç›®ï¼Œæ‰¾å‡ºæ‰€æœ‰æ­£ç¡®çš„é€‰é¡¹
2. å¤šé€‰é¢˜é€šå¸¸æœ‰2ä¸ªæˆ–ä»¥ä¸Šçš„æ­£ç¡®ç­”æ¡ˆ
3. **å¿…é¡»è¾“å‡ºé€‰é¡¹çš„å®Œæ•´åŸå§‹å†…å®¹ï¼Œä¸è¦è¾“å‡ºAã€Bã€Cã€Dç­‰å­—æ¯æ ‡è¯†**
4. å¤šä¸ªç­”æ¡ˆä¹‹é—´ç”¨äº•å·#åˆ†éš”
5. æŒ‰ç…§é€‰é¡¹é¡ºåºè¾“å‡ºï¼ˆå³Açš„å†…å®¹åœ¨å‰ï¼ŒBçš„å†…å®¹åœ¨åï¼Œä»¥æ­¤ç±»æ¨ï¼‰
6. **åªè¾“å‡ºé€‰é¡¹çš„åŸå§‹å†…å®¹ï¼Œä¸è¦æœ‰ä»»ä½•è§£é‡Šã€åˆ†æã€å­—æ¯æ ‡è¯†æˆ–é¢å¤–æ–‡å­—**
7. ç¡®ä¿å®Œæ•´å‡†ç¡®åœ°å¤åˆ¶é€‰é¡¹åŸå§‹å†…å®¹ï¼ŒåŒ…æ‹¬å›¾ç‰‡URLï¼Œä¸è¦é—æ¼æˆ–ä¿®æ”¹ä»»ä½•å­—ç¬¦"""
        
        # å¦‚æœæœ‰å›¾ç‰‡é€‰é¡¹ï¼Œæ·»åŠ ç‰¹æ®Šè¯´æ˜
        if has_image_options:
            image_instruction = """

ã€âš ï¸ ç‰¹åˆ«æ³¨æ„ - å›¾ç‰‡é€‰é¡¹å¤„ç†ã€‘
8. **é€‰é¡¹ä¸­åŒ…å«å›¾ç‰‡URLï¼ˆhttp://æˆ–https://å¼€å¤´ï¼Œä»¥.jpg/.png/.gifç­‰ç»“å°¾ï¼‰**
9. **å¦‚æœé€‰é¡¹æ˜¯å›¾ç‰‡URLï¼Œå¿…é¡»åŸæ ·è¾“å‡ºå®Œæ•´çš„URLåœ°å€**
10. **ä¸è¦å°è¯•æè¿°å›¾ç‰‡å†…å®¹ï¼Œç›´æ¥è¾“å‡ºURLå­—ç¬¦ä¸²**
11. å›¾ç‰‡å·²ç»åœ¨ä¸Šä¸‹æ–‡ä¸­æä¾›ï¼Œä½ èƒ½çœ‹åˆ°å›¾ç‰‡å†…å®¹ï¼Œæ ¹æ®å›¾ç‰‡å†…å®¹åˆ¤æ–­æ˜¯å¦æ­£ç¡®"""
            base_instruction += image_instruction
        
        # æ·»åŠ ç¤ºä¾‹
        examples = """

ã€è¾“å‡ºæ ¼å¼ç¤ºä¾‹ã€‘
ç¤ºä¾‹1 - æ–‡æœ¬é€‰é¡¹ï¼š
å¦‚æœAå’ŒCé€‰é¡¹æ­£ç¡®ï¼ŒAé€‰é¡¹å†…å®¹æ˜¯"åŒ—äº¬æ˜¯ä¸­å›½çš„é¦–éƒ½"ï¼ŒCé€‰é¡¹å†…å®¹æ˜¯"ä¸Šæµ·æ˜¯ä¸­å›½æœ€å¤§çš„åŸå¸‚"ï¼š
é”™è¯¯è¾“å‡ºï¼šA#C
é”™è¯¯è¾“å‡ºï¼šåŒ—äº¬#ä¸Šæµ·
æ­£ç¡®è¾“å‡ºï¼šåŒ—äº¬æ˜¯ä¸­å›½çš„é¦–éƒ½#ä¸Šæµ·æ˜¯ä¸­å›½æœ€å¤§çš„åŸå¸‚"""
        
        if has_image_options:
            examples += """

ç¤ºä¾‹2 - å›¾ç‰‡é€‰é¡¹ï¼š
å¦‚æœé€‰é¡¹Aæ˜¯æ–‡æœ¬"æ­£ç¡®ç­”æ¡ˆ"ï¼Œé€‰é¡¹Bæ˜¯å›¾ç‰‡URL "https://example.com/image.jpg"ï¼Œé€‰é¡¹Cæ˜¯æ–‡æœ¬"å¦ä¸€ä¸ªç­”æ¡ˆ"ï¼Œä¸”Aã€Bã€Céƒ½æ­£ç¡®ï¼š
é”™è¯¯è¾“å‡ºï¼šA#B#C
é”™è¯¯è¾“å‡ºï¼šæ­£ç¡®ç­”æ¡ˆ#å›¾ç‰‡#å¦ä¸€ä¸ªç­”æ¡ˆ
æ­£ç¡®è¾“å‡ºï¼šæ­£ç¡®ç­”æ¡ˆ#https://example.com/image.jpg#å¦ä¸€ä¸ªç­”æ¡ˆ"""
        
        examples += """

ç°åœ¨è¯·å›ç­”ä¸Šè¿°é¢˜ç›®ï¼Œè®°ä½ï¼šåªè¾“å‡ºé€‰é¡¹çš„å®Œæ•´åŸå§‹å†…å®¹ï¼ˆæ–‡æœ¬æˆ–URLï¼‰ï¼Œç”¨#åˆ†éš”ï¼Œä¸è¦æœ‰ä»»ä½•å…¶ä»–å†…å®¹ï¼š"""
        
        return base_instruction + examples

    @staticmethod
    def _build_judgement_prompt(question: str, options: List[str]) -> str:
        """æ„å»ºåˆ¤æ–­é¢˜prompt"""
        return f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„åœ¨çº¿è€ƒè¯•ç­”é¢˜åŠ©æ‰‹ï¼Œè¯·ä¸¥æ ¼æŒ‰ç…§è¦æ±‚å›ç­”ã€‚

ã€é¢˜ç›®ç±»å‹ã€‘åˆ¤æ–­é¢˜ï¼ˆåˆ¤æ–­å¯¹é”™/æ˜¯å¦ï¼‰

ã€é¢˜ç›®ã€‘
{question}

ã€å¯é€‰ç­”æ¡ˆã€‘
{chr(10).join(options) if options else "æ­£ç¡® / é”™è¯¯"}

ã€å›ç­”è¦æ±‚ã€‘
1. ä»”ç»†åˆ†æé¢˜ç›®é™ˆè¿°æ˜¯å¦æ­£ç¡®
2. å¿…é¡»ä»ç»™å®šçš„é€‰é¡¹ä¸­é€‰æ‹©ï¼ˆå¦‚ï¼šæ­£ç¡®/é”™è¯¯ã€å¯¹/é”™ã€æ˜¯/å¦ã€âˆš/Ã—ç­‰ï¼‰
3. åªè¾“å‡ºä¸€ä¸ªåˆ¤æ–­ç»“æœ
4. ä¸è¦æœ‰ä»»ä½•è§£é‡Šã€åˆ†ææˆ–é¢å¤–æ–‡å­—

ã€ç¤ºä¾‹ã€‘
å¦‚æœé¢˜ç›®é™ˆè¿°æ­£ç¡®ï¼Œä¸”é€‰é¡¹ä¸­æœ‰"æ­£ç¡®"ï¼Œåˆ™è¾“å‡ºï¼šæ­£ç¡®

ç°åœ¨è¯·åˆ¤æ–­ä¸Šè¿°é¢˜ç›®ï¼š"""

    @staticmethod
    def _build_completion_prompt(question: str) -> str:
        """æ„å»ºå¡«ç©ºé¢˜prompt"""
        return f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„åœ¨çº¿è€ƒè¯•ç­”é¢˜åŠ©æ‰‹ï¼Œè¯·ä¸¥æ ¼æŒ‰ç…§è¦æ±‚å›ç­”ã€‚

ã€é¢˜ç›®ç±»å‹ã€‘å¡«ç©ºé¢˜

ã€é¢˜ç›®ã€‘
{question}

ã€å›ç­”è¦æ±‚ã€‘
1. ä»”ç»†ç†è§£é¢˜ç›®è¦æ±‚
2. ç»™å‡ºå‡†ç¡®ã€ç®€æ´çš„ç­”æ¡ˆ
3. å¦‚æœæœ‰å¤šä¸ªç©ºï¼Œç­”æ¡ˆä¹‹é—´ç”¨äº•å·#åˆ†éš”
4. ç­”æ¡ˆè¦å…·ä½“ã€å‡†ç¡®ï¼Œé¿å…æ¨¡ç³Šè¡¨è¿°
5. åªè¾“å‡ºç­”æ¡ˆå†…å®¹ï¼Œä¸è¦æœ‰åºå·ã€è§£é‡Šæˆ–é¢å¤–æ–‡å­—

ã€ç¤ºä¾‹ã€‘
- å•ç©ºé¢˜ï¼šå¦‚æœç­”æ¡ˆæ˜¯"åŒ—äº¬"ï¼Œåˆ™è¾“å‡ºï¼šåŒ—äº¬
- å¤šç©ºé¢˜ï¼šå¦‚æœç­”æ¡ˆæ˜¯"æ°¢"å’Œ"æ°§"ï¼Œåˆ™è¾“å‡ºï¼šæ°¢#æ°§

ç°åœ¨è¯·å›ç­”ä¸Šè¿°å¡«ç©ºé¢˜ï¼š"""

    @staticmethod
    def _build_default_prompt(question: str, options: List[str]) -> str:
        """æ„å»ºé»˜è®¤prompt"""
        options_text = "\n".join([f"- {opt}" for opt in options]) if options else "æ— å›ºå®šé€‰é¡¹"
        
        return f"""è¯·å›ç­”ä»¥ä¸‹é—®é¢˜ï¼š

ã€é¢˜ç›®ã€‘
{question}

ã€é€‰é¡¹ã€‘
{options_text}

ã€è¦æ±‚ã€‘
1. ç»™å‡ºå‡†ç¡®çš„ç­”æ¡ˆ
2. å¦‚æœæœ‰å¤šä¸ªç­”æ¡ˆï¼Œç”¨#åˆ†éš”
3. åªè¾“å‡ºç­”æ¡ˆï¼Œä¸è¦è§£é‡Š

è¯·å›ç­”ï¼š"""


class AnswerProcessor:
    """ç­”æ¡ˆå¤„ç†å™¨ - ä¿å®ˆæ¸…æ´—ï¼Œä¼˜å…ˆåŒ¹é…åŸå§‹ç­”æ¡ˆ"""
    
    @staticmethod
    def _clean_answer(text: str) -> str:
        """
        è½»åº¦æ¸…æ´—ï¼Œåªç§»é™¤æ˜æ˜¾çš„æ ¼å¼æ ‡è®°
        ä¸è¿›è¡Œå†…å®¹ä¿®æ”¹ï¼Œé¿å…è¯¯åˆ æ­£ç¡®ç­”æ¡ˆ
        """
        if not text:
            return ""
        
        # åªç§»é™¤è¡Œé¦–çš„å¸¸è§å‰ç¼€ï¼ˆä¸å½±å“ç­”æ¡ˆå†…å®¹ï¼‰
        text = re.sub(r'^(ç­”æ¡ˆ[æ˜¯ä¸ºï¼š:]*|æ­£ç¡®ç­”æ¡ˆ[æ˜¯ä¸ºï¼š:]*|é€‰æ‹©[ï¼š:]*)', '', text)
        text = text.strip()
        
        # åªç§»é™¤markdownçš„æ ¼å¼ç¬¦å·ï¼ˆä¸æ˜¯å†…å®¹ï¼‰
        text = re.sub(r'[*`_]', '', text)
        text = text.strip()
        
        # åªç§»é™¤è¡Œé¦–çš„é€‰é¡¹æ ‡è¯†ï¼ˆå¦‚ "A. "ï¼‰ï¼Œä½†ä¸å½±å“ç­”æ¡ˆæœ¬èº«
        text = re.sub(r'^[A-Z][.ã€)]\s*', '', text)
        text = text.strip()
        
        return text
    
    @staticmethod
    def _match_option(answer: str, option: str) -> bool:
        """
        æ™ºèƒ½åŒ¹é…ç­”æ¡ˆå’Œé€‰é¡¹
        ä¼˜å…ˆç²¾ç¡®åŒ¹é…ï¼Œå†æ¨¡ç³ŠåŒ¹é…
        """
        answer = answer.strip()
        option = option.strip()
        
        if not answer or not option:
            return False
        
        # ç²¾ç¡®åŒ¹é…ï¼ˆå¿½ç•¥å¤§å°å†™å’Œç©ºæ ¼ï¼‰
        if answer.lower() == option.lower():
            return True
        
        # åŒ…å«åŒ¹é…
        if answer.lower() in option.lower() or option.lower() in answer.lower():
            return True
        
        # å»é™¤æ ‡ç‚¹ç¬¦å·ååŒ¹é…
        answer_clean = re.sub(r'[ã€‚ï¼Œã€ï¼›ï¼šï¼ï¼Ÿ\s]', '', answer)
        option_clean = re.sub(r'[ã€‚ï¼Œã€ï¼›ï¼šï¼ï¼Ÿ\s]', '', option)
        if answer_clean.lower() == option_clean.lower():
            return True
        
        return False
    
    @staticmethod
    def process_answer(raw_answer: str, q_type: str, options: List[str]) -> str:
        """
        å¤„ç†å’Œæ¸…æ´—ç­”æ¡ˆ - ä¿å®ˆç­–ç•¥ï¼Œä¼˜å…ˆä¿ç•™åŸå§‹ç­”æ¡ˆ
        """
        if not raw_answer:
            return ""
        
        raw_answer = raw_answer.strip()
        
        # æ ¹æ®é¢˜å‹å¤„ç†
        if q_type == "single":
            return AnswerProcessor._process_single_choice(raw_answer, options)
        elif q_type == "multiple":
            return AnswerProcessor._process_multiple_choice(raw_answer, options)
        elif q_type == "judgement":
            return AnswerProcessor._process_judgement(raw_answer, options)
        elif q_type == "completion":
            # å¡«ç©ºé¢˜åªåšè½»åº¦æ¸…æ´—ï¼Œä¿ç•™åŸå§‹ç­”æ¡ˆ
            cleaned = AnswerProcessor._clean_answer(raw_answer)
            return cleaned if cleaned else raw_answer
        else:
            # å…¶ä»–é¢˜å‹åªåšè½»åº¦æ¸…æ´—
            cleaned = AnswerProcessor._clean_answer(raw_answer)
            return cleaned if cleaned else raw_answer
    
    @staticmethod
    def _process_single_choice(raw_answer: str, options: List[str]) -> str:
        """å¤„ç†å•é€‰é¢˜ç­”æ¡ˆ - ä¼˜å…ˆä½¿ç”¨åŸå§‹ç­”æ¡ˆåŒ¹é…"""
        if not options:
            # æ²¡æœ‰é€‰é¡¹ï¼Œåªåšè½»åº¦æ¸…æ´—
            return AnswerProcessor._clean_answer(raw_answer)
        
        # ç¬¬ä¸€æ­¥ï¼šå°è¯•ç”¨åŸå§‹ç­”æ¡ˆç›´æ¥åŒ¹é…
        for option in options:
            if AnswerProcessor._match_option(raw_answer, option):
                return option.strip()
        
        # ç¬¬äºŒæ­¥ï¼šè½»åº¦æ¸…æ´—åå†åŒ¹é…
        cleaned = AnswerProcessor._clean_answer(raw_answer)
        if cleaned != raw_answer:  # å¦‚æœæ¸…æ´—æœ‰å˜åŒ–
            for option in options:
                if AnswerProcessor._match_option(cleaned, option):
                    return option.strip()
        
        # ç¬¬ä¸‰æ­¥ï¼šå¦‚æœè¿˜æ˜¯åŒ¹é…ä¸åˆ°ï¼Œè¿”å›æ¸…æ´—åçš„ç­”æ¡ˆ
        # è¿™æ ·è‡³å°‘ä¿ç•™äº†å¯èƒ½çš„æ­£ç¡®ç­”æ¡ˆï¼Œè€Œä¸æ˜¯ç©ºå­—ç¬¦ä¸²
        return cleaned if cleaned else raw_answer
    
    @staticmethod
    def _process_multiple_choice(raw_answer: str, options: List[str]) -> str:
        """å¤„ç†å¤šé€‰é¢˜ç­”æ¡ˆ - ä¼˜å…ˆä½¿ç”¨åŸå§‹ç­”æ¡ˆåŒ¹é…"""
        if not options:
            return AnswerProcessor._clean_answer(raw_answer)
        
        # åˆ†å‰²ç­”æ¡ˆï¼ˆæ”¯æŒå¤šç§åˆ†éš”ç¬¦ï¼‰
        raw_answers = re.split(r'[#;ï¼›ã€\n]', raw_answer)
        matched_options = []
        
        # ç¬¬ä¸€æ­¥ï¼šç”¨åŸå§‹ç­”æ¡ˆåŒ¹é…
        for raw_ans in raw_answers:
            raw_ans = raw_ans.strip()
            if not raw_ans:
                continue
            
            for option in options:
                if AnswerProcessor._match_option(raw_ans, option):
                    option_clean = option.strip()
                    if option_clean not in matched_options:
                        matched_options.append(option_clean)
                    break
        
        # ç¬¬äºŒæ­¥ï¼šå¦‚æœåŒ¹é…åˆ°äº†ï¼Œç›´æ¥è¿”å›
        if matched_options:
            return "#".join(matched_options)
        
        # ç¬¬ä¸‰æ­¥ï¼šå°è¯•æ¸…æ´—åå†åŒ¹é…
        cleaned_answers = [AnswerProcessor._clean_answer(ans) for ans in raw_answers if ans.strip()]
        for cleaned_ans in cleaned_answers:
            for option in options:
                if AnswerProcessor._match_option(cleaned_ans, option):
                    option_clean = option.strip()
                    if option_clean not in matched_options:
                        matched_options.append(option_clean)
                    break
        
        # ç¬¬å››æ­¥ï¼šè¿”å›åŒ¹é…ç»“æœæˆ–æ¸…æ´—åçš„åŸå§‹ç­”æ¡ˆ
        if matched_options:
            return "#".join(matched_options)
        else:
            # å¦‚æœåŒ¹é…ä¸åˆ°ï¼Œè¿”å›æ¸…æ´—åçš„ç­”æ¡ˆï¼ˆä¿ç•™å¯èƒ½çš„æ­£ç¡®ç­”æ¡ˆï¼‰
            cleaned = AnswerProcessor._clean_answer(raw_answer)
            return cleaned if cleaned else raw_answer
    
    @staticmethod
    def _process_judgement(raw_answer: str, options: List[str]) -> str:
        """å¤„ç†åˆ¤æ–­é¢˜ç­”æ¡ˆ - ä¿å®ˆç­–ç•¥"""
        if not options:
            return AnswerProcessor._clean_answer(raw_answer)
        
        raw_answer_lower = raw_answer.lower()
        
        # ç¬¬ä¸€æ­¥ï¼šç›´æ¥åŒ¹é…é€‰é¡¹
        for option in options:
            if AnswerProcessor._match_option(raw_answer, option):
                return option.strip()
        
        # ç¬¬äºŒæ­¥ï¼šæ¸…æ´—ååŒ¹é…
        cleaned = AnswerProcessor._clean_answer(raw_answer)
        if cleaned != raw_answer:
            for option in options:
                if AnswerProcessor._match_option(cleaned, option):
                    return option.strip()
        
        # ç¬¬ä¸‰æ­¥ï¼šè¯­ä¹‰åŒ¹é…ï¼ˆä¿å®ˆï¼‰
        # åªåœ¨ä¸åŒ¹é…çš„æƒ…å†µä¸‹æ‰è¿›è¡Œè¯­ä¹‰åˆ¤æ–­
        cleaned_lower = cleaned.lower()
        
        # åˆ¤æ–­"æ­£ç¡®"å€¾å‘
        positive_words = ['æ­£ç¡®', 'å¯¹', 'true', 'âˆš', 'æ˜¯', 'yes', 'æˆç«‹']
        negative_words = ['é”™è¯¯', 'é”™', 'false', 'Ã—', 'å¦', 'no', 'ä¸æˆç«‹']
        
        has_positive = any(word in cleaned_lower for word in positive_words)
        has_negative = any(word in cleaned_lower for word in negative_words)
        
        # åªåœ¨æ˜ç¡®æœ‰å€¾å‘ä¸”æ²¡æœ‰åŒ¹é…åˆ°é€‰é¡¹æ—¶æ‰ä½¿ç”¨
        if has_positive and not has_negative:
            for opt in options:
                opt_lower = opt.lower()
                if any(word in opt_lower for word in positive_words):
                    return opt.strip()
            # å¦‚æœé€‰é¡¹ä¸­æ²¡æœ‰æ˜ç¡®çš„æ­£å‘è¯ï¼Œè¿”å›ç¬¬ä¸€ä¸ªé€‰é¡¹ï¼ˆé€šå¸¸åˆ¤æ–­é¢˜ç¬¬ä¸€ä¸ªæ˜¯"æ­£ç¡®"ï¼‰
            return options[0].strip() if len(options) > 0 else cleaned
        
        if has_negative and not has_positive:
            for opt in options:
                opt_lower = opt.lower()
                if any(word in opt_lower for word in negative_words):
                    return opt.strip()
            # å¦‚æœé€‰é¡¹ä¸­æ²¡æœ‰æ˜ç¡®çš„è´Ÿå‘è¯ï¼Œè¿”å›ç¬¬äºŒä¸ªé€‰é¡¹ï¼ˆé€šå¸¸åˆ¤æ–­é¢˜ç¬¬äºŒä¸ªæ˜¯"é”™è¯¯"ï¼‰
            return options[1].strip() if len(options) > 1 else cleaned
        
        # æ— æ³•åˆ¤æ–­ï¼Œè¿”å›æ¸…æ´—åçš„åŸå§‹ç­”æ¡ˆ
        return cleaned if cleaned else raw_answer


# åˆ›å»ºå…¨å±€æ¨¡å‹å®¢æˆ·ç«¯
model_client = None
init_error = None

try:
    # æ£€æŸ¥å¿…éœ€çš„é…ç½®
    if MODEL_PROVIDER == 'auto':
        # æ™ºèƒ½æ¨¡å¼ï¼šéœ€è¦è‡³å°‘é…ç½®ä¸€ä¸ªæ¨¡å‹
        if not DEEPSEEK_API_KEY and not DOUBAO_API_KEY:
            init_error = "æ™ºèƒ½æ¨¡å¼éœ€è¦è‡³å°‘é…ç½®ä¸€ä¸ªæ¨¡å‹çš„APIå¯†é’¥ï¼ˆDEEPSEEK_API_KEY æˆ– DOUBAO_API_KEYï¼‰"
            logger.error(init_error)
        else:
            model_client = ModelClient(MODEL_PROVIDER)
            logger.info(f"âœ… æ™ºèƒ½æ¨¡å‹é€‰æ‹©å·²å¯ç”¨ - å·²é…ç½® {len(model_client.clients)} ä¸ªæ¨¡å‹")
    elif MODEL_PROVIDER == 'deepseek':
        if not DEEPSEEK_API_KEY:
            init_error = "DeepSeek APIå¯†é’¥æœªé…ç½®ï¼Œè¯·åœ¨.envæ–‡ä»¶ä¸­è®¾ç½® DEEPSEEK_API_KEY"
            logger.error(init_error)
        else:
            model_client = ModelClient(MODEL_PROVIDER)
            logger.info(f"âœ… æ¨¡å‹å®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ: {MODEL_PROVIDER} - {model_client.model}")
    elif MODEL_PROVIDER == 'doubao':
        if not DOUBAO_API_KEY:
            init_error = "è±†åŒ… APIå¯†é’¥æœªé…ç½®ï¼Œè¯·åœ¨.envæ–‡ä»¶ä¸­è®¾ç½® DOUBAO_API_KEY"
            logger.error(init_error)
        elif not DOUBAO_MODEL:
            init_error = "è±†åŒ… æ¨¡å‹IDæœªé…ç½®ï¼Œè¯·åœ¨.envæ–‡ä»¶ä¸­è®¾ç½® DOUBAO_MODEL"
            logger.error(init_error)
        else:
            model_client = ModelClient(MODEL_PROVIDER)
            logger.info(f"âœ… æ¨¡å‹å®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ: {MODEL_PROVIDER} - {model_client.model}")
    else:
        init_error = f"ä¸æ”¯æŒçš„æ¨¡å‹æä¾›å•†: {MODEL_PROVIDER}ï¼ˆæ”¯æŒ: deepseek, doubao, autoï¼‰"
        logger.error(init_error)
except Exception as e:
    init_error = f"åˆå§‹åŒ–æ¨¡å‹å®¢æˆ·ç«¯å¤±è´¥: {str(e)}"
    logger.error(init_error, exc_info=True)
    model_client = None


def format_time(seconds: float) -> str:
    """æ ¼å¼åŒ–æ—¶é—´æ˜¾ç¤º"""
    if seconds < 60:
        return f"{seconds:.1f}ç§’"
    else:
        minutes = int(seconds // 60)
        secs = seconds % 60
        return f"{minutes}åˆ†{secs:.1f}ç§’"


def check_and_fix_csv_header(csv_file: str, correct_headers: List[str]) -> bool:
    """
    æ£€æŸ¥å¹¶ä¿®å¤CSVæ–‡ä»¶è¡¨å¤´
    
    Args:
        csv_file: CSVæ–‡ä»¶è·¯å¾„
        correct_headers: æ­£ç¡®çš„è¡¨å¤´åˆ—è¡¨
    
    Returns:
        Trueè¡¨ç¤ºè¡¨å¤´æ­£ç¡®æˆ–å·²ä¿®å¤ï¼ŒFalseè¡¨ç¤ºä¿®å¤å¤±è´¥
    """
    if not os.path.exists(csv_file):
        # æ–‡ä»¶ä¸å­˜åœ¨ï¼Œæ— éœ€ä¿®å¤
        return True
    
    try:
        # è¯»å–å½“å‰è¡¨å¤´
        with open(csv_file, 'r', encoding='utf-8-sig') as f:
            reader = csv.reader(f)
            current_headers = next(reader, None)
            if current_headers is None:
                # ç©ºæ–‡ä»¶ï¼Œæ— éœ€ä¿®å¤
                return True
            
            # æ£€æŸ¥è¡¨å¤´æ˜¯å¦æ­£ç¡®
            if current_headers == correct_headers:
                # è¡¨å¤´æ­£ç¡®ï¼Œæ— éœ€ä¿®å¤
                return True
            
            # è¡¨å¤´ä¸æ­£ç¡®ï¼Œéœ€è¦ä¿®å¤
            logger.warning(f"âš ï¸  CSVæ–‡ä»¶è¡¨å¤´ä¸æ­£ç¡®ï¼Œå½“å‰åˆ—æ•°: {len(current_headers)}, æ­£ç¡®åˆ—æ•°: {len(correct_headers)}")
            logger.info("ğŸ”§ å¼€å§‹è‡ªåŠ¨ä¿®å¤CSVæ–‡ä»¶è¡¨å¤´...")
            
            # è¯»å–æ‰€æœ‰æ•°æ®
            f.seek(0)
            reader = csv.reader(f)
            rows = list(reader)
        
        # å¤‡ä»½åŸæ–‡ä»¶
        backup_file = csv_file + '.backup'
        import shutil
        shutil.copy2(csv_file, backup_file)
        logger.info(f"ğŸ“‹ å·²å¤‡ä»½åˆ°: {backup_file}")
        
        # ä¿®å¤æ•°æ®
        fixed_rows = [correct_headers]  # æ–°è¡¨å¤´
        
        for i, row in enumerate(rows[1:], start=2):  # è·³è¿‡æ—§è¡¨å¤´
            # å¦‚æœè¡Œçš„åˆ—æ•°å°‘äºæ–°è¡¨å¤´ï¼Œè¡¥å……é»˜è®¤å€¼
            if len(row) < len(correct_headers):
                missing_cols = len(correct_headers) - len(row)
                # è¡¥å……é»˜è®¤å€¼ï¼š0, 0, 0, 0.000000, ''
                row.extend(['0'] * (missing_cols - 1) + [''])
            elif len(row) > len(correct_headers):
                # å¦‚æœåˆ—æ•°è¿‡å¤šï¼Œæˆªæ–­
                row = row[:len(correct_headers)]
            fixed_rows.append(row)
        
        # å†™å…¥ä¿®å¤åçš„æ–‡ä»¶
        with open(csv_file, 'w', newline='', encoding='utf-8-sig') as f:
            writer = csv.writer(f, quoting=csv.QUOTE_MINIMAL)
            writer.writerows(fixed_rows)
        
        logger.info(f"âœ… CSVæ–‡ä»¶è¡¨å¤´ä¿®å¤å®Œæˆï¼Œå…±å¤„ç† {len(fixed_rows)-1} è¡Œæ•°æ®")
        return True
        
    except Exception as e:
        logger.error(f"âŒ CSVæ–‡ä»¶è¡¨å¤´ä¿®å¤å¤±è´¥: {str(e)}")
        return False


def save_to_csv(question: str, options: List[str], q_type: str, raw_answer: str, 
                reasoning: Optional[str], processed_answer: str, ai_time: float, 
                total_time: float, model_name: str, reasoning_used: bool,
                prompt_tokens: int = 0, completion_tokens: int = 0, provider: str = ''):
    """
    ä¿å­˜ç­”é¢˜è®°å½•åˆ°CSVæ–‡ä»¶ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰
    
    Args:
        question: é¢˜ç›®
        options: é€‰é¡¹åˆ—è¡¨
        q_type: é¢˜å‹
        raw_answer: AIåŸå§‹å›ç­”
        reasoning: æ€è€ƒè¿‡ç¨‹ï¼ˆå¦‚æœæœ‰ï¼‰
        processed_answer: å¤„ç†åçš„ç­”æ¡ˆ
        ai_time: AIç­”é¢˜è€—æ—¶ï¼ˆç§’ï¼‰
        total_time: æ€»è€—æ—¶ï¼ˆç§’ï¼‰
        model_name: æ¨¡å‹åç§°
        reasoning_used: æ˜¯å¦ä½¿ç”¨äº†æ€è€ƒæ¨¡å¼
        prompt_tokens: è¾“å…¥tokenæ•°
        completion_tokens: è¾“å‡ºtokenæ•°
        provider: æ¨¡å‹æä¾›å•† (deepseek/doubao)
    """
    csv_file = os.getenv('CSV_LOG_FILE', 'ocs_answers_log.csv')
    
    # CSVè¡¨å¤´
    headers = [
        'æ—¶é—´æˆ³', 'é¢˜å‹', 'é¢˜ç›®', 'é€‰é¡¹', 'åŸå§‹å›ç­”', 'æ€è€ƒè¿‡ç¨‹', 
        'å¤„ç†åç­”æ¡ˆ', 'AIè€—æ—¶(ç§’)', 'æ€»è€—æ—¶(ç§’)', 'æ¨¡å‹', 'æ€è€ƒæ¨¡å¼',
        'è¾“å…¥Token', 'è¾“å‡ºToken', 'æ€»Token', 'è´¹ç”¨(å…ƒ)', 'æä¾›å•†'
    ]
    
    # ä½¿ç”¨çº¿ç¨‹é”ä¿æŠ¤CSVæ–‡ä»¶æ“ä½œï¼ˆæ”¯æŒå¹¶å‘ï¼‰
    with csv_write_lock:
        # æ£€æŸ¥å¹¶ä¿®å¤CSVæ–‡ä»¶è¡¨å¤´ï¼ˆå¦‚æœéœ€è¦ï¼‰
        if os.path.exists(csv_file):
            check_and_fix_csv_header(csv_file, headers)
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»ºå¹¶å†™å…¥è¡¨å¤´
        file_exists = os.path.exists(csv_file)
        
        try:
            # ä½¿ç”¨UTF-8 BOMç¼–ç ï¼Œç¡®ä¿Excelå¯ä»¥æ­£ç¡®æ˜¾ç¤ºä¸­æ–‡
            with open(csv_file, 'a', newline='', encoding='utf-8-sig') as f:
                writer = csv.writer(f, quoting=csv.QUOTE_MINIMAL)
                
                # å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œå†™å…¥è¡¨å¤´
                if not file_exists:
                    writer.writerow(headers)
                
                # å‡†å¤‡æ•°æ®
                timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                options_str = ' | '.join(options) if options else ''
                reasoning_str = reasoning if reasoning else ''
                
                # è®¡ç®—è´¹ç”¨ï¼ˆåŸºäºDeepSeekå’Œè±†åŒ…çš„å®˜æ–¹ä»·æ ¼ï¼‰
                # DeepSeek: è¾“å…¥ç¼“å­˜å‘½ä¸­0.2å…ƒ/ç™¾ä¸‡tokensï¼Œç¼“å­˜æœªå‘½ä¸­2å…ƒ/ç™¾ä¸‡tokensï¼Œè¾“å‡º3å…ƒ/ç™¾ä¸‡tokens
                # è±†åŒ…-Seed-1.6: æ¨ç†è¾“å…¥0.8å…ƒ/ç™¾ä¸‡tokensï¼Œæ¨ç†è¾“å‡º2å…ƒ/ç™¾ä¸‡tokens
                # æ³¨æ„ï¼šè¿™é‡Œå‡è®¾ç¼“å­˜æœªå‘½ä¸­ï¼ˆå®é™…åº”è¯¥æ ¹æ®ç¼“å­˜çŠ¶æ€åˆ¤æ–­ï¼‰
                cost = 0.0
                if provider.lower() == 'deepseek':
                    # DeepSeekä»·æ ¼ï¼ˆå‡è®¾ç¼“å­˜æœªå‘½ä¸­ï¼‰
                    input_cost = (prompt_tokens / 1000000) * 2.0  # 2å…ƒ/ç™¾ä¸‡tokens
                    output_cost = (completion_tokens / 1000000) * 3.0  # 3å…ƒ/ç™¾ä¸‡tokens
                    cost = input_cost + output_cost
                elif provider.lower() == 'doubao':
                    # è±†åŒ…-Seed-1.6 å®˜æ–¹ä»·æ ¼
                    input_cost = (prompt_tokens / 1000000) * 0.8  # 0.8å…ƒ/ç™¾ä¸‡tokens
                    output_cost = (completion_tokens / 1000000) * 2.0  # 2å…ƒ/ç™¾ä¸‡tokens
                    cost = input_cost + output_cost
                else:
                    # æœªçŸ¥æä¾›å•†ï¼Œä½¿ç”¨é»˜è®¤ä»·æ ¼ï¼ˆå‚è€ƒDeepSeekï¼‰
                    input_cost = (prompt_tokens / 1000000) * 2.0
                    output_cost = (completion_tokens / 1000000) * 3.0
                    cost = input_cost + output_cost
                
                total_tokens = prompt_tokens + completion_tokens
                
                # å†™å…¥æ•°æ®è¡Œï¼ˆæ‰€æœ‰å­—æ®µéƒ½ä¼šè¢«æ­£ç¡®è½¬ä¹‰ï¼‰
                row = [
                    timestamp,
                    q_type,
                    question,
                    options_str,
                    raw_answer,
                    reasoning_str,
                    processed_answer,
                    f"{ai_time:.2f}",
                    f"{total_time:.2f}",
                    model_name,
                    'æ˜¯' if reasoning_used else 'å¦',
                    str(prompt_tokens),
                    str(completion_tokens),
                    str(total_tokens),
                    f"{cost:.6f}",
                    provider.upper() if provider else ''
                ]
                
                writer.writerow(row)
                logger.debug(f"CSVè®°å½•å·²ä¿å­˜: {len(row)}ä¸ªå­—æ®µï¼Œæ€è€ƒè¿‡ç¨‹é•¿åº¦: {len(reasoning_str)}")
                
        except Exception as e:
            # CSVè®°å½•å¤±è´¥ä¸å½±å“ç­”é¢˜æµç¨‹ï¼Œåªè®°å½•æ—¥å¿—
            logger.warning(f"ä¿å­˜CSVè®°å½•å¤±è´¥: {str(e)}", exc_info=True)


@app.route('/api/answer', methods=['POST'])
def answer_question():
    """ç­”é¢˜æ¥å£"""
    start_time = time.time()
    
    try:
        if not model_client:
            error_msg = init_error or "æ¨¡å‹å®¢æˆ·ç«¯æœªåˆå§‹åŒ–ï¼Œè¯·æ£€æŸ¥é…ç½®"
            print(f"\nâŒ {error_msg}")
            print("="*80 + "\n")
            return jsonify({
                "success": False,
                "error": error_msg,
                "hint": "è¯·æ£€æŸ¥.envæ–‡ä»¶ä¸­çš„APIå¯†é’¥é…ç½®"
            }), 500
        
        data = request.get_json()
        
        if not data:
            return jsonify({"success": False, "error": "æ— æ•ˆçš„è¯·æ±‚æ•°æ®"}), 400
        
        question = data.get('question', '').strip()
        options = data.get('options', [])
        type_num = data.get('type', 0)
        images = data.get('images', [])  # å›¾ç‰‡URLåˆ—è¡¨
        
        if not question:
            return jsonify({"success": False, "error": "é¢˜ç›®ä¸èƒ½ä¸ºç©º"}), 400
        
        q_type = QUESTION_TYPES.get(type_num, "single")
        q_type_name = {"single": "å•é€‰é¢˜", "multiple": "å¤šé€‰é¢˜", "judgement": "åˆ¤æ–­é¢˜", "completion": "å¡«ç©ºé¢˜"}.get(q_type, "æœªçŸ¥é¢˜å‹")
        
        if isinstance(options, list):
            options = [str(opt).strip() for opt in options if opt]
        else:
            options = []
        
        # æå–é¢˜ç›®ä¸­çš„å›¾ç‰‡URL
        image_urls = []
        
        # æ¸…ç†URLçš„å‡½æ•°ï¼ˆå»é™¤æ‰©å±•ååå¯èƒ½é™„åŠ çš„å­—ç¬¦ï¼‰
        def clean_url(url):
            """æ¸…ç†URLï¼Œå»é™¤æ‰©å±•ååå¯èƒ½é™„åŠ çš„å­—ç¬¦"""
            url = str(url).strip()
            # æ‰¾åˆ°æœ€åä¸€ä¸ªå›¾ç‰‡æ‰©å±•åçš„ä½ç½®
            match = re.search(r'\.(jpg|jpeg|png|gif|bmp|webp)', url, re.IGNORECASE)
            if match:
                # åªä¿ç•™åˆ°æ‰©å±•åç»“æŸï¼ˆåŒ…æ‹¬æ‰©å±•åï¼‰
                end_pos = match.end()
                return url[:end_pos]
            return url
        
        if images and isinstance(images, list):
            image_urls = [clean_url(img) for img in images if img]
        
        # ä»é¢˜ç›®æ–‡æœ¬ä¸­æå–å›¾ç‰‡URLï¼ˆæ”¯æŒå¸¸è§å›¾ç‰‡æ ¼å¼ï¼‰
        # ä½¿ç”¨éè´ªå©ªåŒ¹é…ï¼Œç¡®ä¿åœ¨é‡åˆ°å›¾ç‰‡æ‰©å±•ååç«‹å³åœæ­¢
        # åŒ¹é…URLä¸­çš„åˆæ³•å­—ç¬¦ï¼Œä½†ä½¿ç”¨éè´ªå©ªæ¨¡å¼é¿å…åŒ¹é…è¿‡å¤š
        img_pattern = r'(https?://[a-zA-Z0-9\-._~:/?#\[\]@!$&\'()*+,;=%]+?\.(?:jpg|jpeg|png|gif|bmp|webp))'
        found_images = re.findall(img_pattern, question, re.IGNORECASE)
        
        # æ¸…ç†æå–çš„URL
        found_images = [clean_url(url) for url in found_images]
        
        if found_images:
            logger.info(f"ğŸ“· ä»é¢˜ç›®ä¸­æ£€æµ‹åˆ° {len(found_images)} å¼ å›¾ç‰‡")
        image_urls.extend(found_images)
        
        # ä»é€‰é¡¹ä¸­æå–å›¾ç‰‡URL
        found_images_in_options = []
        if options:
            options_text = ' '.join(str(opt) for opt in options)
            found_images_in_options = re.findall(img_pattern, options_text, re.IGNORECASE)
            found_images_in_options = [clean_url(url) for url in found_images_in_options]
            if found_images_in_options:
                logger.info(f"ğŸ“· ä»é€‰é¡¹ä¸­æ£€æµ‹åˆ° {len(found_images_in_options)} å¼ å›¾ç‰‡")
                image_urls.extend(found_images_in_options)
        
        image_urls = list(dict.fromkeys(image_urls))  # å»é‡
        
        # è¿‡æ»¤æ‰æ˜æ˜¾çš„å›¾æ ‡URLï¼ˆé€šå¸¸ä¸æ˜¯é¢˜ç›®å†…å®¹ï¼‰
        # ä¾‹å¦‚ï¼šicon/video.png, icon/audio.png, icons/ ç­‰
        filtered_image_urls = []
        icon_keywords = ['/icon/', '/icons/', '/icon.', 'icon/', 'video.png', 'audio.png', 'play.png', 'pause.png']
        
        for img_url in image_urls:
            # è·³è¿‡æ˜æ˜¾çš„å›¾æ ‡URL
            img_url_lower = img_url.lower()
            is_icon = any(keyword in img_url_lower for keyword in icon_keywords)
            
            if is_icon:
                logger.debug(f"è·³è¿‡å›¾æ ‡URL: {img_url}")
                continue
            
            filtered_image_urls.append(img_url)
        
        image_urls = filtered_image_urls
        
        # è®°å½•å›¾ç‰‡æ£€æµ‹ç»“æœ
        total_found = len(found_images) + len(found_images_in_options) + len([img for img in (images or []) if img])
        if total_found > 0:
            logger.info(f"ğŸ“· å›¾ç‰‡æ£€æµ‹ç»“æœ: é¢˜å¹²{len(found_images)}å¼ , é€‰é¡¹{len(found_images_in_options)}å¼ , APIä¼ å…¥{len(images or [])}å¼ , è¿‡æ»¤å{len(image_urls)}å¼ ")
        
        # å¦‚æœè¿‡æ»¤åæ²¡æœ‰å›¾ç‰‡ï¼Œè®°å½•æ—¥å¿—
        if len(image_urls) == 0 and total_found > 0:
            logger.debug("æ‰€æœ‰å›¾ç‰‡URLå·²è¢«è¿‡æ»¤ï¼ˆå¯èƒ½éƒ½æ˜¯å›¾æ ‡ï¼‰ï¼Œä½¿ç”¨çº¯æ–‡æœ¬æ¨¡å¼")
        
        # æ§åˆ¶å°è¾“å‡ºé¢˜ç›®ä¿¡æ¯
        print("\n" + "="*80)
        print(f"ğŸ“ ã€{q_type_name}ã€‘")
        print(f"é¢˜ç›®: {question}")
        if options:
            print(f"é€‰é¡¹: {' | '.join(options)}")
        if image_urls:
            print(f"ğŸ“· æ£€æµ‹åˆ°å›¾ç‰‡: {len(image_urls)}å¼ ")
            if found_images_in_options and len(found_images_in_options) > 0:
                print(f"   âš ï¸  é€‰é¡¹ä¸­æœ‰å›¾ç‰‡ï¼Œå°†è‡ªåŠ¨ä½¿ç”¨è±†åŒ…æ¨¡å‹")
            for i, img_url in enumerate(image_urls, 1):
                print(f"   {i}. {img_url}")
        print("="*80)
        
        # æ„å»ºprompt
        prompt = PromptBuilder.build_prompt(question, options, q_type)
        
        # å¤šé€‰é¢˜è‡ªåŠ¨å¯ç”¨æ€è€ƒæ¨¡å¼
        force_reasoning = False
        reasoning_reasons = []
        
        if q_type == "multiple" and model_client.auto_reasoning_for_multiple:
            force_reasoning = True
            reasoning_reasons.append("å¤šé€‰é¢˜")
        
        # å¸¦å›¾ç‰‡é¢˜ç›®è‡ªåŠ¨å¯ç”¨æ€è€ƒæ¨¡å¼
        if image_urls and model_client.auto_reasoning_for_images:
            force_reasoning = True
            reasoning_reasons.append("å›¾ç‰‡é¢˜")
        
        if force_reasoning and reasoning_reasons:
            print(f"ğŸ§  {' + '.join(reasoning_reasons)}è‡ªåŠ¨å¯ç”¨æ·±åº¦æ€è€ƒæ¨¡å¼")
        
        # è°ƒç”¨æ¨¡å‹ï¼ˆè®¡æ—¶ï¼‰
        ai_start = time.time()
        reasoning, raw_answer, usage_info = model_client.chat(
            prompt, 
            force_reasoning=force_reasoning,
            image_urls=image_urls if image_urls else None
        )
        ai_time = time.time() - ai_start
        
        if not raw_answer:
            print(f"âŒ ç­”é¢˜å¤±è´¥: AIæœªè¿”å›ç­”æ¡ˆ")
            return jsonify({"success": False, "error": "AIç­”é¢˜å¤±è´¥"}), 500
        
        # æå–tokenä½¿ç”¨é‡
        prompt_tokens = 0
        completion_tokens = 0
        if usage_info:
            prompt_tokens = usage_info.get('prompt_tokens', 0)
            completion_tokens = usage_info.get('completion_tokens', 0)
        
        # å¤„ç†ç­”æ¡ˆ
        processed_answer = AnswerProcessor.process_answer(raw_answer, q_type, options)
        
        # è®¡ç®—æ€»è€—æ—¶
        total_time = time.time() - start_time
        
        # æ§åˆ¶å°è¾“å‡ºç­”æ¡ˆå’Œè€—æ—¶
        print(f"\nğŸ¤– AIåŸå§‹å›ç­”: {raw_answer}")
        print(f"âœ… å¤„ç†åç­”æ¡ˆ: {processed_answer}")
        print(f"â±ï¸  æ¨¡å‹ç­”é¢˜ç”¨æ—¶: {format_time(ai_time)}")
        print(f"â±ï¸  æ€»å¤„ç†ç”¨æ—¶: {format_time(total_time)}")
        print("="*80 + "\n")
        
        # è®°å½•åˆ°CSVæ–‡ä»¶
        # ç¡®å®šå®é™…ä½¿ç”¨çš„æ¨¡å‹åç§°
        if model_client.is_auto_mode:
            # æ™ºèƒ½æ¨¡å¼ï¼šä»å“åº”ä¸­è·å–å®é™…ä½¿ç”¨çš„æ¨¡å‹
            actual_provider = model_client._select_model(image_urls if image_urls else None)[0]
            if actual_provider in model_client.models:
                model_name = model_client.models[actual_provider]
            else:
                model_name = "auto-unknown"
        else:
            model_name = model_client.model if not force_reasoning else ('deepseek-reasoner' if model_client.provider == 'deepseek' else model_client.model)
        
        reasoning_used = force_reasoning or model_client.enable_reasoning
        
        # ç¡®å®šæä¾›å•†
        actual_provider = ''
        if model_client.is_auto_mode:
            actual_provider = model_client._select_model(image_urls if image_urls else None)[0]
        else:
            actual_provider = model_client.provider
        
        save_to_csv(
            question=question,
            options=options,
            q_type=q_type_name,
            raw_answer=raw_answer,
            reasoning=reasoning,
            processed_answer=processed_answer,
            ai_time=ai_time,
            total_time=total_time,
            model_name=model_name,
            reasoning_used=reasoning_used,
            prompt_tokens=prompt_tokens,
            completion_tokens=completion_tokens,
            provider=actual_provider
        )
        
        # æ„å»ºå“åº”ï¼ˆOCSè„šæœ¬æ ¼å¼ï¼šè¿”å›[é¢˜ç›®, ç­”æ¡ˆ, extra_data]ï¼‰
        # extra_dataæ ¼å¼ï¼š{ai: true, tags: [{text, title, color}]}
        # æ³¨æ„ï¼šOCSè„šæœ¬ä¼šåœ¨ai=trueæ—¶è‡ªåŠ¨æ·»åŠ "AI"æ ‡ç­¾ï¼ˆè“è‰²ï¼‰
        # æ‰€ä»¥æˆ‘ä»¬åªéœ€è¦æ·»åŠ é¢å¤–çš„æ ‡ç­¾æ¥åŒºåˆ†æ€è€ƒ/éæ€è€ƒæ¨¡å¼
        
        # æ„å»ºæ ‡ç­¾
        tags = []
        
        # æ€è€ƒæ¨¡å¼ï¼šæ·»åŠ "æ·±åº¦æ€è€ƒ"æ ‡ç­¾ï¼ˆç´«è‰²ï¼‰ï¼ŒOCSä¼šè‡ªåŠ¨æ·»åŠ "AI"æ ‡ç­¾ï¼ˆè“è‰²ï¼‰
        if force_reasoning or model_client.enable_reasoning:
            tags.append({
                "text": "æ·±åº¦æ€è€ƒ",
                "title": "ä½¿ç”¨æ·±åº¦æ€è€ƒæ¨¡å¼ç”Ÿæˆï¼Œç­”æ¡ˆæ›´å‡†ç¡®",
                "color": "purple"  # OCSæ”¯æŒçš„é¢œè‰²ï¼šblue, green, red, yellow, gray, purple, orange
            })
            # å¦‚æœæ˜¯å¤šé€‰é¢˜è‡ªåŠ¨å¯ç”¨çš„æ€è€ƒæ¨¡å¼
            if force_reasoning:
                tags.append({
                    "text": "è‡ªåŠ¨æ€è€ƒ",
                    "title": "å¤šé€‰é¢˜è‡ªåŠ¨å¯ç”¨æ·±åº¦æ€è€ƒ",
                    "color": "orange"
                })
        # æ™®é€šæ¨¡å¼ï¼šä¸æ·»åŠ æ ‡ç­¾ï¼ŒOCSè„šæœ¬ä¼šè‡ªåŠ¨æ·»åŠ "AI"æ ‡ç­¾ï¼ˆè“è‰²ï¼‰
        
        # æ¨¡å‹æ ‡ç­¾
        if model_client.is_auto_mode:
            # æ™ºèƒ½æ¨¡å¼ï¼šæ˜¾ç¤ºå®é™…ä½¿ç”¨çš„æ¨¡å‹
            actual_provider = model_client._select_model(image_urls if image_urls else None)[0]
            display_provider = actual_provider.upper()
            if actual_provider in model_client.models:
                display_model = model_client.models[actual_provider]
            else:
                display_model = "unknown"
            
            # æ·»åŠ æ™ºèƒ½é€‰æ‹©æ ‡ç­¾
            tags.append({
                "text": "æ™ºèƒ½é€‰æ‹©",
                "title": "æ ¹æ®é¢˜ç›®å†…å®¹è‡ªåŠ¨é€‰æ‹©æœ€åˆé€‚çš„æ¨¡å‹",
                "color": "blue"
            })
            tags.append({
                "text": display_provider,
                "title": f"å®é™…ä½¿ç”¨: {display_model}",
                "color": "green"
            })
            model_name = display_model
        else:
            model_name = model_client.model if not force_reasoning else ('deepseek-reasoner' if model_client.provider == 'deepseek' else model_client.model)
            tags.append({
                "text": model_client.provider.upper(),
                "title": f"æ¨¡å‹: {model_name}",
                "color": "green"
            })
        
        # OCSè„šæœ¬æœŸæœ›çš„æ ¼å¼ï¼š[é¢˜ç›®, ç­”æ¡ˆ, extra_data]
        # ai=true ä¼šè®©OCSè‡ªåŠ¨æ·»åŠ "AI"æ ‡ç­¾
        # è®¡ç®—æ€»tokenæ•°
        total_tokens = prompt_tokens + completion_tokens
        
        ocs_format = [
            question,
            processed_answer,
            {
                "ai": True,  # OCSä¼šè‡ªåŠ¨æ·»åŠ "AI"æ ‡ç­¾
                "tags": tags,  # æˆ‘ä»¬æ·»åŠ çš„é¢å¤–æ ‡ç­¾ï¼ˆæ·±åº¦æ€è€ƒã€æ¨¡å‹ç­‰ï¼‰
                "model": model_name,
                "provider": model_client.provider,
                "reasoning_used": force_reasoning or model_client.enable_reasoning,
                "ai_time": round(ai_time, 2),
                "total_time": round(total_time, 2),
                # Tokenä½¿ç”¨é‡ï¼ˆä»APIå“åº”ä¸­æå–ï¼‰
                "usage": {
                    "prompt_tokens": prompt_tokens,
                    "completion_tokens": completion_tokens,
                    "total_tokens": total_tokens
                }
            }
        ]
        
        # è¿”å›å…¼å®¹æ ¼å¼ï¼ˆåŒæ—¶æ”¯æŒOCSæ ¼å¼å’ŒåŸå§‹æ ¼å¼ï¼‰
        response_provider = model_client.provider
        if model_client.is_auto_mode:
            actual_provider = model_client._select_model(image_urls if image_urls else None)[0]
            response_provider = f"auto({actual_provider})"
        
        return jsonify({
            "success": True,
            "question": question,
            "answer": processed_answer,
            "type": q_type,
            "raw_answer": raw_answer,
            "model": model_name,
            "provider": response_provider,
            "reasoning_used": force_reasoning or model_client.enable_reasoning,
            "ai_time": round(ai_time, 2),
            "total_time": round(total_time, 2),
            # Tokenä½¿ç”¨é‡ï¼ˆä»APIå“åº”ä¸­æå–ï¼‰
            "usage": {
                "prompt_tokens": prompt_tokens,
                "completion_tokens": completion_tokens,
                "total_tokens": total_tokens
            },
            # OCSè„šæœ¬ç›´æ¥ä½¿ç”¨çš„æ ¼å¼
            "ocs_format": ocs_format
        })
    
    except Exception as e:
        error_time = time.time() - start_time
        print(f"\nâŒ é”™è¯¯: {str(e)}")
        print(f"â±ï¸  å¤„ç†ç”¨æ—¶: {format_time(error_time)}")
        print("="*80 + "\n")
        logger.error(f"å¤„ç†è¯·æ±‚é”™è¯¯: {str(e)}", exc_info=True)
        return jsonify({"success": False, "error": f"æœåŠ¡å™¨é”™è¯¯: {str(e)}"}), 500


@app.route('/', methods=['HEAD', 'GET'])
def latency_test():
    """
    OCSè„šæœ¬å»¶è¿Ÿæµ‹è¯•æ¥å£
    æ”¯æŒHEADå’ŒGETè¯·æ±‚ï¼Œç”¨äºæµ‹è¯•é¢˜åº“è¿æ¥å»¶è¿Ÿ
    """
    # è·å–æ—¶é—´æˆ³å‚æ•°ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    timestamp = request.args.get('t', None)
    
    # åˆ›å»ºå“åº”
    response = make_response('', 200)
    
    # è®¾ç½®å“åº”å¤´
    response.headers['Content-Type'] = 'text/plain; charset=utf-8'
    response.headers['X-Service'] = 'OCS AI Answerer'
    response.headers['X-Version'] = '2.0.0'
    
    # å¦‚æœæä¾›äº†æ—¶é—´æˆ³ï¼Œè®¡ç®—å»¶è¿Ÿï¼ˆå¯é€‰ï¼Œç”¨äºè°ƒè¯•ï¼‰
    if timestamp:
        try:
            client_timestamp = int(timestamp) / 1000  # è½¬æ¢ä¸ºç§’
            server_timestamp = time.time()
            latency = (server_timestamp - client_timestamp) * 1000  # æ¯«ç§’
            response.headers['X-Latency'] = f"{latency:.2f}ms"
        except (ValueError, TypeError):
            pass
    
    # GETè¯·æ±‚è¿”å›ç®€å•æ–‡æœ¬
    if request.method == 'GET':
        response.set_data('OK')
    
    return response


@app.route('/api/health', methods=['GET'])
def health_check():
    """å¥åº·æ£€æŸ¥"""
    return jsonify({
        "status": "ok" if model_client else "error",
        "service": "OCS AI Answerer (Multi-Model)",
        "version": "2.0.0",
        "provider": MODEL_PROVIDER,
        "model": model_client.model if model_client else "æœªé…ç½®",
        "reasoning_enabled": ENABLE_REASONING,
        "api_configured": bool(
            (MODEL_PROVIDER == 'deepseek' and DEEPSEEK_API_KEY) or
            (MODEL_PROVIDER == 'doubao' and DOUBAO_API_KEY)
        ),
        "init_error": init_error if not model_client else None
    })


@app.route('/api/config', methods=['GET'])
def get_config():
    """è·å–å½“å‰é…ç½®"""
    config = {
        "provider": MODEL_PROVIDER,
        "model": model_client.model if model_client else None,
        "reasoning_enabled": ENABLE_REASONING,
        "auto_reasoning_for_multiple": AUTO_REASONING_FOR_MULTIPLE,
        "auto_reasoning_for_images": AUTO_REASONING_FOR_IMAGES,
        "reasoning_effort": REASONING_EFFORT if ENABLE_REASONING else None,
        "temperature": TEMPERATURE,
        "max_tokens": MAX_TOKENS
    }
    
    # å¦‚æœæ˜¯æ™ºèƒ½æ¨¡å¼ï¼Œè¿”å›æ›´å¤šä¿¡æ¯
    if model_client and model_client.is_auto_mode:
        config.update({
            "auto_mode": True,
            "available_models": list(model_client.clients.keys()),
            "prefer_model": model_client.prefer_model,
            "image_model": model_client.image_model,
            "deepseek_configured": "deepseek" in model_client.clients,
            "doubao_configured": "doubao" in model_client.clients
        })
    else:
        config["auto_mode"] = False
    
    return jsonify(config)


@app.route('/api/csv', methods=['GET'])
def get_csv():
    """è·å–CSVæ—¥å¿—æ–‡ä»¶"""
    csv_file = os.getenv('CSV_LOG_FILE', 'ocs_answers_log.csv')
    
    try:
        if os.path.exists(csv_file):
            with open(csv_file, 'r', encoding='utf-8-sig') as f:
                content = f.read()
            response = make_response(content)
            response.headers['Content-Type'] = 'text/csv; charset=utf-8'
            # ä¸è®¾ç½®Content-Dispositionï¼Œå…è®¸æµè§ˆå™¨ç›´æ¥è¯»å–å†…å®¹
            return response
        else:
            return jsonify({"error": "CSVæ–‡ä»¶ä¸å­˜åœ¨"}), 404
    except Exception as e:
        logger.error(f"è¯»å–CSVæ–‡ä»¶å¤±è´¥: {str(e)}")
        return jsonify({"error": f"è¯»å–CSVæ–‡ä»¶å¤±è´¥: {str(e)}"}), 500


@app.route('/api/csv/clear', methods=['POST'])
def clear_csv():
    """æ¸…ç©ºCSVæ—¥å¿—æ–‡ä»¶ï¼ˆä¿ç•™è¡¨å¤´ï¼‰"""
    csv_file = os.getenv('CSV_LOG_FILE', 'ocs_answers_log.csv')
    
    try:
        # CSVè¡¨å¤´
        headers = [
            'æ—¶é—´æˆ³', 'é¢˜å‹', 'é¢˜ç›®', 'é€‰é¡¹', 'åŸå§‹å›ç­”', 'æ€è€ƒè¿‡ç¨‹', 
            'å¤„ç†åç­”æ¡ˆ', 'AIè€—æ—¶(ç§’)', 'æ€»è€—æ—¶(ç§’)', 'æ¨¡å‹', 'æ€è€ƒæ¨¡å¼',
            'è¾“å…¥Token', 'è¾“å‡ºToken', 'æ€»Token', 'è´¹ç”¨(å…ƒ)', 'æä¾›å•†'
        ]
        
        # å†™å…¥ç©ºæ–‡ä»¶ï¼ˆåªä¿ç•™è¡¨å¤´ï¼‰
        with open(csv_file, 'w', newline='', encoding='utf-8-sig') as f:
            writer = csv.writer(f)
            writer.writerow(headers)
        
        logger.info(f"CSVæ–‡ä»¶å·²æ¸…ç©º: {csv_file}")
        return jsonify({
            "success": True,
            "message": "CSVæ–‡ä»¶å·²æ¸…ç©ºï¼ˆä¿ç•™è¡¨å¤´ï¼‰",
            "file": csv_file
        })
    except Exception as e:
        logger.error(f"æ¸…ç©ºCSVæ–‡ä»¶å¤±è´¥: {str(e)}")
        return jsonify({"success": False, "error": f"æ¸…ç©ºCSVæ–‡ä»¶å¤±è´¥: {str(e)}"}), 500


@app.route('/viewer', methods=['GET'])
@app.route('/viewer/', methods=['GET'])
def viewer():
    """ç­”é¢˜è®°å½•å¯è§†åŒ–é¡µé¢"""
    html_file = os.path.join(os.path.dirname(__file__), 'ocs_answers_viewer.html')
    
    try:
        if os.path.exists(html_file):
            with open(html_file, 'r', encoding='utf-8') as f:
                html_content = f.read()
            
            # ä¿®æ”¹HTMLä¸­çš„fetchè·¯å¾„ï¼Œä½¿å…¶æŒ‡å‘Flask API
            html_content = html_content.replace(
                "fetch('ocs_answers_log.csv')",
                "fetch('/api/csv')"
            )
            # ç¡®ä¿æ‰€æœ‰å¯èƒ½çš„CSVè·¯å¾„éƒ½è¢«æ›¿æ¢
            html_content = html_content.replace(
                'fetch("ocs_answers_log.csv")',
                'fetch("/api/csv")'
            )
            # å¦‚æœChart.jsä¸å­˜åœ¨ï¼Œä½¿ç”¨CDN
            html_content = html_content.replace(
                '<script src="chart.js.min.js"></script>',
                '<script src="https://cdn.jsdelivr.net/npm/chart.js@4.4.0/dist/chart.umd.min.js"></script>'
            )
            
            response = make_response(html_content)
            response.headers['Content-Type'] = 'text/html; charset=utf-8'
            return response
        else:
            return jsonify({"error": "å¯è§†åŒ–é¡µé¢æ–‡ä»¶ä¸å­˜åœ¨"}), 404
    except Exception as e:
        logger.error(f"åŠ è½½å¯è§†åŒ–é¡µé¢å¤±è´¥: {str(e)}")
        return jsonify({"error": f"åŠ è½½å¯è§†åŒ–é¡µé¢å¤±è´¥: {str(e)}"}), 500


if __name__ == '__main__':
    # æ˜¾ç¤ºæ¨¡å‹ä¿¡æ¯
    if model_client and model_client.is_auto_mode:
        model_info = f"AUTO (æ™ºèƒ½é€‰æ‹©)"
        models_list = ", ".join(model_client.clients.keys())
        model_detail = f"å·²é…ç½®: {models_list}"
    elif model_client:
        model_info = f"{MODEL_PROVIDER.upper()} - {model_client.model}"
        model_detail = "å›ºå®šæ¨¡å¼"
    else:
        model_info = "æœªé…ç½®"
        model_detail = ""
    
    print(f"""
    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
    â•‘       OCSæ™ºèƒ½ç­”é¢˜APIæœåŠ¡ - å¤šæ¨¡å‹æ”¯æŒç‰ˆæœ¬ v2.1          â•‘
    â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
    â•‘  æ¥å£åœ°å€: http://{HOST}:{PORT}/api/answer              
    â•‘  å¥åº·æ£€æŸ¥: http://{HOST}:{PORT}/api/health              
    â•‘  é…ç½®æŸ¥è¯¢: http://{HOST}:{PORT}/api/config              
    â•‘  CSVæ•°æ®: http://{HOST}:{PORT}/api/csv                  
    â•‘  å¯è§†åŒ–é¡µé¢: http://{HOST}:{PORT}/viewer                
    â•‘  å»¶è¿Ÿæµ‹è¯•: http://{HOST}:{PORT}/?t=æ—¶é—´æˆ³ (HEAD/GET)    
    â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
    â•‘  å½“å‰æ¨¡å¼: {model_info:<48s}â•‘
    â•‘  {'  ' + model_detail if model_detail else '':<60s}â•‘
    â•‘  æ€è€ƒæ¨¡å¼: {'âœ… å·²å¯ç”¨' if ENABLE_REASONING else 'âŒ æœªå¯ç”¨':<40s}â•‘
    â•‘  å¤šé€‰é¢˜æ€è€ƒ: {'âœ… è‡ªåŠ¨å¯ç”¨' if AUTO_REASONING_FOR_MULTIPLE else 'âŒ å…³é—­':<38s}â•‘
    â•‘  å›¾ç‰‡é¢˜æ€è€ƒ: {'âœ… è‡ªåŠ¨å¯ç”¨' if AUTO_REASONING_FOR_IMAGES else 'âŒ å…³é—­':<38s}â•‘
    â•‘  æ”¯æŒé¢˜å‹: å•é€‰ã€å¤šé€‰ã€åˆ¤æ–­ã€å¡«ç©º                        â•‘
    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)
    
    if not model_client:
        print("\n" + "="*80)
        print("âŒ æ¨¡å‹å®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥")
        if init_error:
            print(f"é”™è¯¯ä¿¡æ¯: {init_error}")
        print("\nğŸ’¡ è§£å†³æ–¹æ¡ˆ:")
        if MODEL_PROVIDER == 'auto':
            print("   æ™ºèƒ½æ¨¡å¼éœ€è¦è‡³å°‘é…ç½®ä¸€ä¸ªæ¨¡å‹:")
            print("   1. åˆ›å»ºæˆ–ç¼–è¾‘ .env æ–‡ä»¶")
            print("   2. è®¾ç½® MODEL_PROVIDER=auto")
            print("   3. é…ç½®è‡³å°‘ä¸€ä¸ªæ¨¡å‹çš„APIå¯†é’¥:")
            print("      - DEEPSEEK_API_KEY=your_key (è·å–: https://platform.deepseek.com/api_keys)")
            print("      - DOUBAO_API_KEY=your_key + DOUBAO_MODEL=your_endpoint_id")
            print("        (è·å–: https://console.volcengine.com/ark)")
            print("   4. å»ºè®®é…ç½®ä¸¤ä¸ªæ¨¡å‹ä»¥è·å¾—æœ€ä½³æ•ˆæœ")
        elif MODEL_PROVIDER == 'deepseek':
            print("   1. åˆ›å»ºæˆ–ç¼–è¾‘ .env æ–‡ä»¶")
            print("   2. è®¾ç½® DEEPSEEK_API_KEY=your_api_key")
            print("   3. è·å–APIå¯†é’¥: https://platform.deepseek.com/api_keys")
        elif MODEL_PROVIDER == 'doubao':
            print("   1. åˆ›å»ºæˆ–ç¼–è¾‘ .env æ–‡ä»¶")
            print("   2. è®¾ç½® DOUBAO_API_KEY=your_api_key")
            print("   3. è®¾ç½® DOUBAO_MODEL=your_endpoint_id")
            print("   4. è·å–APIå¯†é’¥: https://console.volcengine.com/ark")
        print("="*80 + "\n")
    else:
        if model_client.is_auto_mode:
            print("âœ… æ™ºèƒ½æ¨¡å‹é€‰æ‹©å·²å¯ç”¨ï¼\n")
            print("ğŸ’¡ å·¥ä½œåŸç†:")
            print(f"   ğŸ“· æœ‰å›¾ç‰‡ â†’ è‡ªåŠ¨ä½¿ç”¨ {model_client.image_model}")
            print(f"   ğŸ“„ çº¯æ–‡æœ¬ â†’ è‡ªåŠ¨ä½¿ç”¨ {model_client.prefer_model} (æˆæœ¬æ›´ä½)")
            print(f"   ğŸ”§ å·²é…ç½®æ¨¡å‹: {', '.join(model_client.clients.keys())}\n")
        else:
            print("âœ… æœåŠ¡å¯åŠ¨æˆåŠŸï¼\n")
        
        print("ğŸš€ å¹¶å‘æ¨¡å¼å·²å¯ç”¨ï¼Œæ”¯æŒåŒæ—¶å¤„ç†å¤šä¸ªè¯·æ±‚ï¼\n")
    
    # å¯ç”¨å¤šçº¿ç¨‹æ”¯æŒï¼ˆæ”¯æŒå¹¶å‘è¯·æ±‚ï¼‰
    app.run(host=HOST, port=PORT, debug=DEBUG, threaded=True)

