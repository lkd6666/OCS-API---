#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
OCSè„šæœ¬æ™ºèƒ½ç­”é¢˜API - å¤šæ¨¡å‹æ”¯æŒç‰ˆæœ¬

è¿™æ˜¯ä¸€ä¸ªåŠŸèƒ½å®Œæ•´çš„åœ¨çº¿è¯¾ç¨‹ç³»ç»Ÿ(OCS)æ™ºèƒ½ç­”é¢˜APIæœåŠ¡ï¼Œæä¾›ä»¥ä¸‹æ ¸å¿ƒåŠŸèƒ½ï¼š

æ ¸å¿ƒç‰¹æ€§ï¼š
    - å¤šæ¨¡å‹æ”¯æŒï¼šDeepSeekã€è±†åŒ…(Doubao)ç­‰å¤šä¸ªå¤§è¯­è¨€æ¨¡å‹
    - æ™ºèƒ½æ¨¡å‹é€‰æ‹©ï¼šæ ¹æ®é¢˜ç›®ç±»å‹ï¼ˆæ–‡æœ¬/å›¾ç‰‡ï¼‰è‡ªåŠ¨é€‰æ‹©æœ€åˆé€‚çš„æ¨¡å‹
    - æ€è€ƒæ¨¡å¼ï¼šæ”¯æŒæ·±åº¦æ¨ç†æ¨¡å¼ï¼Œæé«˜å¤æ‚é¢˜ç›®çš„å‡†ç¡®ç‡
    - å®‰å…¨è®¤è¯ï¼šåŸºäºå¯†é’¥çš„è®¿é—®æ§åˆ¶å’Œé™æµä¿æŠ¤
    - å®Œæ•´çš„APIï¼šç­”é¢˜ã€é…ç½®ç®¡ç†ã€æ•°æ®ç»Ÿè®¡ã€CSVæ—¥å¿—ç­‰
    - Webç•Œé¢ï¼šVue3å‰ç«¯ + å¯è§†åŒ–æ•°æ®åˆ†æ

æ”¯æŒçš„é¢˜å‹ï¼š
    - å•é€‰é¢˜ (single)
    - å¤šé€‰é¢˜ (multiple)
    - åˆ¤æ–­é¢˜ (judgement)
    - å¡«ç©ºé¢˜ (completion)

æŠ€æœ¯æ ˆï¼š
    - Flask: Webæ¡†æ¶
    - OpenAI SDK: ç»Ÿä¸€çš„AIæ¨¡å‹è°ƒç”¨æ¥å£
    - httpx: é«˜æ€§èƒ½HTTPå®¢æˆ·ç«¯
    - CSV: ç­”é¢˜è®°å½•æŒä¹…åŒ–

ä½œè€…ï¼šå¼€æºé¡¹ç›®
ç‰ˆæœ¬ï¼šv2.2.0
è®¸å¯ï¼šMIT License
"""

# ==================== æ ‡å‡†åº“å¯¼å…¥ ====================
import os
import re
import time
import csv
import base64
import secrets
import hashlib
import json
import logging
from datetime import datetime
from io import BytesIO
from functools import wraps
from collections import defaultdict
from typing import List, Dict, Any, Optional, Tuple

# ==================== ç¬¬ä¸‰æ–¹åº“å¯¼å…¥ ====================
from flask import Flask, request, jsonify, make_response, redirect, send_from_directory
from flask_cors import CORS
from openai import OpenAI
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# ==================== é…ç½®åŒºåŸŸ ====================
# æ‰€æœ‰é…ç½®é¡¹éƒ½ä»ç¯å¢ƒå˜é‡è¯»å–ï¼Œæ”¯æŒé€šè¿‡.envæ–‡ä»¶æˆ–ç³»ç»Ÿç¯å¢ƒå˜é‡è®¾ç½®
# é…ç½®ä¼˜å…ˆçº§ï¼šç³»ç»Ÿç¯å¢ƒå˜é‡ > .envæ–‡ä»¶ > é»˜è®¤å€¼

# -------------------- æ¨¡å‹é…ç½® --------------------
MODEL_PROVIDER = os.getenv('MODEL_PROVIDER', 'deepseek')  # deepseek, doubao æˆ– autoï¼ˆæ™ºèƒ½é€‰æ‹©ï¼‰
MODEL_NAME = os.getenv('MODEL_NAME', 'deepseek-chat')     # æ¨¡å‹åç§°

# -------------------- æ™ºèƒ½æ¨¡å‹é€‰æ‹©é…ç½® --------------------
# AUTOæ¨¡å¼ä¸‹æ ¹æ®é¢˜ç›®å†…å®¹è‡ªåŠ¨é€‰æ‹©æœ€åˆé€‚çš„æ¨¡å‹
# - å›¾ç‰‡é¢˜ç›®ï¼šä½¿ç”¨IMAGE_MODELæŒ‡å®šçš„æ¨¡å‹ï¼ˆé€šå¸¸æ˜¯è±†åŒ…ï¼Œæ”¯æŒå¤šæ¨¡æ€ï¼‰
# - æ–‡æœ¬é¢˜ç›®ï¼šä½¿ç”¨PREFER_MODELæŒ‡å®šçš„æ¨¡å‹ï¼ˆé€šå¸¸æ˜¯DeepSeekï¼Œæˆæœ¬æ›´ä½ï¼‰
AUTO_MODEL_SELECTION = os.getenv('AUTO_MODEL_SELECTION', 'true').lower() == 'true'  # æ˜¯å¦å¯ç”¨æ™ºèƒ½é€‰æ‹©
PREFER_MODEL = os.getenv('PREFER_MODEL', 'deepseek')  # çº¯æ–‡æœ¬é¢˜ç›®é¦–é€‰æ¨¡å‹
IMAGE_MODEL = os.getenv('IMAGE_MODEL', 'doubao')       # å›¾ç‰‡é¢˜ç›®ä½¿ç”¨çš„æ¨¡å‹

# -------------------- DeepSeeké…ç½® --------------------
# DeepSeekæ˜¯ä¸€ä¸ªé«˜æ€§ä»·æ¯”çš„å¤§è¯­è¨€æ¨¡å‹
# æ”¯æŒdeepseek-chatï¼ˆæ™®é€šæ¨¡å¼ï¼‰å’Œdeepseek-reasonerï¼ˆæ€è€ƒæ¨¡å¼ï¼‰
DEEPSEEK_API_KEY = os.getenv('DEEPSEEK_API_KEY', '')
DEEPSEEK_BASE_URL = os.getenv('DEEPSEEK_BASE_URL', 'https://api.deepseek.com')
DEEPSEEK_MODEL = os.getenv('DEEPSEEK_MODEL', 'deepseek-chat')  # deepseek-chat æˆ– deepseek-reasoner

# -------------------- è±†åŒ…(Doubao)é…ç½® --------------------
# è±†åŒ…æ˜¯å­—èŠ‚è·³åŠ¨çš„å¤šæ¨¡æ€å¤§æ¨¡å‹ï¼Œæ”¯æŒå›¾ç‰‡è¾“å…¥
# éœ€è¦åœ¨ç«å±±å¼•æ“æ§åˆ¶å°åˆ›å»ºæ¨ç†æ¥å…¥ç‚¹è·å–endpoint ID
DOUBAO_API_KEY = os.getenv('DOUBAO_API_KEY', '')
DOUBAO_BASE_URL = os.getenv('DOUBAO_BASE_URL', 'https://ark.cn-beijing.volces.com/api/v3')
DOUBAO_MODEL = os.getenv('DOUBAO_MODEL', 'doubao-seed-1-6-251015')

# -------------------- æ€è€ƒæ¨¡å¼é…ç½® --------------------
# æ€è€ƒæ¨¡å¼ä½¿ç”¨æ·±åº¦æ¨ç†æé«˜å¤æ‚é¢˜ç›®çš„å‡†ç¡®ç‡
# é€‚åˆå¤šé€‰é¢˜ã€é€»è¾‘æ¨ç†é¢˜ç­‰éœ€è¦ä»”ç»†åˆ†æçš„åœºæ™¯
ENABLE_REASONING = os.getenv('ENABLE_REASONING', 'false').lower() == 'true'
REASONING_EFFORT = os.getenv('REASONING_EFFORT', 'medium')  # low, medium, high
AUTO_REASONING_FOR_MULTIPLE = os.getenv('AUTO_REASONING_FOR_MULTIPLE', 'true').lower() == 'true'
AUTO_REASONING_FOR_IMAGES = os.getenv('AUTO_REASONING_FOR_IMAGES', 'true').lower() == 'true'  # å¸¦å›¾ç‰‡é¢˜ç›®è‡ªåŠ¨å¯ç”¨æ·±åº¦æ€è€ƒ

# -------------------- AIå‚æ•°é…ç½® --------------------
# æ§åˆ¶æ¨¡å‹ç”Ÿæˆçš„éšæœºæ€§å’Œè¾“å‡ºé•¿åº¦
TEMPERATURE = float(os.getenv('TEMPERATURE', '0.1'))

# max_tokens é™åˆ¶:
# - deepseek-chat: [1, 8192] (æœ€å¤§8K)
# - deepseek-reasoner: [1, 65536] (æœ€å¤§64K)
# æ™®é€šæ¨¡å¼çš„ max_tokensï¼ˆé»˜è®¤500ï¼‰
MAX_TOKENS_RAW = int(os.getenv('MAX_TOKENS', '500'))
MAX_TOKENS = max(1, min(8192, MAX_TOKENS_RAW))  # é»˜è®¤é™åˆ¶åˆ°8Kï¼ˆdeepseek-chatçš„é™åˆ¶ï¼‰

# æ€è€ƒæ¨¡å¼çš„ max_tokensï¼ˆé»˜è®¤4096ï¼Œå¯ä»¥æ›´å¤§ä»¥æ”¯æŒå¤æ‚æ¨ç†ï¼‰
REASONING_MAX_TOKENS_RAW = int(os.getenv('REASONING_MAX_TOKENS', '4096'))
REASONING_MAX_TOKENS = max(1, min(65536, REASONING_MAX_TOKENS_RAW))  # é™åˆ¶åˆ°64Kï¼ˆdeepseek-reasonerçš„é™åˆ¶ï¼‰

TOP_P = float(os.getenv('TOP_P', '0.95'))

# -------------------- ç½‘ç»œé…ç½® --------------------
# æ”¯æŒHTTPä»£ç†ã€è¶…æ—¶æ§åˆ¶å’Œè‡ªåŠ¨é‡è¯•
HTTP_PROXY = os.getenv('HTTP_PROXY', '')
HTTPS_PROXY = os.getenv('HTTPS_PROXY', '')
TIMEOUT = float(os.getenv('TIMEOUT', '1200.0'))  # è¯·æ±‚è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
MAX_RETRIES = int(os.getenv('MAX_RETRIES', '3'))  # æœ€å¤§é‡è¯•æ¬¡æ•°

# -------------------- æœåŠ¡é…ç½® --------------------
# FlaskæœåŠ¡å™¨çš„ç›‘å¬åœ°å€å’Œç«¯å£
HOST = os.getenv('HOST', '0.0.0.0')
PORT = int(os.getenv('PORT', 5000))
DEBUG = os.getenv('DEBUG', 'False').lower() == 'true'

# -------------------- å®‰å…¨é…ç½® --------------------
# è®¿é—®æ§åˆ¶å’Œé™æµé…ç½®ï¼Œé˜²æ­¢æœªæˆæƒè®¿é—®å’Œæ»¥ç”¨
SECRET_KEY_FILE = os.getenv('SECRET_KEY_FILE', '.secret_key')  # å¯†é’¥æ–‡ä»¶è·¯å¾„
RATE_LIMIT_ATTEMPTS = int(os.getenv('RATE_LIMIT_ATTEMPTS', '5'))  # å…è®¸çš„è¿ç»­é”™è¯¯æ¬¡æ•°
RATE_LIMIT_WINDOW = int(os.getenv('RATE_LIMIT_WINDOW', '300'))  # é™æµæ—¶é—´çª—å£ï¼ˆç§’ï¼‰

# ==================== é…ç½®åŒºåŸŸç»“æŸ ====================

# ==================== å¸¸é‡å®šä¹‰ ====================
# HTTPçŠ¶æ€ç 
HTTP_OK = 200
HTTP_BAD_REQUEST = 400
HTTP_UNAUTHORIZED = 401
HTTP_FORBIDDEN = 403
HTTP_NOT_FOUND = 404
HTTP_TOO_MANY_REQUESTS = 429
HTTP_SERVER_ERROR = 500
HTTP_SERVICE_UNAVAILABLE = 503

# CSVæ–‡ä»¶åˆ—åï¼ˆç”¨äºç¡®ä¿ä¸€è‡´æ€§ï¼‰
CSV_HEADERS = [
    'æ—¶é—´æˆ³', 'é¢˜å‹', 'é¢˜ç›®', 'é€‰é¡¹', 'åŸå§‹å›ç­”', 'æ€è€ƒè¿‡ç¨‹', 
    'å¤„ç†åç­”æ¡ˆ', 'AIè€—æ—¶(ç§’)', 'æ€»è€—æ—¶(ç§’)', 'æ¨¡å‹', 'æ€è€ƒæ¨¡å¼',
    'è¾“å…¥Token', 'è¾“å‡ºToken', 'æ€»Token', 'è´¹ç”¨(å…ƒ)', 'æä¾›å•†'
]

# é¢˜å‹æ˜ å°„å¸¸é‡
QUESTION_TYPE_SINGLE = 'single'
QUESTION_TYPE_MULTIPLE = 'multiple'
QUESTION_TYPE_COMPLETION = 'completion'
QUESTION_TYPE_JUDGEMENT = 'judgement'

# æ¨¡å‹æä¾›å•†å¸¸é‡
PROVIDER_DEEPSEEK = 'deepseek'
PROVIDER_DOUBAO = 'doubao'
PROVIDER_AUTO = 'auto'

# é…ç½®æ—¥å¿—ï¼ˆå¿…é¡»åœ¨SecurityManagerä¹‹å‰åˆå§‹åŒ–ï¼‰
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# ==================== è‡ªå®šä¹‰æ¨¡å‹ç®¡ç† ====================

class CustomModelManager:
    """
    è‡ªå®šä¹‰æ¨¡å‹ç®¡ç†å™¨ï¼šç®¡ç†ç”¨æˆ·è‡ªå®šä¹‰çš„AIæ¨¡å‹é…ç½®
    
    åŠŸèƒ½ï¼š
        1. æ¨¡å‹CRUDï¼šæ·»åŠ ã€åˆ é™¤ã€æ›´æ–°ã€æŸ¥è¯¢è‡ªå®šä¹‰æ¨¡å‹
        2. å¤šæ¨¡æ€æ”¯æŒï¼šæ ‡è®°æ¨¡å‹æ˜¯å¦æ”¯æŒå›¾ç‰‡è¾“å…¥
        3. Tokené…ç½®ï¼šæ¯ä¸ªæ¨¡å‹å¯å•ç‹¬é…ç½®tokenå‚æ•°
        4. é¢˜å‹æ˜ å°„ï¼šä¸ºä¸åŒé¢˜å‹æŒ‡å®šä½¿ç”¨çš„æ¨¡å‹
        5. æŒä¹…åŒ–å­˜å‚¨ï¼šé…ç½®ä¿å­˜åˆ°JSONæ–‡ä»¶
    
    æ•°æ®ç»“æ„ï¼š
        models = {
            'model_id': {
                'name': 'æ¨¡å‹æ˜¾ç¤ºåç§°',
                'provider': 'æä¾›å•†ç±»å‹ï¼ˆopenai/customï¼‰',
                'api_key': 'APIå¯†é’¥',
                'base_url': 'åŸºç¡€URL',
                'model_name': 'å®é™…æ¨¡å‹åç§°',
                'is_multimodal': True/False,
                'max_tokens': æ•´æ•°,
                'temperature': æµ®ç‚¹æ•°,
                'top_p': æµ®ç‚¹æ•°,
                'supports_reasoning': True/False,
                'enabled': True/False,
                'created_at': 'åˆ›å»ºæ—¶é—´',
                'updated_at': 'æ›´æ–°æ—¶é—´'
            }
        }
        
        question_type_models = {
            'single': {
                'models': ['model_id1', 'model_id2'],
                'enable_reasoning': False
            },
            'multiple': {
                'models': ['model_id1'],
                'enable_reasoning': True
            },
            'judgement': {
                'models': ['model_id1'],
                'enable_reasoning': False
            },
            'completion': {
                'models': ['model_id1'],
                'enable_reasoning': False
            },
            'image': {
                'models': ['model_id2'],
                'enable_reasoning': False
            }
        }
    """
    
    def __init__(self, config_file: str = 'custom_models.json'):
        """åˆå§‹åŒ–è‡ªå®šä¹‰æ¨¡å‹ç®¡ç†å™¨"""
        self.config_file = config_file
        self.models = {}
        self.question_type_models = {
            'single': {'models': [], 'enable_reasoning': False},
            'multiple': {'models': [], 'enable_reasoning': True},
            'judgement': {'models': [], 'enable_reasoning': False},
            'completion': {'models': [], 'enable_reasoning': False},
            'image': {'models': [], 'enable_reasoning': False}
        }
        self._load_config()
    
    def _load_config(self):
        """ä»æ–‡ä»¶åŠ è½½é…ç½®"""
        if os.path.exists(self.config_file):
            try:
                with open(self.config_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    self.models = data.get('models', {})
                    self.question_type_models = data.get('question_type_models', self.question_type_models)
                logger.info(f"âœ… å·²åŠ è½½ {len(self.models)} ä¸ªè‡ªå®šä¹‰æ¨¡å‹")
            except Exception as e:
                logger.error(f"âŒ åŠ è½½è‡ªå®šä¹‰æ¨¡å‹é…ç½®å¤±è´¥: {e}")
        else:
            logger.info("ğŸ“ æœªæ‰¾åˆ°è‡ªå®šä¹‰æ¨¡å‹é…ç½®æ–‡ä»¶ï¼Œå°†ä½¿ç”¨ç©ºé…ç½®")
    
    def _save_config(self):
        """ä¿å­˜é…ç½®åˆ°æ–‡ä»¶"""
        try:
            data = {
                'models': self.models,
                'question_type_models': self.question_type_models,
                'version': '1.0',
                'updated_at': datetime.now().isoformat()
            }
            with open(self.config_file, 'w', encoding='utf-8') as f:
                json.dump(data, f, indent=2, ensure_ascii=False)
            logger.info(f"âœ… è‡ªå®šä¹‰æ¨¡å‹é…ç½®å·²ä¿å­˜")
            return True
        except Exception as e:
            logger.error(f"âŒ ä¿å­˜è‡ªå®šä¹‰æ¨¡å‹é…ç½®å¤±è´¥: {e}")
            return False
    
    def add_model(self, model_id: str, model_config: Dict[str, Any]) -> Tuple[bool, str]:
        """
        æ·»åŠ è‡ªå®šä¹‰æ¨¡å‹
        
        Args:
            model_id: æ¨¡å‹å”¯ä¸€æ ‡è¯†
            model_config: æ¨¡å‹é…ç½®å­—å…¸
        
        Returns:
            (æ˜¯å¦æˆåŠŸ, æ¶ˆæ¯)
        """
        # éªŒè¯å¿…éœ€å­—æ®µ
        required_fields = ['name', 'provider', 'api_key', 'base_url', 'model_name']
        for field in required_fields:
            if field not in model_config:
                return False, f"ç¼ºå°‘å¿…éœ€å­—æ®µ: {field}"
        
        # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
        if model_id in self.models:
            return False, f"æ¨¡å‹IDå·²å­˜åœ¨: {model_id}"
        
        # æ·»åŠ é»˜è®¤å€¼
        model_config.setdefault('is_multimodal', False)
        model_config.setdefault('max_tokens', 2000)
        model_config.setdefault('temperature', 0.1)
        model_config.setdefault('top_p', 0.95)
        model_config.setdefault('supports_reasoning', False)
        model_config.setdefault('reasoning_param_name', 'reasoning_effort')  # æ€è€ƒå‚æ•°åç§°
        model_config.setdefault('reasoning_param_value', 'medium')  # æ€è€ƒå‚æ•°å€¼
        model_config.setdefault('enabled', True)
        model_config.setdefault('is_system', False)  # æ ‡è®°æ˜¯å¦ä¸ºç³»ç»Ÿæ¨¡å‹
        model_config['created_at'] = datetime.now().isoformat()
        model_config['updated_at'] = datetime.now().isoformat()
        
        # ä¿å­˜æ¨¡å‹
        self.models[model_id] = model_config
        
        if self._save_config():
            logger.info(f"âœ… å·²æ·»åŠ è‡ªå®šä¹‰æ¨¡å‹: {model_id} - {model_config['name']}")
            return True, "æ¨¡å‹æ·»åŠ æˆåŠŸ"
        else:
            # å›æ»š
            del self.models[model_id]
            return False, "ä¿å­˜é…ç½®å¤±è´¥"
    
    def update_model(self, model_id: str, model_config: Dict[str, Any]) -> Tuple[bool, str]:
        """æ›´æ–°æ¨¡å‹é…ç½®"""
        if model_id not in self.models:
            return False, f"æ¨¡å‹ä¸å­˜åœ¨: {model_id}"
        
        # æ£€æŸ¥æ˜¯å¦ä¸ºç³»ç»Ÿæ¨¡å‹
        if self.models[model_id].get('is_system', False):
            return False, "ç³»ç»Ÿæ¨¡å‹ä¸å¯ç¼–è¾‘ï¼Œè¯·åœ¨.envæ–‡ä»¶ä¸­ä¿®æ”¹é…ç½®"
        
        # æ›´æ–°é…ç½®
        model_config['updated_at'] = datetime.now().isoformat()
        # ä¿ç•™åˆ›å»ºæ—¶é—´å’Œç³»ç»Ÿæ ‡è®°
        model_config['created_at'] = self.models[model_id].get('created_at', datetime.now().isoformat())
        model_config['is_system'] = self.models[model_id].get('is_system', False)
        
        self.models[model_id].update(model_config)
        
        if self._save_config():
            logger.info(f"âœ… å·²æ›´æ–°æ¨¡å‹: {model_id}")
            return True, "æ¨¡å‹æ›´æ–°æˆåŠŸ"
        else:
            return False, "ä¿å­˜é…ç½®å¤±è´¥"
    
    def delete_model(self, model_id: str) -> Tuple[bool, str]:
        """åˆ é™¤æ¨¡å‹"""
        if model_id not in self.models:
            return False, f"æ¨¡å‹ä¸å­˜åœ¨: {model_id}"
        
        # æ£€æŸ¥æ˜¯å¦ä¸ºç³»ç»Ÿæ¨¡å‹
        if self.models[model_id].get('is_system', False):
            return False, "ç³»ç»Ÿæ¨¡å‹ä¸å¯åˆ é™¤ï¼Œå¦‚éœ€ç¦ç”¨è¯·åœ¨.envæ–‡ä»¶ä¸­åˆ é™¤å¯¹åº”çš„APIå¯†é’¥"
        
        # ä»é¢˜å‹æ˜ å°„ä¸­ç§»é™¤
        for q_type in self.question_type_models:
            if model_id in self.question_type_models[q_type]:
                self.question_type_models[q_type].remove(model_id)
        
        # åˆ é™¤æ¨¡å‹
        model_name = self.models[model_id].get('name', model_id)
        del self.models[model_id]
        
        if self._save_config():
            logger.info(f"âœ… å·²åˆ é™¤æ¨¡å‹: {model_id} - {model_name}")
            return True, "æ¨¡å‹åˆ é™¤æˆåŠŸ"
        else:
            return False, "ä¿å­˜é…ç½®å¤±è´¥"
    
    def get_model(self, model_id: str) -> Optional[Dict[str, Any]]:
        """è·å–å•ä¸ªæ¨¡å‹é…ç½®"""
        return self.models.get(model_id)
    
    def get_all_models(self, enabled_only: bool = False) -> Dict[str, Dict[str, Any]]:
        """è·å–æ‰€æœ‰æ¨¡å‹é…ç½®"""
        if enabled_only:
            return {k: v for k, v in self.models.items() if v.get('enabled', True)}
        return self.models.copy()
    
    def set_question_type_models(self, question_type: str, model_ids: List[str], enable_reasoning: bool = None) -> Tuple[bool, str]:
        """
        è®¾ç½®é¢˜å‹ä½¿ç”¨çš„æ¨¡å‹åˆ—è¡¨å’Œæ€è€ƒæ¨¡å¼é…ç½®
        
        Args:
            question_type: é¢˜å‹ï¼ˆsingle/multiple/judgement/completion/imageï¼‰
            model_ids: æ¨¡å‹IDåˆ—è¡¨ï¼ˆæŒ‰ä¼˜å…ˆçº§æ’åºï¼‰
            enable_reasoning: æ˜¯å¦å¯ç”¨æ€è€ƒæ¨¡å¼ï¼ˆNoneè¡¨ç¤ºä¸ä¿®æ”¹ç°æœ‰é…ç½®ï¼‰
        """
        if question_type not in self.question_type_models:
            return False, f"æ— æ•ˆçš„é¢˜å‹: {question_type}"
        
        # éªŒè¯æ‰€æœ‰æ¨¡å‹IDæ˜¯å¦å­˜åœ¨
        for model_id in model_ids:
            if model_id not in self.models:
                return False, f"æ¨¡å‹ä¸å­˜åœ¨: {model_id}"
        
        # ä¿æŒå­—å…¸ç»“æ„
        if isinstance(self.question_type_models[question_type], dict):
            self.question_type_models[question_type]['models'] = model_ids
            if enable_reasoning is not None:
                self.question_type_models[question_type]['enable_reasoning'] = enable_reasoning
        else:
            # å…¼å®¹æ—§æ ¼å¼ï¼šä»åˆ—è¡¨è½¬æ¢ä¸ºå­—å…¸
            self.question_type_models[question_type] = {
                'models': model_ids,
                'enable_reasoning': enable_reasoning if enable_reasoning is not None else False
            }
        
        if self._save_config():
            logger.info(f"âœ… å·²è®¾ç½® {question_type} é¢˜å‹çš„æ¨¡å‹åˆ—è¡¨å’Œæ€è€ƒé…ç½®")
            return True, "è®¾ç½®æˆåŠŸ"
        else:
            return False, "ä¿å­˜é…ç½®å¤±è´¥"
    
    def get_question_type_models(self, question_type: str) -> List[str]:
        """è·å–é¢˜å‹ä½¿ç”¨çš„æ¨¡å‹åˆ—è¡¨"""
        config = self.question_type_models.get(question_type, {})
        if isinstance(config, dict):
            return config.get('models', [])
        # å…¼å®¹æ—§æ ¼å¼
        return config if isinstance(config, list) else []
    
    def get_question_type_reasoning(self, question_type: str) -> bool:
        """è·å–é¢˜å‹çš„æ€è€ƒæ¨¡å¼é…ç½®"""
        config = self.question_type_models.get(question_type, {})
        if isinstance(config, dict):
            return config.get('enable_reasoning', False)
        return False
    
    def get_best_model_for_question(self, question_type: str, has_images: bool = False) -> Optional[str]:
        """
        ä¸ºé¢˜ç›®é€‰æ‹©æœ€ä½³æ¨¡å‹
        
        Args:
            question_type: é¢˜å‹
            has_images: æ˜¯å¦åŒ…å«å›¾ç‰‡
        
        Returns:
            æ¨¡å‹IDæˆ–None
        """
        # å¦‚æœæœ‰å›¾ç‰‡ï¼Œä¼˜å…ˆä½¿ç”¨å›¾ç‰‡é¢˜ä¸“ç”¨æ¨¡å‹
        if has_images:
            image_models = self.get_question_type_models('image')
            for model_id in image_models:
                model = self.get_model(model_id)
                if model and model.get('enabled', True) and model.get('is_multimodal', False):
                    return model_id
        
        # ä½¿ç”¨é¢˜å‹å¯¹åº”çš„æ¨¡å‹
        type_models = self.get_question_type_models(question_type)
        for model_id in type_models:
            model = self.get_model(model_id)
            if model and model.get('enabled', True):
                # å¦‚æœæœ‰å›¾ç‰‡ï¼Œå¿…é¡»æ˜¯å¤šæ¨¡æ€æ¨¡å‹
                if has_images and not model.get('is_multimodal', False):
                    continue
                return model_id
        
        return None

# å…¨å±€è‡ªå®šä¹‰æ¨¡å‹ç®¡ç†å™¨
custom_model_manager = CustomModelManager()

def import_system_models():
    """
    å°†.envä¸­é…ç½®çš„ç³»ç»Ÿæ¨¡å‹å¯¼å…¥åˆ°è‡ªå®šä¹‰æ¨¡å‹ç®¡ç†
    ç³»ç»Ÿæ¨¡å‹ä¸å¯åœ¨ç•Œé¢ç¼–è¾‘/åˆ é™¤ï¼Œéœ€è¦åœ¨.envæ–‡ä»¶ä¸­ä¿®æ”¹
    """
    imported = False
    
    # æ¸…ç†æ—§ç‰ˆæœ¬çš„ç³»ç»Ÿæ¨¡å‹ï¼ˆè¿ç§»åˆ°æ–°çš„IDï¼‰
    if 'system_deepseek' in custom_model_manager.models:
        # åˆ é™¤æ—§çš„å•ä¸€ DeepSeek æ¨¡å‹
        old_model = custom_model_manager.models.pop('system_deepseek', None)
        if old_model:
            logger.info("ğŸ”„ æ¸…ç†æ—§ç‰ˆæœ¬ç³»ç»Ÿæ¨¡å‹: system_deepseek")
            # ä»é¢˜å‹æ˜ å°„ä¸­ç§»é™¤
            for q_type in custom_model_manager.question_type_models:
                if 'system_deepseek' in custom_model_manager.question_type_models[q_type]:
                    custom_model_manager.question_type_models[q_type].remove('system_deepseek')
            custom_model_manager._save_config()
    
    # å¯¼å…¥DeepSeekæ¨¡å‹ï¼ˆåŒæ—¶å¯¼å…¥ chat å’Œ reasoner ä¸¤ä¸ªç‰ˆæœ¬ï¼‰
    if DEEPSEEK_API_KEY:
        # 1. å¯¼å…¥ DeepSeek Chatï¼ˆæ ‡å‡†æ¨¡å‹ï¼‰
        if 'system_deepseek_chat' not in custom_model_manager.models:
            deepseek_chat_config = {
                'name': 'DeepSeek Chat (ç³»ç»Ÿé…ç½®)',
                'provider': 'openai',
                'api_key': DEEPSEEK_API_KEY,
                'base_url': DEEPSEEK_BASE_URL,
                'model_name': 'deepseek-chat',
                'is_multimodal': False,
                'max_tokens': MAX_TOKENS,
                'temperature': TEMPERATURE,
                'top_p': TOP_P,
                'supports_reasoning': False,
                'reasoning_param_name': 'reasoning_effort',
                'reasoning_param_value': REASONING_EFFORT,
                'enabled': True,
                'is_system': True
            }
            success, msg = custom_model_manager.add_model('system_deepseek_chat', deepseek_chat_config)
            if success:
                logger.info("âœ… å·²å¯¼å…¥ç³»ç»Ÿæ¨¡å‹: DeepSeek Chat")
                imported = True
        
        # 2. å¯¼å…¥ DeepSeek Reasonerï¼ˆæ€è€ƒæ¨¡å‹ï¼‰
        if 'system_deepseek_reasoner' not in custom_model_manager.models:
            deepseek_reasoner_config = {
                'name': 'DeepSeek Reasoner (ç³»ç»Ÿé…ç½®)',
                'provider': 'openai',
                'api_key': DEEPSEEK_API_KEY,
                'base_url': DEEPSEEK_BASE_URL,
                'model_name': 'deepseek-reasoner',
                'is_multimodal': False,
                'max_tokens': REASONING_MAX_TOKENS,  # æ€è€ƒæ¨¡å‹éœ€è¦æ›´å¤§çš„token
                'temperature': TEMPERATURE,
                'top_p': TOP_P,
                'supports_reasoning': True,  # æ”¯æŒæ€è€ƒæ¨¡å¼
                'reasoning_param_name': 'reasoning_effort',
                'reasoning_param_value': REASONING_EFFORT,
                'enabled': True,
                'is_system': True
            }
            success, msg = custom_model_manager.add_model('system_deepseek_reasoner', deepseek_reasoner_config)
            if success:
                logger.info("âœ… å·²å¯¼å…¥ç³»ç»Ÿæ¨¡å‹: DeepSeek Reasoner")
                imported = True
    
    # å¯¼å…¥è±†åŒ…æ¨¡å‹
    if DOUBAO_API_KEY:
        doubao_config = {
            'name': 'è±†åŒ… Doubao (ç³»ç»Ÿé…ç½®)',
            'provider': 'openai',
            'api_key': DOUBAO_API_KEY,
            'base_url': DOUBAO_BASE_URL,
            'model_name': DOUBAO_MODEL,
            'is_multimodal': True,  # è±†åŒ…æ”¯æŒå¤šæ¨¡æ€
            'max_tokens': MAX_TOKENS,
            'temperature': TEMPERATURE,
            'top_p': TOP_P,
            'supports_reasoning': True,  # è±†åŒ…æ”¯æŒæ€è€ƒæ¨¡å¼
            'reasoning_param_name': 'reasoning_effort',
            'reasoning_param_value': REASONING_EFFORT,
            'enabled': True,
            'is_system': True  # æ ‡è®°ä¸ºç³»ç»Ÿæ¨¡å‹
        }
        
        if 'system_doubao' not in custom_model_manager.models:
            # æ–°å¢
            success, msg = custom_model_manager.add_model('system_doubao', doubao_config)
            if success:
                logger.info("âœ… å·²å¯¼å…¥ç³»ç»Ÿæ¨¡å‹: è±†åŒ…")
                imported = True
        else:
            # æ›´æ–°ç°æœ‰é…ç½®ï¼ˆä¿æŒç³»ç»Ÿæ¨¡å‹æœ€æ–°ï¼‰
            existing = custom_model_manager.models['system_doubao']
            if existing.get('supports_reasoning') != True:
                logger.info("ğŸ”„ æ›´æ–°è±†åŒ…ç³»ç»Ÿæ¨¡å‹é…ç½®ï¼ˆæ·»åŠ æ€è€ƒæ¨¡å¼æ”¯æŒï¼‰")
                custom_model_manager.models['system_doubao'].update(doubao_config)
                custom_model_manager._save_config()
                imported = True
    
    # å¦‚æœæœ‰å¯¼å…¥ï¼Œè‡ªåŠ¨é…ç½®é¢˜å‹æ˜ å°„ï¼ˆå¦‚æœè¿˜æ²¡æœ‰é…ç½®ï¼‰
    if imported:
        if not custom_model_manager.get_question_type_models('single'):
            # å•é€‰é¢˜ä¼˜å…ˆDeepSeek Chatï¼ˆå¿«é€Ÿï¼‰
            custom_model_manager.set_question_type_models('single', ['system_deepseek_chat'])
        
        if not custom_model_manager.get_question_type_models('multiple'):
            # å¤šé€‰é¢˜ä½¿ç”¨DeepSeek Reasonerï¼ˆéœ€è¦æ€è€ƒï¼‰
            custom_model_manager.set_question_type_models('multiple', ['system_deepseek_reasoner', 'system_deepseek_chat'])
        
        if not custom_model_manager.get_question_type_models('judgement'):
            # åˆ¤æ–­é¢˜ä¼˜å…ˆDeepSeek Chat
            custom_model_manager.set_question_type_models('judgement', ['system_deepseek_chat'])
        
        if not custom_model_manager.get_question_type_models('completion'):
            # å¡«ç©ºé¢˜ä¼˜å…ˆDeepSeek Chat
            custom_model_manager.set_question_type_models('completion', ['system_deepseek_chat'])
        
        if not custom_model_manager.get_question_type_models('image'):
            # å›¾ç‰‡é¢˜ä½¿ç”¨è±†åŒ…
            if DOUBAO_API_KEY:
                custom_model_manager.set_question_type_models('image', ['system_doubao'])
        
        logger.info("âœ… å·²è‡ªåŠ¨é…ç½®é¢˜å‹æ˜ å°„")

# è‡ªåŠ¨å¯¼å…¥ç³»ç»Ÿæ¨¡å‹
try:
    import_system_models()
except Exception as e:
    logger.warning(f"å¯¼å…¥ç³»ç»Ÿæ¨¡å‹å¤±è´¥: {e}")

# ==================== å®‰å…¨è®¤è¯ç³»ç»Ÿ ====================

class SecurityManager:
    """
    å®‰å…¨ç®¡ç†å™¨ï¼šå¤„ç†APIå¯†é’¥è®¤è¯å’Œè¯·æ±‚é™æµ
    
    åŠŸèƒ½ï¼š
        1. å¯†é’¥ç®¡ç†ï¼šç”Ÿæˆã€éªŒè¯å’Œæ›´æ–°è®¿é—®å¯†é’¥
        2. é™æµä¿æŠ¤ï¼šåŸºäºIPçš„å¤±è´¥å°è¯•è®°å½•å’Œé™æµ
        3. å¯†é’¥å­˜å‚¨ï¼šä½¿ç”¨SHA256å“ˆå¸Œå­˜å‚¨å¯†é’¥ï¼Œä¿è¯å®‰å…¨æ€§
    
    Attributes:
        key_file (str): å¯†é’¥æ–‡ä»¶è·¯å¾„
        secret_key_hash (str): å¯†é’¥çš„SHA256å“ˆå¸Œå€¼
        failed_attempts (defaultdict): IPåˆ°å¤±è´¥æ—¶é—´æˆ³åˆ—è¡¨çš„æ˜ å°„
        rate_limit_attempts (int): å…è®¸çš„æœ€å¤§è¿ç»­å¤±è´¥æ¬¡æ•°
        rate_limit_window (int): é™æµæ—¶é—´çª—å£ï¼ˆç§’ï¼‰
    """
    
    def __init__(self, key_file=SECRET_KEY_FILE):
        self.key_file = key_file
        self.secret_key_hash = None
        self.failed_attempts = defaultdict(list)  # IP -> [timestamp1, timestamp2, ...]
        self.rate_limit_attempts = RATE_LIMIT_ATTEMPTS
        self.rate_limit_window = RATE_LIMIT_WINDOW
        
        # åˆå§‹åŒ–å¯†é’¥
        self._init_secret_key()
    
    def _init_secret_key(self):
        """
        åˆå§‹åŒ–è®¿é—®å¯†é’¥
        
        è¡Œä¸ºï¼š
            - å¦‚æœå¯†é’¥æ–‡ä»¶å­˜åœ¨ï¼šåŠ è½½ç°æœ‰å¯†é’¥çš„å“ˆå¸Œå€¼
            - å¦‚æœå¯†é’¥æ–‡ä»¶ä¸å­˜åœ¨ï¼šç”Ÿæˆæ–°çš„éšæœºå¯†é’¥å¹¶ä¿å­˜
        
        æ³¨æ„ï¼š
            é¦–æ¬¡ç”Ÿæˆæ—¶ä¼šåœ¨æ—¥å¿—ä¸­æ˜¾ç¤ºæ˜æ–‡å¯†é’¥ï¼Œè¯·å¦¥å–„ä¿ç®¡
        """
        if os.path.exists(self.key_file):
            # åŠ è½½ç°æœ‰å¯†é’¥
            try:
                with open(self.key_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    self.secret_key_hash = data.get('key_hash')
                    logger.info(f"âœ… å·²åŠ è½½ç°æœ‰è®¿é—®å¯†é’¥")
            except Exception as e:
                logger.error(f"âŒ åŠ è½½å¯†é’¥å¤±è´¥: {e}ï¼Œå°†ç”Ÿæˆæ–°å¯†é’¥")
                self._generate_new_key()
        else:
            # é¦–æ¬¡å¯åŠ¨ï¼Œç”Ÿæˆæ–°å¯†é’¥
            self._generate_new_key()
    
    def _generate_new_key(self):
        """
        ç”Ÿæˆæ–°çš„64ä½éšæœºå¯†é’¥
        
        è¿‡ç¨‹ï¼š
            1. ä½¿ç”¨secrets.token_hexç”Ÿæˆ256ä½ç†µçš„éšæœºå¯†é’¥
            2. è®¡ç®—å¯†é’¥çš„SHA256å“ˆå¸Œå€¼ç”¨äºéªŒè¯
            3. å°†å¯†é’¥å’Œå“ˆå¸Œå€¼ä¿å­˜åˆ°æ–‡ä»¶
            4. åœ¨æ—¥å¿—ä¸­æ˜¾ç¤ºæ˜æ–‡å¯†é’¥ï¼ˆä»…æ­¤ä¸€æ¬¡ï¼‰
        
        å®‰å…¨æ€§ï¼š
            - ä½¿ç”¨åŠ å¯†å®‰å…¨çš„éšæœºæ•°ç”Ÿæˆå™¨
            - åªåœ¨é¦–æ¬¡ç”Ÿæˆæ—¶ä¿å­˜æ˜æ–‡å¯†é’¥åˆ°æ–‡ä»¶
            - åç»­åªä½¿ç”¨å“ˆå¸Œå€¼è¿›è¡ŒéªŒè¯
        """
        # ç”Ÿæˆ64ä½éšæœºhexå­—ç¬¦ä¸²ï¼ˆ256ä½ç†µï¼‰
        raw_key = secrets.token_hex(32)  # 32å­—èŠ‚ = 64ä¸ªhexå­—ç¬¦
        
        # å­˜å‚¨å¯†é’¥çš„SHA256å“ˆå¸Œå€¼
        self.secret_key_hash = hashlib.sha256(raw_key.encode()).hexdigest()
        
        # ä¿å­˜åˆ°æ–‡ä»¶
        try:
            with open(self.key_file, 'w', encoding='utf-8') as f:
                json.dump({
                    'key_hash': self.secret_key_hash,
                    'created_at': datetime.now().isoformat(),
                    'raw_key': raw_key  # ä»…é¦–æ¬¡ç”Ÿæˆæ—¶ä¿å­˜æ˜æ–‡å¯†é’¥
                }, f, indent=2)
            
            logger.info("=" * 80)
            logger.info("ğŸ” é¦–æ¬¡å¯åŠ¨ï¼šå·²ç”Ÿæˆè®¿é—®å¯†é’¥")
            logger.info("=" * 80)
            logger.info(f"   è®¿é—®å¯†é’¥: {raw_key}")
            logger.info("=" * 80)
            logger.info(f"âš ï¸  è¯·å¦¥å–„ä¿ç®¡æ­¤å¯†é’¥ï¼")
            logger.info(f"   - å¯†é’¥å·²ä¿å­˜åˆ°: {self.key_file}")
            logger.info(f"   - è®¿é—®é…ç½®é¡µé¢å’Œæ•æ„Ÿæ¥å£éœ€è¦æ­¤å¯†é’¥")
            logger.info(f"   - å¯åœ¨é…ç½®é¡µé¢ä¿®æ”¹å¯†é’¥")
            logger.info("=" * 80)
        except Exception as e:
            logger.error(f"âŒ ä¿å­˜å¯†é’¥å¤±è´¥: {e}")
    
    def verify_key(self, provided_key: str) -> bool:
        """
        éªŒè¯æä¾›çš„å¯†é’¥æ˜¯å¦æ­£ç¡®
        
        Args:
            provided_key: ç”¨æˆ·æä¾›çš„å¯†é’¥
        
        Returns:
            bool: å¯†é’¥æ­£ç¡®è¿”å›Trueï¼Œå¦åˆ™è¿”å›False
        
        å®ç°ï¼š
            é€šè¿‡æ¯”è¾ƒSHA256å“ˆå¸Œå€¼æ¥éªŒè¯å¯†é’¥ï¼Œé¿å…æ˜æ–‡æ¯”è¾ƒ
        """
        if not provided_key:
            return False
        
        provided_hash = hashlib.sha256(provided_key.encode()).hexdigest()
        return provided_hash == self.secret_key_hash
    
    def update_key(self, old_key: str, new_key: str) -> Tuple[bool, str]:
        """æ›´æ–°å¯†é’¥"""
        # éªŒè¯æ—§å¯†é’¥
        if not self.verify_key(old_key):
            return False, "æ—§å¯†é’¥é”™è¯¯"
        
        # éªŒè¯æ–°å¯†é’¥æ ¼å¼ï¼ˆè‡³å°‘8å­—ç¬¦ï¼Œåƒæ™®é€šå¯†ç ï¼‰
        if len(new_key) < 8:
            return False, "æ–°å¯†é’¥é•¿åº¦è‡³å°‘8å­—ç¬¦"
        
        # ç”Ÿæˆæ–°å¯†é’¥çš„å“ˆå¸Œ
        new_hash = hashlib.sha256(new_key.encode()).hexdigest()
        
        # ä¿å­˜æ–°å¯†é’¥
        try:
            with open(self.key_file, 'w', encoding='utf-8') as f:
                json.dump({
                    'key_hash': new_hash,
                    'updated_at': datetime.now().isoformat()
                }, f, indent=2)
            
            self.secret_key_hash = new_hash
            logger.info("âœ… è®¿é—®å¯†é’¥å·²æ›´æ–°")
            return True, "å¯†é’¥æ›´æ–°æˆåŠŸ"
        except Exception as e:
            logger.error(f"âŒ æ›´æ–°å¯†é’¥å¤±è´¥: {e}")
            return False, f"æ›´æ–°å¤±è´¥: {str(e)}"
    
    def check_rate_limit(self, ip: str) -> Tuple[bool, str]:
        """æ£€æŸ¥IPæ˜¯å¦è¢«é™æµ"""
        now = time.time()
        
        # æ¸…ç†è¿‡æœŸçš„å¤±è´¥è®°å½•
        self.failed_attempts[ip] = [
            ts for ts in self.failed_attempts[ip]
            if now - ts < self.rate_limit_window
        ]
        
        # æ£€æŸ¥æ˜¯å¦è¶…è¿‡é™åˆ¶
        if len(self.failed_attempts[ip]) >= self.rate_limit_attempts:
            remaining_time = int(self.rate_limit_window - (now - self.failed_attempts[ip][0]))
            return False, f"é”™è¯¯æ¬¡æ•°è¿‡å¤šï¼Œè¯·{remaining_time}ç§’åé‡è¯•"
        
        return True, ""
    
    def record_failed_attempt(self, ip: str):
        """è®°å½•å¤±è´¥çš„è®¤è¯å°è¯•"""
        self.failed_attempts[ip].append(time.time())
    
    def clear_failed_attempts(self, ip: str):
        """æ¸…é™¤å¤±è´¥è®°å½•ï¼ˆè®¤è¯æˆåŠŸåè°ƒç”¨ï¼‰"""
        if ip in self.failed_attempts:
            del self.failed_attempts[ip]

# å…¨å±€å®‰å…¨ç®¡ç†å™¨
security_manager = SecurityManager()

def require_auth(f):
    """è£…é¥°å™¨ï¼šè¦æ±‚APIå¯†é’¥è®¤è¯"""
    @wraps(f)
    def decorated_function(*args, **kwargs):
        # è·å–å®¢æˆ·ç«¯IP
        client_ip = request.headers.get('X-Forwarded-For', request.remote_addr)
        if ',' in client_ip:
            client_ip = client_ip.split(',')[0].strip()
        
        # æ£€æŸ¥é™æµ
        allowed, message = security_manager.check_rate_limit(client_ip)
        if not allowed:
            return jsonify({"error": message, "code": "RATE_LIMITED"}), 429
        
        # ä»è¯·æ±‚å¤´æˆ–æŸ¥è¯¢å‚æ•°è·å–å¯†é’¥
        api_key = request.headers.get('X-API-Key') or request.args.get('api_key')
        
        if not api_key:
            security_manager.record_failed_attempt(client_ip)
            return jsonify({"error": "ç¼ºå°‘APIå¯†é’¥", "code": "MISSING_KEY"}), 401
        
        # éªŒè¯å¯†é’¥
        if not security_manager.verify_key(api_key):
            security_manager.record_failed_attempt(client_ip)
            return jsonify({"error": "APIå¯†é’¥æ— æ•ˆ", "code": "INVALID_KEY"}), 403
        
        # è®¤è¯æˆåŠŸï¼Œæ¸…é™¤å¤±è´¥è®°å½•
        security_manager.clear_failed_attempts(client_ip)
        
        return f(*args, **kwargs)
    return decorated_function

# ==================== å®‰å…¨è®¤è¯ç³»ç»Ÿç»“æŸ ====================

app = Flask(__name__)
CORS(app)

# é¢˜å‹æ˜ å°„
QUESTION_TYPES = {
    0: "single",
    1: "multiple",
    3: "completion",
    4: "judgement"
}


class ModelClient:
    """
    ç»Ÿä¸€çš„AIæ¨¡å‹å®¢æˆ·ç«¯ï¼ˆæ”¯æŒå¤šæ¨¡å‹å’Œæ™ºèƒ½é€‰æ‹©ï¼‰
    
    åŠŸèƒ½ï¼š
        1. å¤šæ¨¡å‹æ”¯æŒï¼šDeepSeekã€è±†åŒ…ç­‰å¤šä¸ªå¤§è¯­è¨€æ¨¡å‹
        2. æ™ºèƒ½é€‰æ‹©ï¼šæ ¹æ®é¢˜ç›®å†…å®¹ï¼ˆæ–‡æœ¬/å›¾ç‰‡ï¼‰è‡ªåŠ¨é€‰æ‹©æœ€åˆé€‚çš„æ¨¡å‹
        3. æ€è€ƒæ¨¡å¼ï¼šæ”¯æŒæ·±åº¦æ¨ç†æ¨¡å¼ï¼Œæé«˜å¤æ‚é¢˜ç›®çš„å‡†ç¡®ç‡
        4. å›¾ç‰‡å¤„ç†ï¼šä¸‹è½½å¹¶è½¬æ¢å›¾ç‰‡ä¸ºbase64æ ¼å¼ä¾›æ¨¡å‹ä½¿ç”¨
        5. é‡è¯•æœºåˆ¶ï¼šè‡ªåŠ¨é‡è¯•å¤±è´¥çš„è¯·æ±‚ï¼Œæé«˜ç¨³å®šæ€§
    
    Attributes:
        provider (str): æ¨¡å‹æä¾›å•†ï¼ˆdeepseek/doubao/autoï¼‰
        enable_reasoning (bool): æ˜¯å¦å…¨å±€å¯ç”¨æ€è€ƒæ¨¡å¼
        is_auto_mode (bool): æ˜¯å¦ä¸ºæ™ºèƒ½é€‰æ‹©æ¨¡å¼
        clients (dict): æä¾›å•†åˆ°OpenAIå®¢æˆ·ç«¯çš„æ˜ å°„ï¼ˆä»…autoæ¨¡å¼ï¼‰
        models (dict): æä¾›å•†åˆ°æ¨¡å‹åç§°çš„æ˜ å°„ï¼ˆä»…autoæ¨¡å¼ï¼‰
    """
    
    def __init__(self, provider: str = MODEL_PROVIDER):
        """
        åˆå§‹åŒ–æ¨¡å‹å®¢æˆ·ç«¯
        
        Args:
            provider: æ¨¡å‹æä¾›å•† (deepseek/doubao/auto)
        """
        self.provider = provider.lower()
        self.enable_reasoning = ENABLE_REASONING
        self.reasoning_effort = REASONING_EFFORT
        self.auto_reasoning_for_multiple = AUTO_REASONING_FOR_MULTIPLE
        self.auto_reasoning_for_images = AUTO_REASONING_FOR_IMAGES
        
        # æ™ºèƒ½æ¨¡å¼ç›¸å…³
        self.is_auto_mode = (self.provider == 'auto')
        self.prefer_model = PREFER_MODEL.lower()
        self.image_model = IMAGE_MODEL.lower()
        
        # å­˜å‚¨å¤šä¸ªå®¢æˆ·ç«¯ï¼ˆç”¨äºautoæ¨¡å¼ï¼‰
        self.clients = {}
        self.models = {}
        
        # é…ç½®HTTPå®¢æˆ·ç«¯ï¼ˆä»£ç†ã€è¶…æ—¶ç­‰ï¼‰
        import httpx
        
        # è®¾ç½®è¶…æ—¶
        try:
            timeout = httpx.Timeout(TIMEOUT, connect=10.0)
        except Exception:
            # å…¼å®¹æ—§ç‰ˆæœ¬httpx
            timeout = TIMEOUT
        
        # åˆ›å»ºhttpxå®¢æˆ·ç«¯ï¼ˆæœ€ç®€æ–¹å¼ï¼Œé¿å…ç‰ˆæœ¬å…¼å®¹é—®é¢˜ï¼‰
        if HTTP_PROXY or HTTPS_PROXY:
            # æœ‰ä»£ç†æ—¶é…ç½®ä»£ç†
            proxies = HTTPS_PROXY if HTTPS_PROXY else HTTP_PROXY
            logger.info(f"âœ… å·²é…ç½®ä»£ç†: {proxies}")
            try:
                http_client = httpx.Client(timeout=timeout, proxies=proxies)
            except TypeError:
                # å¦‚æœhttpxç‰ˆæœ¬ä¸æ”¯æŒproxieså‚æ•°ï¼Œä½¿ç”¨ç¯å¢ƒå˜é‡æ–¹å¼
                import os
                if HTTPS_PROXY:
                    os.environ['HTTPS_PROXY'] = HTTPS_PROXY
                if HTTP_PROXY:
                    os.environ['HTTP_PROXY'] = HTTP_PROXY
                http_client = httpx.Client(timeout=timeout)
        else:
            # æ— ä»£ç†æ—¶ç›´æ¥åˆ›å»º
            http_client = httpx.Client(timeout=timeout)
        
        # æ ¹æ®provideråˆå§‹åŒ–å¯¹åº”çš„å®¢æˆ·ç«¯
        if self.provider == 'auto':
            # æ™ºèƒ½æ¨¡å¼ï¼šåˆå§‹åŒ–æ‰€æœ‰å·²é…ç½®çš„å®¢æˆ·ç«¯
            logger.info("ğŸ¤– å¯ç”¨æ™ºèƒ½æ¨¡å‹é€‰æ‹©æ¨¡å¼")
            
            # å°è¯•åˆå§‹åŒ–DeepSeek
            if DEEPSEEK_API_KEY:
                try:
                    self.clients['deepseek'] = OpenAI(
                        api_key=DEEPSEEK_API_KEY,
                        base_url=DEEPSEEK_BASE_URL,
                        http_client=http_client,
                        max_retries=MAX_RETRIES
                    )
                    self.models['deepseek'] = DEEPSEEK_MODEL
                    logger.info("âœ… DeepSeekå®¢æˆ·ç«¯å·²å°±ç»ª")
                except Exception as e:
                    logger.warning(f"âš ï¸  DeepSeekåˆå§‹åŒ–å¤±è´¥: {str(e)}")
            else:
                logger.warning("âš ï¸  DeepSeek APIå¯†é’¥æœªé…ç½®ï¼Œçº¯æ–‡æœ¬é¢˜ç›®å¯èƒ½æ— æ³•ä½¿ç”¨")
            
            # å°è¯•åˆå§‹åŒ–è±†åŒ…
            if DOUBAO_API_KEY and DOUBAO_MODEL:
                try:
                    self.clients['doubao'] = OpenAI(
                        api_key=DOUBAO_API_KEY,
                        base_url=DOUBAO_BASE_URL,
                        http_client=http_client,
                        max_retries=MAX_RETRIES
                    )
                    self.models['doubao'] = DOUBAO_MODEL
                    logger.info("âœ… è±†åŒ…å®¢æˆ·ç«¯å·²å°±ç»ª")
                except Exception as e:
                    logger.warning(f"âš ï¸  è±†åŒ…åˆå§‹åŒ–å¤±è´¥: {str(e)}")
            else:
                logger.warning("âš ï¸  è±†åŒ… APIå¯†é’¥æˆ–æ¨¡å‹IDæœªé…ç½®ï¼Œå›¾ç‰‡é¢˜ç›®å¯èƒ½æ— æ³•ä½¿ç”¨")
            
            if not self.clients:
                raise ValueError("æ™ºèƒ½æ¨¡å¼éœ€è¦è‡³å°‘é…ç½®ä¸€ä¸ªæ¨¡å‹çš„APIå¯†é’¥ï¼ˆDeepSeekæˆ–è±†åŒ…ï¼‰")
            
            # è®¾ç½®é»˜è®¤å®¢æˆ·ç«¯å’Œæ¨¡å‹ï¼ˆç”¨äºæ˜¾ç¤ºï¼‰
            if self.prefer_model in self.clients:
                self.client = self.clients[self.prefer_model]
                self.model = self.models[self.prefer_model]
            else:
                # ä½¿ç”¨ç¬¬ä¸€ä¸ªå¯ç”¨çš„å®¢æˆ·ç«¯
                first_provider = list(self.clients.keys())[0]
                self.client = self.clients[first_provider]
                self.model = self.models[first_provider]
            
            logger.info(f"âœ… æ™ºèƒ½æ¨¡å¼å·²å¯ç”¨ - å·²é…ç½® {len(self.clients)} ä¸ªæ¨¡å‹")
            logger.info(f"   é»˜è®¤é¦–é€‰: {self.prefer_model} (çº¯æ–‡æœ¬)")
            logger.info(f"   å›¾ç‰‡æ¨¡å‹: {self.image_model}")
            
        elif self.provider == 'deepseek':
            if not DEEPSEEK_API_KEY:
                logger.warning("âš ï¸  DeepSeek APIå¯†é’¥æœªé…ç½®")
            
            self.client = OpenAI(
                api_key=DEEPSEEK_API_KEY,
                base_url=DEEPSEEK_BASE_URL,
                http_client=http_client,
                max_retries=MAX_RETRIES
            )
            
            # å¦‚æœå¯ç”¨æ€è€ƒæ¨¡å¼ï¼Œä½¿ç”¨deepseek-reasoner
            if self.enable_reasoning:
                self.model = 'deepseek-reasoner'
                logger.info("âœ… DeepSeekæ€è€ƒæ¨¡å¼å·²å¯ç”¨ï¼ˆæœ€å¤§64K tokensï¼‰")
            else:
                self.model = DEEPSEEK_MODEL
                logger.info("âœ… DeepSeekæ™®é€šæ¨¡å¼ï¼ˆæœ€å¤§8K tokensï¼‰")
            
        elif self.provider == 'doubao':
            if not DOUBAO_API_KEY:
                logger.warning("âš ï¸  è±†åŒ… APIå¯†é’¥æœªé…ç½®")
            
            self.client = OpenAI(
                api_key=DOUBAO_API_KEY,
                base_url=DOUBAO_BASE_URL,
                http_client=http_client,
                max_retries=MAX_RETRIES
            )
            self.model = DOUBAO_MODEL
            
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ¨¡å‹æä¾›å•†: {provider}")
        
        if not self.is_auto_mode:
            logger.info(f"âœ… å·²åˆå§‹åŒ– {self.provider} å®¢æˆ·ç«¯ï¼Œæ¨¡å‹: {self.model}, è¶…æ—¶: {TIMEOUT}ç§’, æœ€å¤§é‡è¯•: {MAX_RETRIES}æ¬¡")
    
    def download_image_as_base64(self, image_url: str) -> Optional[str]:
        """
        ä¸‹è½½å›¾ç‰‡å¹¶è½¬æ¢ä¸ºbase64æ ¼å¼ï¼ˆä½¿ç”¨ä¼ªè£…è¯·æ±‚å¤´ï¼‰
        
        Args:
            image_url: å›¾ç‰‡URL
            
        Returns:
            base64ç¼–ç çš„data URIï¼Œæ ¼å¼: data:image/xxx;base64,xxxxx
            å¦‚æœä¸‹è½½å¤±è´¥è¿”å›None
        """
        try:
            import httpx
            
            # ä¼ªè£…æˆæµè§ˆå™¨çš„è¯·æ±‚å¤´
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                'Referer': 'https://mooc1.chaoxing.com/',
                'Accept': 'image/avif,image/webp,image/apng,image/svg+xml,image/*,*/*;q=0.8',
                'Accept-Encoding': 'gzip, deflate, br',
                'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
                'Connection': 'keep-alive',
                'Sec-Fetch-Dest': 'image',
                'Sec-Fetch-Mode': 'no-cors',
                'Sec-Fetch-Site': 'cross-site',
            }
            
            # åˆ›å»ºHTTPå®¢æˆ·ç«¯ï¼ˆå¸¦è¶…æ—¶ï¼‰
            with httpx.Client(timeout=10.0, follow_redirects=True) as client:
                logger.info(f"ğŸ“¥ ä¸‹è½½å›¾ç‰‡: {image_url}")
                response = client.get(image_url, headers=headers)
                response.raise_for_status()
                
                # è·å–å›¾ç‰‡å†…å®¹
                image_data = response.content
                
                # æ ¹æ®Content-Typeåˆ¤æ–­å›¾ç‰‡ç±»å‹
                content_type = response.headers.get('Content-Type', 'image/jpeg')
                if 'image/' not in content_type:
                    content_type = 'image/jpeg'  # é»˜è®¤JPEG
                
                # è½¬æ¢ä¸ºbase64
                base64_data = base64.b64encode(image_data).decode('utf-8')
                data_uri = f"data:{content_type};base64,{base64_data}"
                
                logger.info(f"âœ… å›¾ç‰‡ä¸‹è½½æˆåŠŸï¼Œå¤§å°: {len(image_data)} bytes")
                return data_uri
                
        except Exception as e:
            logger.error(f"âŒ å›¾ç‰‡ä¸‹è½½å¤±è´¥: {image_url}")
            logger.error(f"   é”™è¯¯: {str(e)}")
            return None
    
    def chat(self, prompt: str, force_reasoning: bool = False, image_urls: List[str] = None) -> Tuple[Optional[str], Optional[str], Optional[Dict[str, int]]]:
        """
        è°ƒç”¨æ¨¡å‹è¿›è¡Œå¯¹è¯ï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼Œæ”¯æŒæ™ºèƒ½æ¨¡å‹é€‰æ‹©ï¼‰
        
        Args:
            prompt: æç¤ºè¯
            force_reasoning: æ˜¯å¦å¼ºåˆ¶å¯ç”¨æ€è€ƒæ¨¡å¼ï¼ˆç”¨äºå¤šé€‰é¢˜ç­‰ï¼‰
            image_urls: å›¾ç‰‡URLåˆ—è¡¨ï¼ˆä»…è±†åŒ…æ”¯æŒï¼‰
        
        Returns:
            (æ¨ç†è¿‡ç¨‹, æœ€ç»ˆç­”æ¡ˆ, tokenä½¿ç”¨é‡) æˆ– (None, ç­”æ¡ˆ, tokenä½¿ç”¨é‡)
            tokenä½¿ç”¨é‡æ ¼å¼: {"prompt_tokens": int, "completion_tokens": int, "total_tokens": int}
        """
        # ç¡®å®šæ˜¯å¦ä½¿ç”¨æ€è€ƒæ¨¡å¼
        use_reasoning = self.enable_reasoning or force_reasoning
        
        # æ™ºèƒ½é€‰æ‹©æ¨¡å‹ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if self.is_auto_mode:
            selected_provider, selected_client, selected_model = self._select_model(image_urls)
            if not selected_client:
                return None, None, None
        else:
            selected_provider = self.provider
            selected_client = self.client
            selected_model = self.model
        
        # æ ¹æ®æ˜¯å¦ä½¿ç”¨æ€è€ƒæ¨¡å¼é€‰æ‹©æ¨¡å‹å’Œmax_tokensé™åˆ¶
        if selected_provider == 'deepseek':
            if use_reasoning and not self.enable_reasoning:
                # ä¸´æ—¶å¯ç”¨æ€è€ƒæ¨¡å¼ï¼Œéœ€è¦åˆ‡æ¢åˆ°reasoneræ¨¡å‹
                actual_model = 'deepseek-reasoner'
                # ä½¿ç”¨æ€è€ƒæ¨¡å¼ä¸“ç”¨çš„ max_tokensï¼ˆæ”¯æŒæ›´å¤§çš„è¾“å‡ºï¼‰
                max_tokens_limit = REASONING_MAX_TOKENS
                logger.debug(f"æ€è€ƒæ¨¡å¼ä½¿ç”¨ max_tokens: {max_tokens_limit}")
            elif self.enable_reasoning:
                # å…¨å±€å¯ç”¨æ€è€ƒæ¨¡å¼
                actual_model = selected_model
                max_tokens_limit = REASONING_MAX_TOKENS
                logger.debug(f"æ€è€ƒæ¨¡å¼ä½¿ç”¨ max_tokens: {max_tokens_limit}")
            else:
                # æ™®é€šæ¨¡å¼
                actual_model = selected_model
                max_tokens_limit = MAX_TOKENS
        else:
            # è±†åŒ…æ¨¡å‹
            actual_model = selected_model
            if use_reasoning:
                # è±†åŒ…çš„æ€è€ƒæ¨¡å¼ä¹Ÿä½¿ç”¨æ›´å¤§çš„ token
                max_tokens_limit = REASONING_MAX_TOKENS
                logger.debug(f"è±†åŒ…æ€è€ƒæ¨¡å¼ä½¿ç”¨ max_tokens: {max_tokens_limit}")
            else:
                max_tokens_limit = MAX_TOKENS
        
        # æ„å»ºæ¶ˆæ¯ï¼ˆæ”¯æŒåŠ¨æ€åˆ‡æ¢ï¼šé¦–æ¬¡å°è¯•ä½¿ç”¨å›¾ç‰‡ï¼Œå¤±è´¥åé™çº§ä¸ºçº¯æ–‡æœ¬ï¼‰
        # æ³¨æ„ï¼šåœ¨æ™ºèƒ½æ¨¡å¼ä¸‹ï¼Œselected_provider å·²ç»ç¡®å®šï¼Œæ‰€ä»¥ç”¨å®ƒåˆ¤æ–­è€Œä¸æ˜¯ self.provider
        use_images = selected_provider == 'doubao' and image_urls
        
        # å¦‚æœéœ€è¦ä½¿ç”¨å›¾ç‰‡ï¼Œå…ˆä¸‹è½½å¹¶è½¬æ¢ä¸ºbase64
        base64_images = []
        if use_images and image_urls:
            logger.info(f"ğŸ”„ å¼€å§‹ä¸‹è½½ {len(image_urls)} å¼ å›¾ç‰‡...")
            for img_url in image_urls:
                base64_data = self.download_image_as_base64(img_url)
                if base64_data:
                    base64_images.append(base64_data)
                else:
                    logger.warning(f"âš ï¸  è·³è¿‡æ— æ³•ä¸‹è½½çš„å›¾ç‰‡: {img_url}")
            
            if not base64_images:
                logger.warning("âš ï¸  æ‰€æœ‰å›¾ç‰‡ä¸‹è½½å¤±è´¥ï¼Œå°†ä½¿ç”¨çº¯æ–‡æœ¬æ¨¡å¼")
                use_images = False
            else:
                logger.info(f"âœ… æˆåŠŸä¸‹è½½ {len(base64_images)}/{len(image_urls)} å¼ å›¾ç‰‡")
        
        # æ„å»ºæ¶ˆæ¯çš„å‡½æ•°
        def build_messages(use_image_urls: bool):
            if use_image_urls and selected_provider == 'doubao' and base64_images:
                # è±†åŒ…æ”¯æŒå›¾ç‰‡è¾“å…¥ï¼ˆå¤šæ¨¡æ€ï¼‰- ä½¿ç”¨base64æ ¼å¼
                user_content = []
                # å…ˆæ·»åŠ å›¾ç‰‡ï¼ˆä½¿ç”¨base64æ ¼å¼ï¼‰
                for base64_data in base64_images:
                    user_content.append({
                        "type": "image_url",
                        "image_url": {"url": base64_data}  # ç›´æ¥ä½¿ç”¨data URI
                    })
                # å†æ·»åŠ æ–‡æœ¬
                user_content.append({"type": "text", "text": prompt})
                
                return [
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šã€ä¸¥è°¨çš„ç­”é¢˜åŠ©æ‰‹ã€‚ä½ å¿…é¡»æ ¹æ®é¢˜ç›®ã€å›¾ç‰‡å’Œé€‰é¡¹ç»™å‡ºå‡†ç¡®çš„ç­”æ¡ˆï¼Œä¸¥æ ¼æŒ‰ç…§è¦æ±‚çš„æ ¼å¼è¾“å‡ºï¼Œä¸è¦æœ‰ä»»ä½•å¤šä½™çš„å†…å®¹ã€‚"},
                    {"role": "user", "content": user_content}
                ]
            else:
                # çº¯æ–‡æœ¬æ ¼å¼ï¼ˆDeepSeekæˆ–æ— å›¾ç‰‡ï¼‰
                if image_urls and selected_provider == 'deepseek':
                    logger.warning("âš ï¸  DeepSeekä¸æ”¯æŒå›¾ç‰‡è¾“å…¥ï¼Œå·²å¿½ç•¥å›¾ç‰‡")
                return [
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šã€ä¸¥è°¨çš„ç­”é¢˜åŠ©æ‰‹ã€‚ä½ å¿…é¡»æ ¹æ®é¢˜ç›®å’Œé€‰é¡¹ç»™å‡ºå‡†ç¡®çš„ç­”æ¡ˆï¼Œä¸¥æ ¼æŒ‰ç…§è¦æ±‚çš„æ ¼å¼è¾“å‡ºï¼Œä¸è¦æœ‰ä»»ä½•å¤šä½™çš„å†…å®¹ã€‚"},
                    {"role": "user", "content": prompt}
                ]
        
        # æ„å»ºè¯·æ±‚å‚æ•°
        request_params = {
            "model": actual_model,
            "messages": build_messages(use_images),
            "temperature": TEMPERATURE,
            "max_tokens": max_tokens_limit,
            "top_p": TOP_P,
            "stream": False
        }
        
        # è±†åŒ…æ¨¡å‹æ”¯æŒreasoning_effort
        if selected_provider == 'doubao' and use_reasoning:
            request_params["reasoning_effort"] = self.reasoning_effort
        
        reasoning_status = "ï¼ˆæ€è€ƒæ¨¡å¼ï¼‰" if use_reasoning else ""
        image_status = f"ï¼Œ{len(base64_images)}å¼ å›¾ç‰‡(base64)" if use_images and base64_images else ""
        auto_status = "ğŸ¤–æ™ºèƒ½é€‰æ‹©-" if self.is_auto_mode else ""
        logger.info(f"è°ƒç”¨{auto_status}{selected_provider}æ¨¡å‹ - {actual_model}{reasoning_status}{image_status}")
        
        # é‡è¯•æœºåˆ¶
        last_error = None
        retry_without_images = False  # æ ‡è®°æ˜¯å¦åº”è¯¥ä¸ä½¿ç”¨å›¾ç‰‡é‡è¯•
        
        for attempt in range(1, MAX_RETRIES + 1):
            try:
                # å¦‚æœä¹‹å‰æ£€æµ‹åˆ°å›¾ç‰‡URLé—®é¢˜ï¼Œä½¿ç”¨çº¯æ–‡æœ¬æ¨¡å¼
                if retry_without_images:
                    request_params["messages"] = build_messages(False)
                    logger.info("ğŸ”„ ä½¿ç”¨çº¯æ–‡æœ¬æ¨¡å¼é‡è¯•ï¼ˆä¸ä½¿ç”¨å›¾ç‰‡ï¼‰")
                
                # è°ƒç”¨APIï¼ˆä½¿ç”¨é€‰å®šçš„å®¢æˆ·ç«¯ï¼‰
                response = selected_client.chat.completions.create(**request_params)
                
                # æå–æ¨ç†è¿‡ç¨‹å’Œç­”æ¡ˆ
                reasoning_content = None
                if hasattr(response.choices[0].message, 'reasoning_content'):
                    reasoning_content = response.choices[0].message.reasoning_content
                    if reasoning_content:
                        logger.info(f"æ¨ç†è¿‡ç¨‹: {reasoning_content[:100]}...")
                
                answer = response.choices[0].message.content.strip()
                logger.info(f"æ¨¡å‹è¿”å›ç­”æ¡ˆ: {answer}")
                
                # æå–tokenä½¿ç”¨é‡
                usage_info = None
                if hasattr(response, 'usage'):
                    usage_info = {
                        'prompt_tokens': response.usage.prompt_tokens if hasattr(response.usage, 'prompt_tokens') else 0,
                        'completion_tokens': response.usage.completion_tokens if hasattr(response.usage, 'completion_tokens') else 0,
                        'total_tokens': response.usage.total_tokens if hasattr(response.usage, 'total_tokens') else 0
                    }
                    logger.info(f"ğŸ’° Tokenä½¿ç”¨é‡: è¾“å…¥={usage_info['prompt_tokens']}, è¾“å‡º={usage_info['completion_tokens']}, æ€»è®¡={usage_info['total_tokens']}")
                else:
                    logger.warning("âš ï¸  å“åº”ä¸­æ²¡æœ‰usageä¿¡æ¯ï¼Œtokenç”¨é‡å°†è®°å½•ä¸º0")
                    usage_info = {'prompt_tokens': 0, 'completion_tokens': 0, 'total_tokens': 0}
                
                return reasoning_content, answer, usage_info
                
            except Exception as e:
                last_error = e
                error_msg = str(e)
                error_type = type(e).__name__
                
                # è®°å½•è¯¦ç»†é”™è¯¯ä¿¡æ¯
                logger.error(f"APIè°ƒç”¨å¤±è´¥ (å°è¯• {attempt}/{MAX_RETRIES}): {error_type}: {error_msg[:300]}")
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯å‚æ•°é”™è¯¯ï¼ˆ400ï¼‰ï¼Œè¿™ç§é”™è¯¯é‡è¯•ä¹Ÿæ²¡ç”¨
                is_param_error = (
                    "400" in error_msg or 
                    "Invalid" in error_msg or 
                    "invalid_request_error" in error_msg.lower() or
                    "max_tokens" in error_msg.lower()
                )
                
                if is_param_error:
                    logger.error(f"å‚æ•°é”™è¯¯ï¼ˆæ— éœ€é‡è¯•ï¼‰: {error_msg}")
                    print(f"\nâŒ APIå‚æ•°é”™è¯¯: {error_msg[:200]}")
                    if "max_tokens" in error_msg.lower():
                        print("ğŸ’¡ æç¤º: max_tokenså¿…é¡»åœ¨[1, 8192]èŒƒå›´å†…ï¼Œå·²è‡ªåŠ¨é™åˆ¶")
                    return None, None, None
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯å›¾ç‰‡ç›¸å…³çš„é”™è¯¯ï¼ˆå³ä½¿ä½¿ç”¨äº†base64ï¼Œä¹Ÿå¯èƒ½å› ä¸ºå›¾ç‰‡è¿‡å¤§æˆ–æ ¼å¼é—®é¢˜å¤±è´¥ï¼‰
                # å¦‚æœä½¿ç”¨äº†å›¾ç‰‡ä¸”å‡ºç°è¿æ¥/è¶…æ—¶é”™è¯¯ï¼Œä¸”æ˜¯ç¬¬ä¸€æ¬¡å°è¯•ï¼Œå°è¯•ä¸ä½¿ç”¨å›¾ç‰‡é‡è¯•
                is_image_error = (
                    "connection" in error_msg.lower() or
                    "Connection" in error_type or
                    "timeout" in error_msg.lower() or
                    "image" in error_msg.lower() or
                    "base64" in error_msg.lower()
                ) and base64_images  # åªæœ‰åœ¨å®é™…ä½¿ç”¨äº†å›¾ç‰‡æ—¶æ‰è€ƒè™‘æ˜¯å›¾ç‰‡é—®é¢˜
                
                # å¦‚æœæ˜¯å›¾ç‰‡ç›¸å…³é”™è¯¯ï¼Œä¸”æ˜¯ç¬¬ä¸€æ¬¡å°è¯•ï¼Œæ ‡è®°ä¸ºä¸ä½¿ç”¨å›¾ç‰‡é‡è¯•
                if is_image_error and attempt == 1 and selected_provider == 'doubao' and base64_images and not retry_without_images:
                    logger.warning(f"âš ï¸  æ£€æµ‹åˆ°å¯èƒ½çš„å›¾ç‰‡å¤„ç†é—®é¢˜")
                    logger.warning(f"   é”™è¯¯ç±»å‹: {error_type}")
                    logger.warning(f"   å·²å‘é€ {len(base64_images)} å¼ base64å›¾ç‰‡")
                    logger.warning(f"   å¯èƒ½åŸå› : 1) å›¾ç‰‡è¿‡å¤§ 2) å›¾ç‰‡æ ¼å¼ä¸æ”¯æŒ 3) ç½‘ç»œè¿æ¥é—®é¢˜")
                    print(f"\nâš ï¸  æ£€æµ‹åˆ°å›¾ç‰‡å¤„ç†é—®é¢˜ï¼Œå°†å°è¯•ä¸ä½¿ç”¨å›¾ç‰‡é‡è¯•...")
                    print(f"   é”™è¯¯ç±»å‹: {error_type}")
                    print(f"   å›¾ç‰‡æ•°é‡: {len(base64_images)} å¼ ")
                    
                    # æ ‡è®°ä¸ºä¸ä½¿ç”¨å›¾ç‰‡é‡è¯•
                    retry_without_images = True
                    # ç»§ç»­é‡è¯•ï¼Œä½†è¿™æ¬¡ä¸ä½¿ç”¨å›¾ç‰‡
                    continue
                
                # å¦‚æœæ˜¯æœ€åä¸€æ¬¡å°è¯•ï¼Œç›´æ¥è¿”å›å¤±è´¥
                if attempt >= MAX_RETRIES:
                    logger.error(f"æ¨¡å‹è°ƒç”¨å¤±è´¥ (å·²é‡è¯•{MAX_RETRIES}æ¬¡): {error_msg}")
                    print(f"\nâš ï¸  ç½‘ç»œé”™è¯¯ï¼Œå·²é‡è¯• {MAX_RETRIES} æ¬¡")
                    print(f"é”™è¯¯ç±»å‹: {error_type}")
                    print(f"é”™è¯¯ä¿¡æ¯: {error_msg[:200]}")
                    if "Connection" in error_msg or "timeout" in error_msg.lower():
                        print("ğŸ’¡ æç¤º: æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–é…ç½®HTTP_PROXY/HTTPS_PROXYç¯å¢ƒå˜é‡")
                        if image_urls:
                            print("ğŸ’¡ æç¤º: å›¾ç‰‡URLå¯èƒ½æ— æ³•è®¿é—®ï¼Œå·²å°è¯•ä¸ä½¿ç”¨å›¾ç‰‡")
                    return None, None, None
                
                # ç­‰å¾…åé‡è¯•ï¼ˆä»…å¯¹ç½‘ç»œé”™è¯¯ï¼‰
                wait_time = min(2 ** attempt, 10)  # æŒ‡æ•°é€€é¿ï¼Œæœ€å¤š10ç§’
                logger.warning(f"æ¨¡å‹è°ƒç”¨å¤±è´¥ (ç¬¬{attempt}æ¬¡å°è¯•)ï¼Œ{wait_time}ç§’åé‡è¯•: {error_msg[:100]}")
                print(f"âš ï¸  è¯·æ±‚å¤±è´¥ï¼Œ{wait_time}ç§’åé‡è¯• ({attempt}/{MAX_RETRIES})...")
                time.sleep(wait_time)
        
        # ç†è®ºä¸Šä¸ä¼šæ‰§è¡Œåˆ°è¿™é‡Œ
        logger.error(f"æ¨¡å‹è°ƒç”¨å¤±è´¥: {last_error}")
        return None, None, None
    
    def _select_model(self, image_urls: List[str] = None) -> Tuple[str, Optional[Any], Optional[str]]:
        """
        æ™ºèƒ½é€‰æ‹©æ¨¡å‹
        
        Args:
            image_urls: å›¾ç‰‡URLåˆ—è¡¨
        
        Returns:
            (provider, client, model) æˆ– (provider, None, None)
        """
        has_images = image_urls and len(image_urls) > 0
        
        if has_images:
            # æœ‰å›¾ç‰‡ï¼šä¼˜å…ˆä½¿ç”¨è±†åŒ…
            if self.image_model in self.clients:
                logger.info(f"ğŸ’¡ æ™ºèƒ½é€‰æ‹©: æ£€æµ‹åˆ°å›¾ç‰‡ï¼Œä½¿ç”¨ {self.image_model}")
                return self.image_model, self.clients[self.image_model], self.models[self.image_model]
            else:
                # è±†åŒ…æœªé…ç½®ï¼Œå°è¯•é™çº§
                logger.warning(f"âš ï¸  {self.image_model} æœªé…ç½®ï¼Œä½†é¢˜ç›®åŒ…å«å›¾ç‰‡")
                
                # å°è¯•ä½¿ç”¨å·²é…ç½®çš„å…¶ä»–æ¨¡å‹
                if self.clients:
                    fallback_provider = list(self.clients.keys())[0]
                    logger.warning(f"âš ï¸  é™çº§ä½¿ç”¨ {fallback_provider}ï¼ˆè¯¥æ¨¡å‹å¯èƒ½ä¸æ”¯æŒå›¾ç‰‡ï¼‰")
                    print(f"\nâš ï¸  è­¦å‘Š: {self.image_model} æœªé…ç½®ï¼Œé™çº§ä½¿ç”¨ {fallback_provider}")
                    print(f"   è¯¥æ¨¡å‹å¯èƒ½ä¸æ”¯æŒå›¾ç‰‡è¾“å…¥ï¼Œç­”é¢˜å‡†ç¡®ç‡å¯èƒ½é™ä½")
                    print(f"   å»ºè®®é…ç½® {self.image_model.upper()}_API_KEY ä»¥è·å¾—æœ€ä½³æ•ˆæœ\n")
                    return fallback_provider, self.clients[fallback_provider], self.models[fallback_provider]
                else:
                    logger.error("âŒ æ²¡æœ‰å¯ç”¨çš„æ¨¡å‹å®¢æˆ·ç«¯")
                    print("\nâŒ é”™è¯¯: æ²¡æœ‰å¯ç”¨çš„æ¨¡å‹å®¢æˆ·ç«¯")
                    print("   è¯·è‡³å°‘é…ç½®ä¸€ä¸ªæ¨¡å‹çš„APIå¯†é’¥\n")
                    return 'none', None, None
        else:
            # æ— å›¾ç‰‡ï¼šä¼˜å…ˆä½¿ç”¨é¦–é€‰æ¨¡å‹ï¼ˆé€šå¸¸æ˜¯DeepSeekï¼Œæˆæœ¬æ›´ä½ï¼‰
            if self.prefer_model in self.clients:
                logger.info(f"ğŸ’¡ æ™ºèƒ½é€‰æ‹©: çº¯æ–‡æœ¬é¢˜ç›®ï¼Œä½¿ç”¨ {self.prefer_model}ï¼ˆæˆæœ¬æ›´ä½ï¼‰")
                return self.prefer_model, self.clients[self.prefer_model], self.models[self.prefer_model]
            else:
                # é¦–é€‰æ¨¡å‹æœªé…ç½®ï¼Œä½¿ç”¨å…¶ä»–å¯ç”¨æ¨¡å‹
                if self.clients:
                    fallback_provider = list(self.clients.keys())[0]
                    logger.info(f"ğŸ’¡ {self.prefer_model} æœªé…ç½®ï¼Œä½¿ç”¨ {fallback_provider}")
                    return fallback_provider, self.clients[fallback_provider], self.models[fallback_provider]
                else:
                    logger.error("âŒ æ²¡æœ‰å¯ç”¨çš„æ¨¡å‹å®¢æˆ·ç«¯")
                    print("\nâŒ é”™è¯¯: æ²¡æœ‰å¯ç”¨çš„æ¨¡å‹å®¢æˆ·ç«¯")
                    print("   è¯·è‡³å°‘é…ç½®ä¸€ä¸ªæ¨¡å‹çš„APIå¯†é’¥\n")
                    return 'none', None, None


class PromptBuilder:
    """
    æ™ºèƒ½Promptæ„å»ºå™¨ï¼šæ ¹æ®é¢˜å‹ç”Ÿæˆä¼˜åŒ–çš„æç¤ºè¯
    
    åŠŸèƒ½ï¼š
        ä¸ºä¸åŒé¢˜å‹ï¼ˆå•é€‰ã€å¤šé€‰ã€åˆ¤æ–­ã€å¡«ç©ºï¼‰ç”Ÿæˆä¸“é—¨ä¼˜åŒ–çš„æç¤ºè¯ï¼Œ
        ç¡®ä¿AIæ¨¡å‹èƒ½å¤Ÿå‡†ç¡®ç†è§£é¢˜ç›®è¦æ±‚å¹¶è¿”å›æ­£ç¡®æ ¼å¼çš„ç­”æ¡ˆã€‚
    
    è®¾è®¡åŸåˆ™ï¼š
        1. æ¸…æ™°çš„é¢˜ç›®ç±»å‹è¯´æ˜
        2. æ˜ç¡®çš„å›ç­”æ ¼å¼è¦æ±‚
        3. å…·ä½“çš„ç¤ºä¾‹æ¼”ç¤º
        4. é¿å…AIæ·»åŠ é¢å¤–çš„è§£é‡Š
    """
    
    @staticmethod
    def build_prompt(question: str, options: List[str], q_type: str) -> str:
        """æ ¹æ®é¢˜å‹æ„å»ºprompt"""
        
        if q_type == "single":
            return PromptBuilder._build_single_choice_prompt(question, options)
        elif q_type == "multiple":
            return PromptBuilder._build_multiple_choice_prompt(question, options)
        elif q_type == "judgement":
            return PromptBuilder._build_judgement_prompt(question, options)
        elif q_type == "completion":
            return PromptBuilder._build_completion_prompt(question)
        else:
            return PromptBuilder._build_default_prompt(question, options)
    
    @staticmethod
    def _build_single_choice_prompt(question: str, options: List[str]) -> str:
        """æ„å»ºå•é€‰é¢˜prompt"""
        options_text = "\n".join([f"{chr(65+i)}. {opt}" for i, opt in enumerate(options)])
        
        return f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„åœ¨çº¿è€ƒè¯•ç­”é¢˜åŠ©æ‰‹ï¼Œè¯·ä¸¥æ ¼æŒ‰ç…§è¦æ±‚å›ç­”ã€‚

ã€é¢˜ç›®ç±»å‹ã€‘å•é€‰é¢˜ï¼ˆåªèƒ½é€‰æ‹©ä¸€ä¸ªæ­£ç¡®ç­”æ¡ˆï¼‰

ã€é¢˜ç›®ã€‘
{question}

ã€é€‰é¡¹ã€‘
{options_text}

ã€å›ç­”è¦æ±‚ã€‘
1. ä»”ç»†åˆ†æé¢˜ç›®å’Œæ‰€æœ‰é€‰é¡¹
2. åªé€‰æ‹©ä¸€ä¸ªæœ€æ­£ç¡®çš„ç­”æ¡ˆ
3. å¿…é¡»ä»ç»™å®šçš„é€‰é¡¹ä¸­é€‰æ‹©ï¼Œä¸èƒ½è‡ªå·±ç¼–é€ 
4. å›ç­”æ ¼å¼ï¼šç›´æ¥è¾“å‡ºé€‰é¡¹å†…å®¹ï¼Œä¸è¦åŒ…å«Aã€Bã€Cç­‰æ ‡è¯†ç¬¦
5. åªè¾“å‡ºç­”æ¡ˆå†…å®¹ï¼Œä¸è¦æœ‰ä»»ä½•è§£é‡Šã€åˆ†ææˆ–é¢å¤–æ–‡å­—

ã€ç¤ºä¾‹ã€‘
å¦‚æœæ­£ç¡®ç­”æ¡ˆæ˜¯é€‰é¡¹"åŒ—äº¬"ï¼Œåˆ™åªè¾“å‡ºï¼šåŒ—äº¬

ç°åœ¨è¯·å›ç­”ä¸Šè¿°é¢˜ç›®ï¼š"""

    @staticmethod
    def _build_multiple_choice_prompt(question: str, options: List[str]) -> str:
        """æ„å»ºå¤šé€‰é¢˜prompt"""
        options_text = "\n".join([f"{chr(65+i)}. {opt}" for i, opt in enumerate(options)])
        
        return f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„åœ¨çº¿è€ƒè¯•ç­”é¢˜åŠ©æ‰‹ï¼Œè¯·ä¸¥æ ¼æŒ‰ç…§è¦æ±‚å›ç­”ã€‚

ã€é¢˜ç›®ç±»å‹ã€‘å¤šé€‰é¢˜ï¼ˆå¯èƒ½æœ‰å¤šä¸ªæ­£ç¡®ç­”æ¡ˆï¼‰

ã€é¢˜ç›®ã€‘
{question}

ã€é€‰é¡¹ã€‘
{options_text}

ã€å›ç­”è¦æ±‚ã€‘
1. ä»”ç»†åˆ†æé¢˜ç›®ï¼Œæ‰¾å‡ºæ‰€æœ‰æ­£ç¡®çš„é€‰é¡¹
2. å¤šé€‰é¢˜é€šå¸¸æœ‰2ä¸ªæˆ–ä»¥ä¸Šçš„æ­£ç¡®ç­”æ¡ˆ
3. å¿…é¡»ä»ç»™å®šçš„é€‰é¡¹ä¸­é€‰æ‹©ï¼Œä¸èƒ½è‡ªå·±ç¼–é€ 
4. å¤šä¸ªç­”æ¡ˆä¹‹é—´ç”¨äº•å·#åˆ†éš”
5. å›ç­”æ ¼å¼ï¼šé€‰é¡¹1#é€‰é¡¹2#é€‰é¡¹3ï¼ˆä¸è¦åŒ…å«Aã€Bã€Cç­‰æ ‡è¯†ç¬¦ï¼‰
6. åªè¾“å‡ºç­”æ¡ˆå†…å®¹ï¼Œä¸è¦æœ‰ä»»ä½•è§£é‡Šã€åˆ†ææˆ–é¢å¤–æ–‡å­—

ã€ç¤ºä¾‹ã€‘
å¦‚æœæ­£ç¡®ç­”æ¡ˆæ˜¯"åŒ—äº¬"å’Œ"ä¸Šæµ·"ä¸¤ä¸ªé€‰é¡¹ï¼Œåˆ™è¾“å‡ºï¼šåŒ—äº¬#ä¸Šæµ·

ç°åœ¨è¯·å›ç­”ä¸Šè¿°é¢˜ç›®ï¼š"""

    @staticmethod
    def _build_judgement_prompt(question: str, options: List[str]) -> str:
        """æ„å»ºåˆ¤æ–­é¢˜prompt"""
        return f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„åœ¨çº¿è€ƒè¯•ç­”é¢˜åŠ©æ‰‹ï¼Œè¯·ä¸¥æ ¼æŒ‰ç…§è¦æ±‚å›ç­”ã€‚

ã€é¢˜ç›®ç±»å‹ã€‘åˆ¤æ–­é¢˜ï¼ˆåˆ¤æ–­å¯¹é”™/æ˜¯å¦ï¼‰

ã€é¢˜ç›®ã€‘
{question}

ã€å¯é€‰ç­”æ¡ˆã€‘
{chr(10).join(options) if options else "æ­£ç¡® / é”™è¯¯"}

ã€å›ç­”è¦æ±‚ã€‘
1. ä»”ç»†åˆ†æé¢˜ç›®é™ˆè¿°æ˜¯å¦æ­£ç¡®
2. å¿…é¡»ä»ç»™å®šçš„é€‰é¡¹ä¸­é€‰æ‹©ï¼ˆå¦‚ï¼šæ­£ç¡®/é”™è¯¯ã€å¯¹/é”™ã€æ˜¯/å¦ã€âˆš/Ã—ç­‰ï¼‰
3. åªè¾“å‡ºä¸€ä¸ªåˆ¤æ–­ç»“æœ
4. ä¸è¦æœ‰ä»»ä½•è§£é‡Šã€åˆ†ææˆ–é¢å¤–æ–‡å­—

ã€ç¤ºä¾‹ã€‘
å¦‚æœé¢˜ç›®é™ˆè¿°æ­£ç¡®ï¼Œä¸”é€‰é¡¹ä¸­æœ‰"æ­£ç¡®"ï¼Œåˆ™è¾“å‡ºï¼šæ­£ç¡®

ç°åœ¨è¯·åˆ¤æ–­ä¸Šè¿°é¢˜ç›®ï¼š"""

    @staticmethod
    def _build_completion_prompt(question: str) -> str:
        """æ„å»ºå¡«ç©ºé¢˜prompt"""
        return f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„åœ¨çº¿è€ƒè¯•ç­”é¢˜åŠ©æ‰‹ï¼Œè¯·ä¸¥æ ¼æŒ‰ç…§è¦æ±‚å›ç­”ã€‚

ã€é¢˜ç›®ç±»å‹ã€‘å¡«ç©ºé¢˜

ã€é¢˜ç›®ã€‘
{question}

ã€å›ç­”è¦æ±‚ã€‘
1. ä»”ç»†ç†è§£é¢˜ç›®è¦æ±‚
2. ç»™å‡ºå‡†ç¡®ã€ç®€æ´çš„ç­”æ¡ˆ
3. å¦‚æœæœ‰å¤šä¸ªç©ºï¼Œç­”æ¡ˆä¹‹é—´ç”¨äº•å·#åˆ†éš”
4. ç­”æ¡ˆè¦å…·ä½“ã€å‡†ç¡®ï¼Œé¿å…æ¨¡ç³Šè¡¨è¿°
5. åªè¾“å‡ºç­”æ¡ˆå†…å®¹ï¼Œä¸è¦æœ‰åºå·ã€è§£é‡Šæˆ–é¢å¤–æ–‡å­—

ã€ç¤ºä¾‹ã€‘
- å•ç©ºé¢˜ï¼šå¦‚æœç­”æ¡ˆæ˜¯"åŒ—äº¬"ï¼Œåˆ™è¾“å‡ºï¼šåŒ—äº¬
- å¤šç©ºé¢˜ï¼šå¦‚æœç­”æ¡ˆæ˜¯"æ°¢"å’Œ"æ°§"ï¼Œåˆ™è¾“å‡ºï¼šæ°¢#æ°§

ç°åœ¨è¯·å›ç­”ä¸Šè¿°å¡«ç©ºé¢˜ï¼š"""

    @staticmethod
    def _build_default_prompt(question: str, options: List[str]) -> str:
        """æ„å»ºé»˜è®¤prompt"""
        options_text = "\n".join([f"- {opt}" for opt in options]) if options else "æ— å›ºå®šé€‰é¡¹"
        
        return f"""è¯·å›ç­”ä»¥ä¸‹é—®é¢˜ï¼š

ã€é¢˜ç›®ã€‘
{question}

ã€é€‰é¡¹ã€‘
{options_text}

ã€è¦æ±‚ã€‘
1. ç»™å‡ºå‡†ç¡®çš„ç­”æ¡ˆ
2. å¦‚æœæœ‰å¤šä¸ªç­”æ¡ˆï¼Œç”¨#åˆ†éš”
3. åªè¾“å‡ºç­”æ¡ˆï¼Œä¸è¦è§£é‡Š

è¯·å›ç­”ï¼š"""


class AnswerProcessor:
    """
    ç­”æ¡ˆå¤„ç†å™¨ï¼šæ¸…æ´—å’Œæ ‡å‡†åŒ–AIè¿”å›çš„ç­”æ¡ˆ
    
    ç­–ç•¥ï¼š
        - ä¿å®ˆæ¸…æ´—ï¼šåªç§»é™¤æ˜æ˜¾çš„æ ¼å¼æ ‡è®°ï¼Œé¿å…è¯¯åˆ æ­£ç¡®å†…å®¹
        - ä¼˜å…ˆåŒ¹é…ï¼šä¼˜å…ˆä½¿ç”¨åŸå§‹ç­”æ¡ˆåŒ¹é…é€‰é¡¹ï¼Œå†å°è¯•æ¸…æ´—ååŒ¹é…
        - æ™ºèƒ½åŒ¹é…ï¼šæ”¯æŒç²¾ç¡®åŒ¹é…ã€åŒ…å«åŒ¹é…ã€å»æ ‡ç‚¹åŒ¹é…ç­‰å¤šç§æ–¹å¼
    
    åŠŸèƒ½ï¼š
        1. æ¸…æ´—ç­”æ¡ˆï¼šç§»é™¤æ ¼å¼æ ‡è®°ï¼ˆmarkdownã€é€‰é¡¹æ ‡è¯†ç­‰ï¼‰
        2. åŒ¹é…é€‰é¡¹ï¼šå°†AIç­”æ¡ˆä¸é¢˜ç›®é€‰é¡¹è¿›è¡Œæ™ºèƒ½åŒ¹é…
        3. å¤„ç†ç‰¹æ®Šé¢˜å‹ï¼šé’ˆå¯¹åˆ¤æ–­é¢˜ã€å¤šé€‰é¢˜ç­‰è¿›è¡Œç‰¹æ®Šå¤„ç†
    """
    
    @staticmethod
    def _clean_answer(text: str) -> str:
        """
        è½»åº¦æ¸…æ´—ï¼Œåªç§»é™¤æ˜æ˜¾çš„æ ¼å¼æ ‡è®°
        ä¸è¿›è¡Œå†…å®¹ä¿®æ”¹ï¼Œé¿å…è¯¯åˆ æ­£ç¡®ç­”æ¡ˆ
        """
        if not text:
            return ""
        
        # åªç§»é™¤è¡Œé¦–çš„å¸¸è§å‰ç¼€ï¼ˆä¸å½±å“ç­”æ¡ˆå†…å®¹ï¼‰
        text = re.sub(r'^(ç­”æ¡ˆ[æ˜¯ä¸ºï¼š:]*|æ­£ç¡®ç­”æ¡ˆ[æ˜¯ä¸ºï¼š:]*|é€‰æ‹©[ï¼š:]*)', '', text)
        text = text.strip()
        
        # åªç§»é™¤markdownçš„æ ¼å¼ç¬¦å·ï¼ˆä¸æ˜¯å†…å®¹ï¼‰
        text = re.sub(r'[*`_]', '', text)
        text = text.strip()
        
        # åªç§»é™¤è¡Œé¦–çš„é€‰é¡¹æ ‡è¯†ï¼ˆå¦‚ "A. "ï¼‰ï¼Œä½†ä¸å½±å“ç­”æ¡ˆæœ¬èº«
        text = re.sub(r'^[A-Z][.ã€)]\s*', '', text)
        text = text.strip()
        
        return text
    
    @staticmethod
    def _match_option(answer: str, option: str) -> bool:
        """
        æ™ºèƒ½åŒ¹é…ç­”æ¡ˆå’Œé€‰é¡¹
        ä¼˜å…ˆç²¾ç¡®åŒ¹é…ï¼Œå†æ¨¡ç³ŠåŒ¹é…
        """
        answer = answer.strip()
        option = option.strip()
        
        if not answer or not option:
            return False
        
        # ç²¾ç¡®åŒ¹é…ï¼ˆå¿½ç•¥å¤§å°å†™å’Œç©ºæ ¼ï¼‰
        if answer.lower() == option.lower():
            return True
        
        # åŒ…å«åŒ¹é…
        if answer.lower() in option.lower() or option.lower() in answer.lower():
            return True
        
        # å»é™¤æ ‡ç‚¹ç¬¦å·ååŒ¹é…
        answer_clean = re.sub(r'[ã€‚ï¼Œã€ï¼›ï¼šï¼ï¼Ÿ\s]', '', answer)
        option_clean = re.sub(r'[ã€‚ï¼Œã€ï¼›ï¼šï¼ï¼Ÿ\s]', '', option)
        if answer_clean.lower() == option_clean.lower():
            return True
        
        return False
    
    @staticmethod
    def process_answer(raw_answer: str, q_type: str, options: List[str]) -> str:
        """
        å¤„ç†å’Œæ¸…æ´—ç­”æ¡ˆ - ä¿å®ˆç­–ç•¥ï¼Œä¼˜å…ˆä¿ç•™åŸå§‹ç­”æ¡ˆ
        """
        if not raw_answer:
            return ""
        
        raw_answer = raw_answer.strip()
        
        # æ ¹æ®é¢˜å‹å¤„ç†
        if q_type == "single":
            return AnswerProcessor._process_single_choice(raw_answer, options)
        elif q_type == "multiple":
            return AnswerProcessor._process_multiple_choice(raw_answer, options)
        elif q_type == "judgement":
            return AnswerProcessor._process_judgement(raw_answer, options)
        elif q_type == "completion":
            # å¡«ç©ºé¢˜åªåšè½»åº¦æ¸…æ´—ï¼Œä¿ç•™åŸå§‹ç­”æ¡ˆ
            cleaned = AnswerProcessor._clean_answer(raw_answer)
            return cleaned if cleaned else raw_answer
        else:
            # å…¶ä»–é¢˜å‹åªåšè½»åº¦æ¸…æ´—
            cleaned = AnswerProcessor._clean_answer(raw_answer)
            return cleaned if cleaned else raw_answer
    
    @staticmethod
    def _process_single_choice(raw_answer: str, options: List[str]) -> str:
        """å¤„ç†å•é€‰é¢˜ç­”æ¡ˆ - ä¼˜å…ˆä½¿ç”¨åŸå§‹ç­”æ¡ˆåŒ¹é…"""
        if not options:
            # æ²¡æœ‰é€‰é¡¹ï¼Œåªåšè½»åº¦æ¸…æ´—
            return AnswerProcessor._clean_answer(raw_answer)
        
        # ç¬¬ä¸€æ­¥ï¼šå°è¯•ç”¨åŸå§‹ç­”æ¡ˆç›´æ¥åŒ¹é…
        for option in options:
            if AnswerProcessor._match_option(raw_answer, option):
                return option.strip()
        
        # ç¬¬äºŒæ­¥ï¼šè½»åº¦æ¸…æ´—åå†åŒ¹é…
        cleaned = AnswerProcessor._clean_answer(raw_answer)
        if cleaned != raw_answer:  # å¦‚æœæ¸…æ´—æœ‰å˜åŒ–
            for option in options:
                if AnswerProcessor._match_option(cleaned, option):
                    return option.strip()
        
        # ç¬¬ä¸‰æ­¥ï¼šå¦‚æœè¿˜æ˜¯åŒ¹é…ä¸åˆ°ï¼Œè¿”å›æ¸…æ´—åçš„ç­”æ¡ˆ
        # è¿™æ ·è‡³å°‘ä¿ç•™äº†å¯èƒ½çš„æ­£ç¡®ç­”æ¡ˆï¼Œè€Œä¸æ˜¯ç©ºå­—ç¬¦ä¸²
        return cleaned if cleaned else raw_answer
    
    @staticmethod
    def _process_multiple_choice(raw_answer: str, options: List[str]) -> str:
        """å¤„ç†å¤šé€‰é¢˜ç­”æ¡ˆ - ä¼˜å…ˆä½¿ç”¨åŸå§‹ç­”æ¡ˆåŒ¹é…"""
        if not options:
            return AnswerProcessor._clean_answer(raw_answer)
        
        # åˆ†å‰²ç­”æ¡ˆï¼ˆæ”¯æŒå¤šç§åˆ†éš”ç¬¦ï¼‰
        raw_answers = re.split(r'[#;ï¼›ã€\n]', raw_answer)
        matched_options = []
        
        # ç¬¬ä¸€æ­¥ï¼šç”¨åŸå§‹ç­”æ¡ˆåŒ¹é…
        for raw_ans in raw_answers:
            raw_ans = raw_ans.strip()
            if not raw_ans:
                continue
            
            for option in options:
                if AnswerProcessor._match_option(raw_ans, option):
                    option_clean = option.strip()
                    if option_clean not in matched_options:
                        matched_options.append(option_clean)
                    break
        
        # ç¬¬äºŒæ­¥ï¼šå¦‚æœåŒ¹é…åˆ°äº†ï¼Œç›´æ¥è¿”å›
        if matched_options:
            return "#".join(matched_options)
        
        # ç¬¬ä¸‰æ­¥ï¼šå°è¯•æ¸…æ´—åå†åŒ¹é…
        cleaned_answers = [AnswerProcessor._clean_answer(ans) for ans in raw_answers if ans.strip()]
        for cleaned_ans in cleaned_answers:
            for option in options:
                if AnswerProcessor._match_option(cleaned_ans, option):
                    option_clean = option.strip()
                    if option_clean not in matched_options:
                        matched_options.append(option_clean)
                    break
        
        # ç¬¬å››æ­¥ï¼šè¿”å›åŒ¹é…ç»“æœæˆ–æ¸…æ´—åçš„åŸå§‹ç­”æ¡ˆ
        if matched_options:
            return "#".join(matched_options)
        else:
            # å¦‚æœåŒ¹é…ä¸åˆ°ï¼Œè¿”å›æ¸…æ´—åçš„ç­”æ¡ˆï¼ˆä¿ç•™å¯èƒ½çš„æ­£ç¡®ç­”æ¡ˆï¼‰
            cleaned = AnswerProcessor._clean_answer(raw_answer)
            return cleaned if cleaned else raw_answer
    
    @staticmethod
    def _process_judgement(raw_answer: str, options: List[str]) -> str:
        """å¤„ç†åˆ¤æ–­é¢˜ç­”æ¡ˆ - ä¿å®ˆç­–ç•¥"""
        if not options:
            return AnswerProcessor._clean_answer(raw_answer)
        
        raw_answer_lower = raw_answer.lower()
        
        # ç¬¬ä¸€æ­¥ï¼šç›´æ¥åŒ¹é…é€‰é¡¹
        for option in options:
            if AnswerProcessor._match_option(raw_answer, option):
                return option.strip()
        
        # ç¬¬äºŒæ­¥ï¼šæ¸…æ´—ååŒ¹é…
        cleaned = AnswerProcessor._clean_answer(raw_answer)
        if cleaned != raw_answer:
            for option in options:
                if AnswerProcessor._match_option(cleaned, option):
                    return option.strip()
        
        # ç¬¬ä¸‰æ­¥ï¼šè¯­ä¹‰åŒ¹é…ï¼ˆä¿å®ˆï¼‰
        # åªåœ¨ä¸åŒ¹é…çš„æƒ…å†µä¸‹æ‰è¿›è¡Œè¯­ä¹‰åˆ¤æ–­
        cleaned_lower = cleaned.lower()
        
        # åˆ¤æ–­"æ­£ç¡®"å€¾å‘
        positive_words = ['æ­£ç¡®', 'å¯¹', 'true', 'âˆš', 'æ˜¯', 'yes', 'æˆç«‹']
        negative_words = ['é”™è¯¯', 'é”™', 'false', 'Ã—', 'å¦', 'no', 'ä¸æˆç«‹']
        
        has_positive = any(word in cleaned_lower for word in positive_words)
        has_negative = any(word in cleaned_lower for word in negative_words)
        
        # åªåœ¨æ˜ç¡®æœ‰å€¾å‘ä¸”æ²¡æœ‰åŒ¹é…åˆ°é€‰é¡¹æ—¶æ‰ä½¿ç”¨
        if has_positive and not has_negative:
            for opt in options:
                opt_lower = opt.lower()
                if any(word in opt_lower for word in positive_words):
                    return opt.strip()
            # å¦‚æœé€‰é¡¹ä¸­æ²¡æœ‰æ˜ç¡®çš„æ­£å‘è¯ï¼Œè¿”å›ç¬¬ä¸€ä¸ªé€‰é¡¹ï¼ˆé€šå¸¸åˆ¤æ–­é¢˜ç¬¬ä¸€ä¸ªæ˜¯"æ­£ç¡®"ï¼‰
            return options[0].strip() if len(options) > 0 else cleaned
        
        if has_negative and not has_positive:
            for opt in options:
                opt_lower = opt.lower()
                if any(word in opt_lower for word in negative_words):
                    return opt.strip()
            # å¦‚æœé€‰é¡¹ä¸­æ²¡æœ‰æ˜ç¡®çš„è´Ÿå‘è¯ï¼Œè¿”å›ç¬¬äºŒä¸ªé€‰é¡¹ï¼ˆé€šå¸¸åˆ¤æ–­é¢˜ç¬¬äºŒä¸ªæ˜¯"é”™è¯¯"ï¼‰
            return options[1].strip() if len(options) > 1 else cleaned
        
        # æ— æ³•åˆ¤æ–­ï¼Œè¿”å›æ¸…æ´—åçš„åŸå§‹ç­”æ¡ˆ
        return cleaned if cleaned else raw_answer


# åˆ›å»ºå…¨å±€æ¨¡å‹å®¢æˆ·ç«¯
model_client = None
init_error = None

try:
    # æ£€æŸ¥å¿…éœ€çš„é…ç½®
    if MODEL_PROVIDER == 'auto':
        # æ™ºèƒ½æ¨¡å¼ï¼šéœ€è¦è‡³å°‘é…ç½®ä¸€ä¸ªæ¨¡å‹
        if not DEEPSEEK_API_KEY and not DOUBAO_API_KEY:
            init_error = "æ™ºèƒ½æ¨¡å¼éœ€è¦è‡³å°‘é…ç½®ä¸€ä¸ªæ¨¡å‹çš„APIå¯†é’¥ï¼ˆDEEPSEEK_API_KEY æˆ– DOUBAO_API_KEYï¼‰"
            logger.error(init_error)
        else:
            model_client = ModelClient(MODEL_PROVIDER)
            logger.info(f"âœ… æ™ºèƒ½æ¨¡å‹é€‰æ‹©å·²å¯ç”¨ - å·²é…ç½® {len(model_client.clients)} ä¸ªæ¨¡å‹")
    elif MODEL_PROVIDER == 'deepseek':
        if not DEEPSEEK_API_KEY:
            init_error = "DeepSeek APIå¯†é’¥æœªé…ç½®ï¼Œè¯·åœ¨.envæ–‡ä»¶ä¸­è®¾ç½® DEEPSEEK_API_KEY"
            logger.error(init_error)
        else:
            model_client = ModelClient(MODEL_PROVIDER)
            logger.info(f"âœ… æ¨¡å‹å®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ: {MODEL_PROVIDER} - {model_client.model}")
    elif MODEL_PROVIDER == 'doubao':
        if not DOUBAO_API_KEY:
            init_error = "è±†åŒ… APIå¯†é’¥æœªé…ç½®ï¼Œè¯·åœ¨.envæ–‡ä»¶ä¸­è®¾ç½® DOUBAO_API_KEY"
            logger.error(init_error)
        elif not DOUBAO_MODEL:
            init_error = "è±†åŒ… æ¨¡å‹IDæœªé…ç½®ï¼Œè¯·åœ¨.envæ–‡ä»¶ä¸­è®¾ç½® DOUBAO_MODEL"
            logger.error(init_error)
        else:
            model_client = ModelClient(MODEL_PROVIDER)
            logger.info(f"âœ… æ¨¡å‹å®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ: {MODEL_PROVIDER} - {model_client.model}")
    else:
        init_error = f"ä¸æ”¯æŒçš„æ¨¡å‹æä¾›å•†: {MODEL_PROVIDER}ï¼ˆæ”¯æŒ: deepseek, doubao, autoï¼‰"
        logger.error(init_error)
except Exception as e:
    init_error = f"åˆå§‹åŒ–æ¨¡å‹å®¢æˆ·ç«¯å¤±è´¥: {str(e)}"
    logger.error(init_error, exc_info=True)
    model_client = None


def format_time(seconds: float) -> str:
    """
    æ ¼å¼åŒ–æ—¶é—´æ˜¾ç¤ºä¸ºæ˜“è¯»æ ¼å¼
    
    Args:
        seconds: ç§’æ•°
    
    Returns:
        str: æ ¼å¼åŒ–åçš„æ—¶é—´å­—ç¬¦ä¸²
             - å°äº60ç§’ï¼š"X.Xç§’"
             - å¤§äºç­‰äº60ç§’ï¼š"Xåˆ†Y.Yç§’"
    
    Examples:
        >>> format_time(45.5)
        '45.5ç§’'
        >>> format_time(125.3)
        '2åˆ†5.3ç§’'
    """
    if seconds < 60:
        return f"{seconds:.1f}ç§’"
    else:
        minutes = int(seconds // 60)
        secs = seconds % 60
        return f"{minutes}åˆ†{secs:.1f}ç§’"


def _call_custom_model(model_id: str, prompt: str, image_urls: List[str] = None, 
                       force_reasoning: bool = False) -> Tuple[Optional[str], Optional[str], Optional[Dict[str, int]]]:
    """
    è°ƒç”¨è‡ªå®šä¹‰æ¨¡å‹
    
    Args:
        model_id: è‡ªå®šä¹‰æ¨¡å‹ID
        prompt: æç¤ºè¯
        image_urls: å›¾ç‰‡URLåˆ—è¡¨
        force_reasoning: æ˜¯å¦å¼ºåˆ¶å¯ç”¨æ€è€ƒæ¨¡å¼
    
    Returns:
        (æ¨ç†è¿‡ç¨‹, æœ€ç»ˆç­”æ¡ˆ, tokenä½¿ç”¨é‡)
    """
    import httpx
    from openai import OpenAI
    
    model = custom_model_manager.get_model(model_id)
    if not model:
        logger.error(f"è‡ªå®šä¹‰æ¨¡å‹ä¸å­˜åœ¨: {model_id}")
        return None, None, None
    
    try:
        # åˆ›å»ºå®¢æˆ·ç«¯
        http_client_kwargs = {'timeout': TIMEOUT}
        if HTTPS_PROXY:
            http_client_kwargs['proxies'] = HTTPS_PROXY
        
        http_client = httpx.Client(**http_client_kwargs)
        client = OpenAI(
            api_key=model['api_key'],
            base_url=model['base_url'],
            http_client=http_client,
            max_retries=MAX_RETRIES
        )
        
        # æ„å»ºæ¶ˆæ¯
        messages = [
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šã€ä¸¥è°¨çš„ç­”é¢˜åŠ©æ‰‹ã€‚ä½ å¿…é¡»æ ¹æ®é¢˜ç›®å’Œé€‰é¡¹ç»™å‡ºå‡†ç¡®çš„ç­”æ¡ˆï¼Œä¸¥æ ¼æŒ‰ç…§è¦æ±‚çš„æ ¼å¼è¾“å‡ºï¼Œä¸è¦æœ‰ä»»ä½•å¤šä½™çš„å†…å®¹ã€‚"}
        ]
        
        # å¤„ç†å›¾ç‰‡ï¼ˆå¦‚æœæ¨¡å‹æ”¯æŒå¤šæ¨¡æ€ï¼‰
        if image_urls and model.get('is_multimodal', False):
            user_content = []
            # ä¸‹è½½å¹¶è½¬æ¢å›¾ç‰‡ä¸ºbase64
            for img_url in image_urls:
                # ä½¿ç”¨ModelClientçš„æ–¹æ³•ä¸‹è½½å›¾ç‰‡
                base64_data = model_client.download_image_as_base64(img_url) if model_client else None
                if base64_data:
                    user_content.append({
                        "type": "image_url",
                        "image_url": {"url": base64_data}
                    })
            user_content.append({"type": "text", "text": prompt})
            messages.append({"role": "user", "content": user_content})
        else:
            messages.append({"role": "user", "content": prompt})
        
        # æ„å»ºè¯·æ±‚å‚æ•°
        request_params = {
            "model": model['model_name'],
            "messages": messages,
            "temperature": model.get('temperature', 0.1),
            "max_tokens": model.get('max_tokens', 2000),
            "top_p": model.get('top_p', 0.95),
            "stream": False
        }
        
        # å¦‚æœæ¨¡å‹æ”¯æŒæ€è€ƒæ¨¡å¼å¹¶ä¸”éœ€è¦å¯ç”¨
        if force_reasoning and model.get('supports_reasoning', False):
            # ä½¿ç”¨è‡ªå®šä¹‰çš„æ€è€ƒå‚æ•°åç§°å’Œå€¼
            param_name = model.get('reasoning_param_name', 'reasoning_effort')
            param_value = model.get('reasoning_param_value', 'medium')
            request_params[param_name] = param_value
            logger.info(f"ğŸ§  å¯ç”¨æ€è€ƒæ¨¡å¼: {param_name}={param_value}")
        
        # è°ƒç”¨API
        response = client.chat.completions.create(**request_params)
        
        # æå–æ¨ç†è¿‡ç¨‹å’Œç­”æ¡ˆ
        reasoning_content = None
        if hasattr(response.choices[0].message, 'reasoning_content'):
            reasoning_content = response.choices[0].message.reasoning_content
        
        answer = response.choices[0].message.content.strip()
        
        # æå–tokenä½¿ç”¨é‡
        usage_info = None
        if hasattr(response, 'usage'):
            usage_info = {
                'prompt_tokens': response.usage.prompt_tokens if hasattr(response.usage, 'prompt_tokens') else 0,
                'completion_tokens': response.usage.completion_tokens if hasattr(response.usage, 'completion_tokens') else 0,
                'total_tokens': response.usage.total_tokens if hasattr(response.usage, 'total_tokens') else 0
            }
        else:
            usage_info = {'prompt_tokens': 0, 'completion_tokens': 0, 'total_tokens': 0}
        
        return reasoning_content, answer, usage_info
        
    except Exception as e:
        logger.error(f"è°ƒç”¨è‡ªå®šä¹‰æ¨¡å‹å¤±è´¥: {model_id}, é”™è¯¯: {str(e)}")
        return None, None, None


def check_and_fix_csv_header(csv_file: str, correct_headers: List[str]) -> bool:
    """
    æ£€æŸ¥å¹¶è‡ªåŠ¨ä¿®å¤CSVæ–‡ä»¶çš„è¡¨å¤´æ ¼å¼
    
    åŠŸèƒ½ï¼š
        1. éªŒè¯CSVæ–‡ä»¶çš„è¡¨å¤´æ˜¯å¦ä¸æœŸæœ›çš„ä¸€è‡´
        2. å¦‚æœä¸ä¸€è‡´ï¼Œå¤‡ä»½åŸæ–‡ä»¶å¹¶è‡ªåŠ¨ä¿®å¤
        3. å¤„ç†åˆ—æ•°ä¸åŒ¹é…çš„æƒ…å†µï¼ˆè¡¥é½æˆ–æˆªæ–­ï¼‰
    
    Args:
        csv_file: CSVæ–‡ä»¶è·¯å¾„
        correct_headers: æ­£ç¡®çš„è¡¨å¤´åˆ—è¡¨
    
    Returns:
        bool: Trueè¡¨ç¤ºè¡¨å¤´æ­£ç¡®æˆ–å·²æˆåŠŸä¿®å¤ï¼ŒFalseè¡¨ç¤ºä¿®å¤å¤±è´¥
    
    æ³¨æ„ï¼š
        - ä¿®å¤å‰ä¼šè‡ªåŠ¨åˆ›å»ºå¤‡ä»½æ–‡ä»¶ (.backup)
        - å¯¹äºåˆ—æ•°ä¸è¶³çš„è¡Œï¼Œä¼šå¡«å……é»˜è®¤å€¼
    """
    if not os.path.exists(csv_file):
        # æ–‡ä»¶ä¸å­˜åœ¨ï¼Œæ— éœ€ä¿®å¤
        return True
    
    try:
        # è¯»å–å½“å‰è¡¨å¤´
        with open(csv_file, 'r', encoding='utf-8-sig') as f:
            reader = csv.reader(f)
            current_headers = next(reader, None)
            if current_headers is None:
                # ç©ºæ–‡ä»¶ï¼Œæ— éœ€ä¿®å¤
                return True
            
            # æ£€æŸ¥è¡¨å¤´æ˜¯å¦æ­£ç¡®
            if current_headers == correct_headers:
                # è¡¨å¤´æ­£ç¡®ï¼Œæ— éœ€ä¿®å¤
                return True
            
            # è¡¨å¤´ä¸æ­£ç¡®ï¼Œéœ€è¦ä¿®å¤
            logger.warning(f"âš ï¸  CSVæ–‡ä»¶è¡¨å¤´ä¸æ­£ç¡®ï¼Œå½“å‰åˆ—æ•°: {len(current_headers)}, æ­£ç¡®åˆ—æ•°: {len(correct_headers)}")
            logger.info("ğŸ”§ å¼€å§‹è‡ªåŠ¨ä¿®å¤CSVæ–‡ä»¶è¡¨å¤´...")
            
            # è¯»å–æ‰€æœ‰æ•°æ®
            f.seek(0)
            reader = csv.reader(f)
            rows = list(reader)
        
        # å¤‡ä»½åŸæ–‡ä»¶
        backup_file = csv_file + '.backup'
        import shutil
        shutil.copy2(csv_file, backup_file)
        logger.info(f"ğŸ“‹ å·²å¤‡ä»½åˆ°: {backup_file}")
        
        # ä¿®å¤æ•°æ®
        fixed_rows = [correct_headers]  # æ–°è¡¨å¤´
        
        for i, row in enumerate(rows[1:], start=2):  # è·³è¿‡æ—§è¡¨å¤´
            # å¦‚æœè¡Œçš„åˆ—æ•°å°‘äºæ–°è¡¨å¤´ï¼Œè¡¥å……é»˜è®¤å€¼
            if len(row) < len(correct_headers):
                missing_cols = len(correct_headers) - len(row)
                # è¡¥å……é»˜è®¤å€¼ï¼š0, 0, 0, 0.000000, ''
                row.extend(['0'] * (missing_cols - 1) + [''])
            elif len(row) > len(correct_headers):
                # å¦‚æœåˆ—æ•°è¿‡å¤šï¼Œæˆªæ–­
                row = row[:len(correct_headers)]
            fixed_rows.append(row)
        
        # å†™å…¥ä¿®å¤åçš„æ–‡ä»¶
        with open(csv_file, 'w', newline='', encoding='utf-8-sig') as f:
            writer = csv.writer(f, quoting=csv.QUOTE_MINIMAL)
            writer.writerows(fixed_rows)
        
        logger.info(f"âœ… CSVæ–‡ä»¶è¡¨å¤´ä¿®å¤å®Œæˆï¼Œå…±å¤„ç† {len(fixed_rows)-1} è¡Œæ•°æ®")
        return True
        
    except Exception as e:
        logger.error(f"âŒ CSVæ–‡ä»¶è¡¨å¤´ä¿®å¤å¤±è´¥: {str(e)}")
        return False


def save_to_csv(question: str, options: List[str], q_type: str, raw_answer: str, 
                reasoning: Optional[str], processed_answer: str, ai_time: float, 
                total_time: float, model_name: str, reasoning_used: bool,
                prompt_tokens: int = 0, completion_tokens: int = 0, provider: str = ''):
    """
    ä¿å­˜ç­”é¢˜è®°å½•åˆ°CSVæ–‡ä»¶
    
    Args:
        question: é¢˜ç›®
        options: é€‰é¡¹åˆ—è¡¨
        q_type: é¢˜å‹
        raw_answer: AIåŸå§‹å›ç­”
        reasoning: æ€è€ƒè¿‡ç¨‹ï¼ˆå¦‚æœæœ‰ï¼‰
        processed_answer: å¤„ç†åçš„ç­”æ¡ˆ
        ai_time: AIç­”é¢˜è€—æ—¶ï¼ˆç§’ï¼‰
        total_time: æ€»è€—æ—¶ï¼ˆç§’ï¼‰
        model_name: æ¨¡å‹åç§°
        reasoning_used: æ˜¯å¦ä½¿ç”¨äº†æ€è€ƒæ¨¡å¼
        prompt_tokens: è¾“å…¥tokenæ•°
        completion_tokens: è¾“å‡ºtokenæ•°
        provider: æ¨¡å‹æä¾›å•† (deepseek/doubao)
    """
    csv_file = os.getenv('CSV_LOG_FILE', 'ocs_answers_log.csv')
    
    # CSVè¡¨å¤´
    headers = [
        'æ—¶é—´æˆ³', 'é¢˜å‹', 'é¢˜ç›®', 'é€‰é¡¹', 'åŸå§‹å›ç­”', 'æ€è€ƒè¿‡ç¨‹', 
        'å¤„ç†åç­”æ¡ˆ', 'AIè€—æ—¶(ç§’)', 'æ€»è€—æ—¶(ç§’)', 'æ¨¡å‹', 'æ€è€ƒæ¨¡å¼',
        'è¾“å…¥Token', 'è¾“å‡ºToken', 'æ€»Token', 'è´¹ç”¨(å…ƒ)', 'æä¾›å•†'
    ]
    
    # æ£€æŸ¥å¹¶ä¿®å¤CSVæ–‡ä»¶è¡¨å¤´ï¼ˆå¦‚æœéœ€è¦ï¼‰
    if os.path.exists(csv_file):
        check_and_fix_csv_header(csv_file, headers)
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»ºå¹¶å†™å…¥è¡¨å¤´
    file_exists = os.path.exists(csv_file)
    
    try:
        # ä½¿ç”¨UTF-8 BOMç¼–ç ï¼Œç¡®ä¿Excelå¯ä»¥æ­£ç¡®æ˜¾ç¤ºä¸­æ–‡
        with open(csv_file, 'a', newline='', encoding='utf-8-sig') as f:
            writer = csv.writer(f, quoting=csv.QUOTE_MINIMAL)
            
            # å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œå†™å…¥è¡¨å¤´
            if not file_exists:
                writer.writerow(headers)
            
            # å‡†å¤‡æ•°æ®
            timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            options_str = ' | '.join(options) if options else ''
            reasoning_str = reasoning if reasoning else ''
            
            # è®¡ç®—è´¹ç”¨ï¼ˆåŸºäºDeepSeekå’Œè±†åŒ…çš„å®˜æ–¹ä»·æ ¼ï¼‰
            # DeepSeek: è¾“å…¥ç¼“å­˜å‘½ä¸­0.2å…ƒ/ç™¾ä¸‡tokensï¼Œç¼“å­˜æœªå‘½ä¸­2å…ƒ/ç™¾ä¸‡tokensï¼Œè¾“å‡º3å…ƒ/ç™¾ä¸‡tokens
            # è±†åŒ…-Seed-1.6: æ¨ç†è¾“å…¥0.8å…ƒ/ç™¾ä¸‡tokensï¼Œæ¨ç†è¾“å‡º2å…ƒ/ç™¾ä¸‡tokens
            # æ³¨æ„ï¼šè¿™é‡Œå‡è®¾ç¼“å­˜æœªå‘½ä¸­ï¼ˆå®é™…åº”è¯¥æ ¹æ®ç¼“å­˜çŠ¶æ€åˆ¤æ–­ï¼‰
            cost = 0.0
            if provider.lower() == 'deepseek':
                # DeepSeekä»·æ ¼ï¼ˆå‡è®¾ç¼“å­˜æœªå‘½ä¸­ï¼‰
                input_cost = (prompt_tokens / 1000000) * 2.0  # 2å…ƒ/ç™¾ä¸‡tokens
                output_cost = (completion_tokens / 1000000) * 3.0  # 3å…ƒ/ç™¾ä¸‡tokens
                cost = input_cost + output_cost
            elif provider.lower() == 'doubao':
                # è±†åŒ…-Seed-1.6 å®˜æ–¹ä»·æ ¼
                input_cost = (prompt_tokens / 1000000) * 0.8  # 0.8å…ƒ/ç™¾ä¸‡tokens
                output_cost = (completion_tokens / 1000000) * 2.0  # 2å…ƒ/ç™¾ä¸‡tokens
                cost = input_cost + output_cost
            else:
                # æœªçŸ¥æä¾›å•†ï¼Œä½¿ç”¨é»˜è®¤ä»·æ ¼ï¼ˆå‚è€ƒDeepSeekï¼‰
                input_cost = (prompt_tokens / 1000000) * 2.0
                output_cost = (completion_tokens / 1000000) * 3.0
                cost = input_cost + output_cost
            
            total_tokens = prompt_tokens + completion_tokens
            
            # å†™å…¥æ•°æ®è¡Œï¼ˆæ‰€æœ‰å­—æ®µéƒ½ä¼šè¢«æ­£ç¡®è½¬ä¹‰ï¼‰
            row = [
                timestamp,
                q_type,
                question,
                options_str,
                raw_answer,
                reasoning_str,
                processed_answer,
                f"{ai_time:.2f}",
                f"{total_time:.2f}",
                model_name,
                'æ˜¯' if reasoning_used else 'å¦',
                str(prompt_tokens),
                str(completion_tokens),
                str(total_tokens),
                f"{cost:.6f}",
                provider.upper() if provider else ''
            ]
            
            writer.writerow(row)
            logger.debug(f"CSVè®°å½•å·²ä¿å­˜: {len(row)}ä¸ªå­—æ®µï¼Œæ€è€ƒè¿‡ç¨‹é•¿åº¦: {len(reasoning_str)}")
            
    except Exception as e:
        # CSVè®°å½•å¤±è´¥ä¸å½±å“ç­”é¢˜æµç¨‹ï¼Œåªè®°å½•æ—¥å¿—
        logger.warning(f"ä¿å­˜CSVè®°å½•å¤±è´¥: {str(e)}", exc_info=True)


@app.route('/api/answer', methods=['POST'])
def answer_question():
    """
    æ ¸å¿ƒç­”é¢˜APIæ¥å£
    
    åŠŸèƒ½ï¼š
        1. æ¥æ”¶é¢˜ç›®ä¿¡æ¯ï¼ˆé¢˜ç›®ã€é€‰é¡¹ã€é¢˜å‹ã€å›¾ç‰‡ï¼‰
        2. è°ƒç”¨AIæ¨¡å‹ç”Ÿæˆç­”æ¡ˆ
        3. å¤„ç†å’Œæ¸…æ´—ç­”æ¡ˆ
        4. è®°å½•ç­”é¢˜æ—¥å¿—åˆ°CSV
        5. è¿”å›OCSè„šæœ¬å…¼å®¹çš„å“åº”æ ¼å¼
    
    è¯·æ±‚æ ¼å¼ (JSON):
        {
            "question": "é¢˜ç›®å†…å®¹",
            "options": ["é€‰é¡¹1", "é€‰é¡¹2", ...],  // æˆ–å­—ç¬¦ä¸²æ ¼å¼
            "type": 0,  // 0=å•é€‰, 1=å¤šé€‰, 3=å¡«ç©º, 4=åˆ¤æ–­
            "images": ["http://..."]  // å¯é€‰ï¼Œå›¾ç‰‡URLåˆ—è¡¨
        }
    
    å“åº”æ ¼å¼ (JSON):
        {
            "success": true,
            "question": "é¢˜ç›®å†…å®¹",
            "answer": "å¤„ç†åçš„ç­”æ¡ˆ",
            "type": "single",
            "raw_answer": "AIåŸå§‹å›ç­”",
            "model": "deepseek-chat",
            "provider": "deepseek",
            "reasoning_used": false,
            "ai_time": 1.23,
            "total_time": 1.45,
            "usage": {"prompt_tokens": 100, "completion_tokens": 50, "total_tokens": 150},
            "ocs_format": ["é¢˜ç›®", "ç­”æ¡ˆ", {...}]
        }
    
    ç‰¹æ€§ï¼š
        - è‡ªåŠ¨è¯†åˆ«é¢˜ç›®ä¸­çš„å›¾ç‰‡URL
        - å¤šé€‰é¢˜è‡ªåŠ¨å¯ç”¨æ€è€ƒæ¨¡å¼
        - å›¾ç‰‡é¢˜è‡ªåŠ¨ä½¿ç”¨æ”¯æŒå¤šæ¨¡æ€çš„æ¨¡å‹
        - è¿‡æ»¤å›¾æ ‡ç±»URLï¼ˆvideo.pngã€icon/ç­‰ï¼‰
    """
    start_time = time.time()
    
    try:
        if not model_client:
            error_msg = init_error or "æ¨¡å‹å®¢æˆ·ç«¯æœªåˆå§‹åŒ–ï¼Œè¯·æ£€æŸ¥é…ç½®"
            print(f"\nâŒ {error_msg}")
            print("="*80 + "\n")
            return jsonify({
                "success": False,
                "error": error_msg,
                "hint": "è¯·æ£€æŸ¥.envæ–‡ä»¶ä¸­çš„APIå¯†é’¥é…ç½®"
            }), 500
        
        data = request.get_json()
        
        if not data:
            return jsonify({"success": False, "error": "æ— æ•ˆçš„è¯·æ±‚æ•°æ®"}), 400
        
        question = data.get('question', '').strip()
        options = data.get('options', [])
        type_num = data.get('type', 0)
        images = data.get('images', [])  # å›¾ç‰‡URLåˆ—è¡¨
        
        if not question:
            return jsonify({"success": False, "error": "é¢˜ç›®ä¸èƒ½ä¸ºç©º"}), 400
        
        q_type = QUESTION_TYPES.get(type_num, "single")
        q_type_name = {"single": "å•é€‰é¢˜", "multiple": "å¤šé€‰é¢˜", "judgement": "åˆ¤æ–­é¢˜", "completion": "å¡«ç©ºé¢˜"}.get(q_type, "æœªçŸ¥é¢˜å‹")
        
        # å¤„ç†é€‰é¡¹ï¼šæ”¯æŒå¤šç§æ ¼å¼
        if isinstance(options, str):
            # å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼ŒæŒ‰æ¢è¡Œç¬¦åˆ†å‰²ï¼ˆOCSè„šæœ¬ä¼ é€’çš„æ ¼å¼ï¼‰
            options = [opt.strip() for opt in options.split('\n') if opt.strip()]
        elif isinstance(options, list):
            # å¦‚æœæ˜¯åˆ—è¡¨ï¼Œæ¸…ç†æ¯ä¸ªé€‰é¡¹
            options = [str(opt).strip() for opt in options if opt]
        else:
            # å…¶ä»–æ ¼å¼è½¬ä¸ºç©ºåˆ—è¡¨
            options = []
        
        # æå–é¢˜ç›®ä¸­çš„å›¾ç‰‡URL
        image_urls = []
        
        # æ¸…ç†URLçš„å‡½æ•°ï¼ˆå»é™¤æ‰©å±•ååå¯èƒ½é™„åŠ çš„å­—ç¬¦ï¼‰
        def clean_url(url):
            """æ¸…ç†URLï¼Œå»é™¤æ‰©å±•ååå¯èƒ½é™„åŠ çš„å­—ç¬¦"""
            url = str(url).strip()
            # æ‰¾åˆ°æœ€åä¸€ä¸ªå›¾ç‰‡æ‰©å±•åçš„ä½ç½®
            match = re.search(r'\.(jpg|jpeg|png|gif|bmp|webp)', url, re.IGNORECASE)
            if match:
                # åªä¿ç•™åˆ°æ‰©å±•åç»“æŸï¼ˆåŒ…æ‹¬æ‰©å±•åï¼‰
                end_pos = match.end()
                return url[:end_pos]
            return url
        
        if images and isinstance(images, list):
            image_urls = [clean_url(img) for img in images if img]
        
        # ä»é¢˜ç›®æ–‡æœ¬ä¸­æå–å›¾ç‰‡URLï¼ˆæ”¯æŒå¸¸è§å›¾ç‰‡æ ¼å¼ï¼‰
        # ä½¿ç”¨éè´ªå©ªåŒ¹é…ï¼Œç¡®ä¿åœ¨é‡åˆ°å›¾ç‰‡æ‰©å±•ååç«‹å³åœæ­¢
        # åŒ¹é…URLä¸­çš„åˆæ³•å­—ç¬¦ï¼Œä½†ä½¿ç”¨éè´ªå©ªæ¨¡å¼é¿å…åŒ¹é…è¿‡å¤š
        img_pattern = r'(https?://[a-zA-Z0-9\-._~:/?#\[\]@!$&\'()*+,;=%]+?\.(?:jpg|jpeg|png|gif|bmp|webp))'
        found_images = re.findall(img_pattern, question, re.IGNORECASE)
        
        # æ¸…ç†æå–çš„URL
        found_images = [clean_url(url) for url in found_images]
        
        if found_images:
            logger.info(f"ğŸ“· ä»é¢˜ç›®ä¸­æ£€æµ‹åˆ° {len(found_images)} å¼ å›¾ç‰‡")
        image_urls.extend(found_images)
        
        # ä»é€‰é¡¹ä¸­æå–å›¾ç‰‡URL
        found_images_in_options = []
        if options:
            options_text = ' '.join(str(opt) for opt in options)
            found_images_in_options = re.findall(img_pattern, options_text, re.IGNORECASE)
            found_images_in_options = [clean_url(url) for url in found_images_in_options]
            if found_images_in_options:
                logger.info(f"ğŸ“· ä»é€‰é¡¹ä¸­æ£€æµ‹åˆ° {len(found_images_in_options)} å¼ å›¾ç‰‡")
                image_urls.extend(found_images_in_options)
        
        image_urls = list(dict.fromkeys(image_urls))  # å»é‡
        
        # è¿‡æ»¤æ‰æ˜æ˜¾çš„å›¾æ ‡URLï¼ˆé€šå¸¸ä¸æ˜¯é¢˜ç›®å†…å®¹ï¼‰
        # ä¾‹å¦‚ï¼šicon/video.png, icon/audio.png, icons/ ç­‰
        filtered_image_urls = []
        icon_keywords = ['/icon/', '/icons/', '/icon.', 'icon/', 'video.png', 'audio.png', 'play.png', 'pause.png']
        
        for img_url in image_urls:
            # è·³è¿‡æ˜æ˜¾çš„å›¾æ ‡URL
            img_url_lower = img_url.lower()
            is_icon = any(keyword in img_url_lower for keyword in icon_keywords)
            
            if is_icon:
                logger.debug(f"è·³è¿‡å›¾æ ‡URL: {img_url}")
                continue
            
            filtered_image_urls.append(img_url)
        
        image_urls = filtered_image_urls
        
        # è®°å½•å›¾ç‰‡æ£€æµ‹ç»“æœ
        total_found = len(found_images) + len(found_images_in_options) + len([img for img in (images or []) if img])
        if total_found > 0:
            logger.info(f"ğŸ“· å›¾ç‰‡æ£€æµ‹ç»“æœ: é¢˜å¹²{len(found_images)}å¼ , é€‰é¡¹{len(found_images_in_options)}å¼ , APIä¼ å…¥{len(images or [])}å¼ , è¿‡æ»¤å{len(image_urls)}å¼ ")
        
        # å¦‚æœè¿‡æ»¤åæ²¡æœ‰å›¾ç‰‡ï¼Œè®°å½•æ—¥å¿—
        if len(image_urls) == 0 and total_found > 0:
            logger.debug("æ‰€æœ‰å›¾ç‰‡URLå·²è¢«è¿‡æ»¤ï¼ˆå¯èƒ½éƒ½æ˜¯å›¾æ ‡ï¼‰ï¼Œä½¿ç”¨çº¯æ–‡æœ¬æ¨¡å¼")
        
        # æ§åˆ¶å°è¾“å‡ºé¢˜ç›®ä¿¡æ¯
        print("\n" + "="*80)
        print(f"ğŸ“ ã€{q_type_name}ã€‘")
        print(f"é¢˜ç›®: {question}")
        if options:
            print(f"é€‰é¡¹: {' | '.join(options)}")
        if image_urls:
            print(f"ğŸ“· æ£€æµ‹åˆ°å›¾ç‰‡: {len(image_urls)}å¼ ")
            if found_images_in_options and len(found_images_in_options) > 0:
                print(f"   âš ï¸  é€‰é¡¹ä¸­æœ‰å›¾ç‰‡ï¼Œå°†è‡ªåŠ¨ä½¿ç”¨è±†åŒ…æ¨¡å‹")
            for i, img_url in enumerate(image_urls, 1):
                print(f"   {i}. {img_url}")
        print("="*80)
        
        # æ„å»ºprompt
        prompt = PromptBuilder.build_prompt(question, options, q_type)
        
        # ç¡®å®šæ˜¯å¦å¯ç”¨æ€è€ƒæ¨¡å¼
        force_reasoning = False
        reasoning_reasons = []
        
        # 1. æ£€æŸ¥é¢˜å‹çš„æ€è€ƒé…ç½®ï¼ˆä¼˜å…ˆçº§æœ€é«˜ï¼‰
        type_reasoning_enabled = custom_model_manager.get_question_type_reasoning(q_type)
        if type_reasoning_enabled:
            force_reasoning = True
            reasoning_reasons.append("é¢˜å‹é…ç½®")
        
        # 2. å…¼å®¹æ—§çš„è‡ªåŠ¨å¯ç”¨é€»è¾‘
        if q_type == "multiple" and model_client.auto_reasoning_for_multiple:
            force_reasoning = True
            if "å¤šé€‰é¢˜" not in reasoning_reasons:
                reasoning_reasons.append("å¤šé€‰é¢˜")
        
        # 3. å¸¦å›¾ç‰‡é¢˜ç›®è‡ªåŠ¨å¯ç”¨æ€è€ƒæ¨¡å¼
        if image_urls and model_client.auto_reasoning_for_images:
            force_reasoning = True
            if "å›¾ç‰‡é¢˜" not in reasoning_reasons:
                reasoning_reasons.append("å›¾ç‰‡é¢˜")
        
        if force_reasoning and reasoning_reasons:
            print(f"ğŸ§  {' + '.join(reasoning_reasons)}è‡ªåŠ¨å¯ç”¨æ·±åº¦æ€è€ƒæ¨¡å¼")
        
        # è°ƒç”¨æ¨¡å‹ï¼ˆè®¡æ—¶ï¼‰
        # ä¼˜å…ˆä½¿ç”¨è‡ªå®šä¹‰æ¨¡å‹ï¼Œæ”¯æŒæ•…éšœè½¬ç§»
        ai_start = time.time()
        
        # è·å–è¯¥é¢˜å‹çš„æ‰€æœ‰å¯ç”¨æ¨¡å‹ï¼ˆæŒ‰ä¼˜å…ˆçº§æ’åºï¼‰
        type_models = custom_model_manager.get_question_type_models(q_type)
        
        reasoning = None
        raw_answer = None
        usage_info = None
        custom_model_id = None
        actual_provider = None
        model_name = None
        
        if type_models:
            # å°è¯•ä½¿ç”¨è‡ªå®šä¹‰æ¨¡å‹ï¼ˆæ”¯æŒæ•…éšœè½¬ç§»ï¼‰
            for model_id in type_models:
                model = custom_model_manager.get_model(model_id)
                if not model or not model.get('enabled', True):
                    continue
                
                # å¦‚æœæœ‰å›¾ç‰‡ï¼Œå¿…é¡»æ˜¯å¤šæ¨¡æ€æ¨¡å‹
                if image_urls and not model.get('is_multimodal', False):
                    logger.info(f"â­ï¸  è·³è¿‡éå¤šæ¨¡æ€æ¨¡å‹: {model_id}")
                    continue
                
                # å°è¯•è°ƒç”¨æ¨¡å‹
                logger.info(f"ğŸ¯ ä½¿ç”¨è‡ªå®šä¹‰æ¨¡å‹: {model_id}")
                print(f"ğŸ¯ ä½¿ç”¨è‡ªå®šä¹‰æ¨¡å‹: {model_id}")
                
                reasoning, raw_answer, usage_info = _call_custom_model(
                    model_id,
                    prompt,
                    image_urls,
                    force_reasoning
                )
                
                if raw_answer:
                    # æˆåŠŸè·å–ç­”æ¡ˆ
                    custom_model_id = model_id
                    actual_provider = 'custom'
                    model_name = model.get('name', model_id)
                    break
                else:
                    # å¤±è´¥ï¼Œå°è¯•ä¸‹ä¸€ä¸ªæ¨¡å‹
                    logger.warning(f"âš ï¸  æ¨¡å‹ {model_id} è°ƒç”¨å¤±è´¥ï¼Œå°è¯•ä¸‹ä¸€ä¸ªæ¨¡å‹...")
                    print(f"âš ï¸  æ¨¡å‹ {model_id} è°ƒç”¨å¤±è´¥ï¼Œå°è¯•ä¸‹ä¸€ä¸ªæ¨¡å‹...")
        
        # å¦‚æœè‡ªå®šä¹‰æ¨¡å‹éƒ½å¤±è´¥äº†ï¼Œä½¿ç”¨é»˜è®¤çš„ model_client
        if not raw_answer and model_client:
            # ä½¿ç”¨é»˜è®¤çš„ model_client
            reasoning, raw_answer, usage_info = model_client.chat(
                prompt, 
                force_reasoning=force_reasoning,
                image_urls=image_urls if image_urls else None
            )
            # ç¡®å®šå®é™…ä½¿ç”¨çš„æ¨¡å‹åç§°å’Œæä¾›å•†
            if model_client.is_auto_mode:
                actual_provider = model_client._select_model(image_urls if image_urls else None)[0]
                if actual_provider in model_client.models:
                    model_name = model_client.models[actual_provider]
                else:
                    model_name = "auto-unknown"
            else:
                model_name = model_client.model if not force_reasoning else ('deepseek-reasoner' if model_client.provider == 'deepseek' else model_client.model)
                actual_provider = model_client.provider
        
        ai_time = time.time() - ai_start
        
        if not raw_answer:
            print(f"âŒ ç­”é¢˜å¤±è´¥: AIæœªè¿”å›ç­”æ¡ˆ")
            return jsonify({"success": False, "error": "AIç­”é¢˜å¤±è´¥"}), 500
        
        # æå–tokenä½¿ç”¨é‡
        prompt_tokens = 0
        completion_tokens = 0
        if usage_info:
            prompt_tokens = usage_info.get('prompt_tokens', 0)
            completion_tokens = usage_info.get('completion_tokens', 0)
        
        # å¤„ç†ç­”æ¡ˆ
        processed_answer = AnswerProcessor.process_answer(raw_answer, q_type, options)
        
        # è®¡ç®—æ€»è€—æ—¶
        total_time = time.time() - start_time
        
        # æ§åˆ¶å°è¾“å‡ºç­”æ¡ˆå’Œè€—æ—¶
        print(f"\nğŸ¤– AIåŸå§‹å›ç­”: {raw_answer}")
        print(f"âœ… å¤„ç†åç­”æ¡ˆ: {processed_answer}")
        print(f"â±ï¸  æ¨¡å‹ç­”é¢˜ç”¨æ—¶: {format_time(ai_time)}")
        print(f"â±ï¸  æ€»å¤„ç†ç”¨æ—¶: {format_time(total_time)}")
        print("="*80 + "\n")
        
        # è®°å½•åˆ°CSVæ–‡ä»¶
        reasoning_used = force_reasoning or (model_client.enable_reasoning if not custom_model_id else False)
        
        save_to_csv(
            question=question,
            options=options,
            q_type=q_type_name,
            raw_answer=raw_answer,
            reasoning=reasoning,
            processed_answer=processed_answer,
            ai_time=ai_time,
            total_time=total_time,
            model_name=model_name,
            reasoning_used=reasoning_used,
            prompt_tokens=prompt_tokens,
            completion_tokens=completion_tokens,
            provider=actual_provider
        )
        
        # æ„å»ºå“åº”ï¼ˆOCSè„šæœ¬æ ¼å¼ï¼šè¿”å›[é¢˜ç›®, ç­”æ¡ˆ, extra_data]ï¼‰
        # extra_dataæ ¼å¼ï¼š{ai: true, tags: [{text, title, color}]}
        # æ³¨æ„ï¼šOCSè„šæœ¬ä¼šåœ¨ai=trueæ—¶è‡ªåŠ¨æ·»åŠ "AI"æ ‡ç­¾ï¼ˆè“è‰²ï¼‰
        # æ‰€ä»¥æˆ‘ä»¬åªéœ€è¦æ·»åŠ é¢å¤–çš„æ ‡ç­¾æ¥åŒºåˆ†æ€è€ƒ/éæ€è€ƒæ¨¡å¼
        
        # æ„å»ºæ ‡ç­¾
        tags = []
        
        # æ€è€ƒæ¨¡å¼ï¼šæ·»åŠ "æ·±åº¦æ€è€ƒ"æ ‡ç­¾ï¼ˆç´«è‰²ï¼‰ï¼ŒOCSä¼šè‡ªåŠ¨æ·»åŠ "AI"æ ‡ç­¾ï¼ˆè“è‰²ï¼‰
        if force_reasoning or model_client.enable_reasoning:
            tags.append({
                "text": "æ·±åº¦æ€è€ƒ",
                "title": "ä½¿ç”¨æ·±åº¦æ€è€ƒæ¨¡å¼ç”Ÿæˆï¼Œç­”æ¡ˆæ›´å‡†ç¡®",
                "color": "purple"  # OCSæ”¯æŒçš„é¢œè‰²ï¼šblue, green, red, yellow, gray, purple, orange
            })
            # å¦‚æœæ˜¯å¤šé€‰é¢˜è‡ªåŠ¨å¯ç”¨çš„æ€è€ƒæ¨¡å¼
            if force_reasoning:
                tags.append({
                    "text": "è‡ªåŠ¨æ€è€ƒ",
                    "title": "å¤šé€‰é¢˜è‡ªåŠ¨å¯ç”¨æ·±åº¦æ€è€ƒ",
                    "color": "orange"
                })
        # æ™®é€šæ¨¡å¼ï¼šä¸æ·»åŠ æ ‡ç­¾ï¼ŒOCSè„šæœ¬ä¼šè‡ªåŠ¨æ·»åŠ "AI"æ ‡ç­¾ï¼ˆè“è‰²ï¼‰
        
        # æ¨¡å‹æ ‡ç­¾
        if custom_model_id:
            # è‡ªå®šä¹‰æ¨¡å‹
            tags.append({
                "text": "è‡ªå®šä¹‰æ¨¡å‹",
                "title": f"ä½¿ç”¨è‡ªå®šä¹‰æ¨¡å‹: {model_name}",
                "color": "green"
            })
        elif model_client.is_auto_mode:
            # æ™ºèƒ½æ¨¡å¼ï¼šæ˜¾ç¤ºå®é™…ä½¿ç”¨çš„æ¨¡å‹
            auto_provider = model_client._select_model(image_urls if image_urls else None)[0]
            display_provider = auto_provider.upper()
            if auto_provider in model_client.models:
                display_model = model_client.models[auto_provider]
            else:
                display_model = "unknown"
            
            # æ·»åŠ æ™ºèƒ½é€‰æ‹©æ ‡ç­¾
            tags.append({
                "text": "æ™ºèƒ½é€‰æ‹©",
                "title": "æ ¹æ®é¢˜ç›®å†…å®¹è‡ªåŠ¨é€‰æ‹©æœ€åˆé€‚çš„æ¨¡å‹",
                "color": "blue"
            })
            tags.append({
                "text": display_provider,
                "title": f"å®é™…ä½¿ç”¨: {display_model}",
                "color": "green"
            })
        else:
            # é»˜è®¤æ¨¡å‹
            tags.append({
                "text": model_client.provider.upper(),
                "title": f"æ¨¡å‹: {model_name}",
                "color": "green"
            })
        
        # OCSè„šæœ¬æœŸæœ›çš„æ ¼å¼ï¼š[é¢˜ç›®, ç­”æ¡ˆ, extra_data]
        # ai=true ä¼šè®©OCSè‡ªåŠ¨æ·»åŠ "AI"æ ‡ç­¾
        # è®¡ç®—æ€»tokenæ•°
        total_tokens = prompt_tokens + completion_tokens
        
        ocs_format = [
            question,
            processed_answer,
            {
                "ai": True,  # OCSä¼šè‡ªåŠ¨æ·»åŠ "AI"æ ‡ç­¾
                "tags": tags,  # æˆ‘ä»¬æ·»åŠ çš„é¢å¤–æ ‡ç­¾ï¼ˆæ·±åº¦æ€è€ƒã€æ¨¡å‹ç­‰ï¼‰
                "model": model_name,
                "provider": model_client.provider,
                "reasoning_used": force_reasoning or model_client.enable_reasoning,
                "ai_time": round(ai_time, 2),
                "total_time": round(total_time, 2),
                # Tokenä½¿ç”¨é‡ï¼ˆä»APIå“åº”ä¸­æå–ï¼‰
                "usage": {
                    "prompt_tokens": prompt_tokens,
                    "completion_tokens": completion_tokens,
                    "total_tokens": total_tokens
                }
            }
        ]
        
        # è¿”å›å…¼å®¹æ ¼å¼ï¼ˆåŒæ—¶æ”¯æŒOCSæ ¼å¼å’ŒåŸå§‹æ ¼å¼ï¼‰
        if custom_model_id:
            response_provider = f"custom({custom_model_id})"
        elif model_client.is_auto_mode:
            auto_prov = model_client._select_model(image_urls if image_urls else None)[0]
            response_provider = f"auto({auto_prov})"
        else:
            response_provider = model_client.provider
        
        return jsonify({
            "success": True,
            "question": question,
            "answer": processed_answer,
            "type": q_type,
            "raw_answer": raw_answer,
            "model": model_name,
            "provider": response_provider,
            "reasoning_used": reasoning_used,
            "ai_time": round(ai_time, 2),
            "total_time": round(total_time, 2),
            # Tokenä½¿ç”¨é‡ï¼ˆä»APIå“åº”ä¸­æå–ï¼‰
            "usage": {
                "prompt_tokens": prompt_tokens,
                "completion_tokens": completion_tokens,
                "total_tokens": total_tokens
            },
            # OCSè„šæœ¬ç›´æ¥ä½¿ç”¨çš„æ ¼å¼
            "ocs_format": ocs_format
        })
    
    except Exception as e:
        error_time = time.time() - start_time
        print(f"\nâŒ é”™è¯¯: {str(e)}")
        print(f"â±ï¸  å¤„ç†ç”¨æ—¶: {format_time(error_time)}")
        print("="*80 + "\n")
        logger.error(f"å¤„ç†è¯·æ±‚é”™è¯¯: {str(e)}", exc_info=True)
        return jsonify({"success": False, "error": f"æœåŠ¡å™¨é”™è¯¯: {str(e)}"}), 500


# ==================== API è·¯ç”± ====================

@app.route('/api/health', methods=['GET'])
def health_check():
    """å¥åº·æ£€æŸ¥"""
    return jsonify({
        "status": "ok" if model_client else "error",
        "service": "OCS AI Answerer (Multi-Model)",
        "version": "3.0.0",
        "provider": MODEL_PROVIDER,
        "model": model_client.model if model_client else "æœªé…ç½®",
        "reasoning_enabled": ENABLE_REASONING,
        "api_configured": bool(
            (MODEL_PROVIDER == 'deepseek' and DEEPSEEK_API_KEY) or
            (MODEL_PROVIDER == 'doubao' and DOUBAO_API_KEY)
        ),
        "init_error": init_error if not model_client else None
    })


@app.route('/api/config', methods=['GET'])
@require_auth
def get_config():
    """è·å–å½“å‰é…ç½®ï¼ˆéœ€è¦è®¤è¯ï¼‰- è¿”å›å®Œæ•´å¯†é’¥"""
    # è¿”å›æ‰€æœ‰ç¯å¢ƒå˜é‡é…ç½®ï¼ˆç”¨äºé…ç½®é¢æ¿ï¼‰
    config = {
        # æ¨¡å‹æä¾›å•†é…ç½®
        "MODEL_PROVIDER": MODEL_PROVIDER,
        "AUTO_MODEL_SELECTION": str(model_client.is_auto_mode if model_client else False).lower(),
        "PREFER_MODEL": getattr(model_client, 'prefer_model', '') if model_client else '',
        "IMAGE_MODEL": getattr(model_client, 'image_model', '') if model_client else '',
        
        # DeepSeek é…ç½® - è¿”å›å®Œæ•´å¯†é’¥
        "DEEPSEEK_API_KEY": DEEPSEEK_API_KEY,
        "DEEPSEEK_BASE_URL": os.getenv('DEEPSEEK_BASE_URL', 'https://api.deepseek.com'),
        "DEEPSEEK_MODEL": os.getenv('DEEPSEEK_MODEL', 'deepseek-chat'),
        
        # è±†åŒ…é…ç½® - è¿”å›å®Œæ•´å¯†é’¥
        "DOUBAO_API_KEY": DOUBAO_API_KEY,
        "DOUBAO_BASE_URL": os.getenv('DOUBAO_BASE_URL', 'https://ark.cn-beijing.volces.com/api/v3'),
        "DOUBAO_MODEL": os.getenv('DOUBAO_MODEL', ''),
        
        # æ€è€ƒæ¨¡å¼é…ç½®
        "ENABLE_REASONING": str(ENABLE_REASONING).lower(),
        "REASONING_EFFORT": REASONING_EFFORT,
        "AUTO_REASONING_FOR_MULTIPLE": str(AUTO_REASONING_FOR_MULTIPLE).lower(),
        "AUTO_REASONING_FOR_IMAGES": str(AUTO_REASONING_FOR_IMAGES).lower(),
        
        # AI å‚æ•°é…ç½®
        "TEMPERATURE": str(TEMPERATURE),
        "MAX_TOKENS": str(MAX_TOKENS),
        "REASONING_MAX_TOKENS": str(os.getenv('REASONING_MAX_TOKENS', '4096')),
        "TOP_P": str(os.getenv('TOP_P', '1.0')),
        
        # ç½‘ç»œé…ç½®
        "HTTP_PROXY": os.getenv('HTTP_PROXY', ''),
        "HTTPS_PROXY": os.getenv('HTTPS_PROXY', ''),
        "TIMEOUT": str(os.getenv('TIMEOUT', '1200')),
        "MAX_RETRIES": str(os.getenv('MAX_RETRIES', '3')),
        
        # ç³»ç»Ÿé…ç½®
        "HOST": HOST,
        "PORT": str(PORT),
        "DEBUG": str(os.getenv('DEBUG', 'false')).lower(),
        "CSV_LOG_FILE": os.getenv('CSV_LOG_FILE', 'ocs_answers_log.csv'),
        "LOG_LEVEL": os.getenv('LOG_LEVEL', 'INFO'),
    }
    
    # æ·»åŠ è¿è¡Œæ—¶ä¿¡æ¯ï¼ˆç”¨äºçŠ¶æ€æ˜¾ç¤ºï¼‰
    config["_runtime"] = {
        "model": model_client.model if model_client else None,
        "auto_mode": model_client.is_auto_mode if model_client else False,
        "available_models": list(model_client.clients.keys()) if model_client and model_client.is_auto_mode else [],
        "deepseek_configured": "deepseek" in model_client.clients if model_client and model_client.is_auto_mode else bool(DEEPSEEK_API_KEY),
        "doubao_configured": "doubao" in model_client.clients if model_client and model_client.is_auto_mode else bool(DOUBAO_API_KEY)
    }
    
    return jsonify(config)


@app.route('/api/config', methods=['POST'])
@require_auth
def save_config():
    """ä¿å­˜é…ç½®åˆ° .env æ–‡ä»¶ï¼ˆéœ€è¦è®¤è¯ï¼‰- åŒ¹é…ä¿®æ”¹è€Œéè¦†ç›–"""
    try:
        config_data = request.get_json()
        if not config_data:
            return jsonify({"error": "æ— æ•ˆçš„é…ç½®æ•°æ®"}), 400
        
        # .env æ–‡ä»¶è·¯å¾„
        env_file = os.path.join(os.path.dirname(__file__), '.env')
        
        # è¯»å–ç°æœ‰çš„ .env æ–‡ä»¶å†…å®¹ï¼ˆé€è¡Œï¼‰
        lines = []
        if os.path.exists(env_file):
            with open(env_file, 'r', encoding='utf-8') as f:
                lines = f.readlines()
        
        # åˆ›å»ºé…ç½®é”®åˆ°æ–°å€¼çš„æ˜ å°„
        updated_keys = set()
        
        # é€è¡Œå¤„ç†ï¼ŒåŒ¹é…å¹¶ä¿®æ”¹
        new_lines = []
        for line in lines:
            stripped = line.strip()
            
            # ä¿ç•™æ³¨é‡Šå’Œç©ºè¡Œ
            if not stripped or stripped.startswith('#'):
                new_lines.append(line)
                continue
            
            # è§£æé…ç½®è¡Œ
            if '=' in stripped:
                key = stripped.split('=', 1)[0].strip()
                
                # å¦‚æœè¿™ä¸ªkeyåœ¨æ›´æ–°æ•°æ®ä¸­ï¼Œæ›¿æ¢å®ƒ
                if key in config_data:
                    value = config_data[key]
                    # å¤„ç†ç©ºå€¼
                    if value == '' or value is None:
                        new_lines.append(f"{key}=\n")
                    else:
                        new_lines.append(f"{key}={value}\n")
                    updated_keys.add(key)
                else:
                    # ä¿ç•™åŸæœ‰é…ç½®
                    new_lines.append(line)
            else:
                # ä¿ç•™æ ¼å¼ä¸æ­£ç¡®çš„è¡Œ
                new_lines.append(line)
        
        # æ·»åŠ æ–°çš„é…ç½®é¡¹ï¼ˆå¦‚æœæœ‰ï¼‰
        new_keys = set(config_data.keys()) - updated_keys
        if new_keys:
            new_lines.append("\n# æ–°å¢é…ç½®é¡¹\n")
            for key in sorted(new_keys):
                value = config_data[key]
                if value == '' or value is None:
                    new_lines.append(f"{key}=\n")
                else:
                    new_lines.append(f"{key}={value}\n")
        
        # å†™å…¥æ–‡ä»¶
        with open(env_file, 'w', encoding='utf-8') as f:
            f.writelines(new_lines)
        
        logger.info(f"é…ç½®å·²ä¿å­˜åˆ° {env_file}ï¼Œæ›´æ–°äº† {len(updated_keys)} ä¸ªé…ç½®é¡¹ï¼Œæ–°å¢äº† {len(new_keys)} ä¸ªé…ç½®é¡¹")
        return jsonify({
            "success": True,
            "message": "é…ç½®å·²æˆåŠŸä¿å­˜åˆ° .env æ–‡ä»¶",
            "file": env_file,
            "updated": len(updated_keys),
            "added": len(new_keys),
            "note": "è¯·é‡å¯æœåŠ¡ä»¥åº”ç”¨æ–°é…ç½®"
        })
        
    except Exception as e:
        logger.error(f"ä¿å­˜é…ç½®å¤±è´¥: {str(e)}")
        return jsonify({"error": f"ä¿å­˜é…ç½®å¤±è´¥: {str(e)}"}), 500


@app.route('/api/restart', methods=['POST'])
@require_auth
def restart_server():
    """é‡å¯æœåŠ¡å™¨ï¼ˆéœ€è¦è®¤è¯ï¼‰"""
    try:
        import sys
        import os
        import threading
        import subprocess
        
        def do_restart():
            """å»¶è¿Ÿé‡å¯ä»¥ä¾¿å“åº”è¿”å›"""
            import time
            time.sleep(1)  # ç­‰å¾…å“åº”è¿”å›
            logger.info("æ­£åœ¨é‡å¯æœåŠ¡å™¨...")
            
            # æ£€æµ‹æ˜¯å¦ä¸º PyInstaller æ‰“åŒ…ç¯å¢ƒ
            if getattr(sys, 'frozen', False):
                # æ‰“åŒ…åçš„ exe ç¯å¢ƒ
                executable = sys.executable  # exe æ–‡ä»¶è·¯å¾„
                logger.info(f"æ£€æµ‹åˆ°æ‰“åŒ…ç¯å¢ƒï¼Œé‡å¯ exe: {executable}")
                
                # ç›´æ¥å¯åŠ¨æ–°çš„ exe è¿›ç¨‹
                if os.name == 'nt':  # Windows
                    subprocess.Popen([executable], 
                                   creationflags=subprocess.CREATE_NEW_CONSOLE)
                else:  # Linux/Mac
                    subprocess.Popen([executable])
                
                # é€€å‡ºå½“å‰è¿›ç¨‹
                os._exit(0)
            else:
                # æ™®é€š Python è„šæœ¬ç¯å¢ƒ
                python = sys.executable
                script = os.path.abspath(__file__)
                logger.info(f"æ£€æµ‹åˆ°è„šæœ¬ç¯å¢ƒï¼Œé‡å¯: {python} {script}")
                
                if os.name == 'nt':  # Windows
                    subprocess.Popen([python, script], 
                                   creationflags=subprocess.CREATE_NEW_CONSOLE)
                    os._exit(0)
                else:  # Linux/Mac
                    os.execv(python, [python, script])
        
        # åœ¨åå°çº¿ç¨‹ä¸­æ‰§è¡Œé‡å¯
        threading.Thread(target=do_restart, daemon=True).start()
        
        return jsonify({
            "success": True,
            "message": "æœåŠ¡å™¨å°†åœ¨ 1 ç§’åé‡å¯"
        })
        
    except Exception as e:
        logger.error(f"é‡å¯æœåŠ¡å™¨å¤±è´¥: {str(e)}")
        return jsonify({"error": f"é‡å¯å¤±è´¥: {str(e)}"}), 500


@app.route('/api/csv/stats', methods=['GET'])
def get_csv_stats():
    """è·å–CSVç»Ÿè®¡æ•°æ®ï¼ˆæ”¯æŒç­›é€‰ï¼‰"""
    csv_file = os.getenv('CSV_LOG_FILE', 'ocs_answers_log.csv')
    
    # è·å–ç­›é€‰å‚æ•°
    search = request.args.get('search', '')
    question_type = request.args.get('type', '')
    reasoning = request.args.get('reasoning', '')
    date_filter = request.args.get('date', 'all')
    custom_date = request.args.get('custom_date', '')
    
    try:
        if not os.path.exists(csv_file):
            return jsonify({"error": "CSVæ–‡ä»¶ä¸å­˜åœ¨"}), 404
        
        # è¯»å–å¹¶è§£æCSV
        import csv as csv_module
        stats = {
            'total': 0,
            'avgTime': 0,
            'reasoningCount': 0,
            'totalTime': 0,
            'totalCost': 0,
            'totalTokens': 0,
            'inputTokens': 0,
            'outputTokens': 0,
            'typeCounts': {},
            'timeRanges': {'0-2ç§’': 0, '2-5ç§’': 0, '5-10ç§’': 0, '10ç§’ä»¥ä¸Š': 0},
            'reasoningCounts': {'æ€è€ƒæ¨¡å¼': 0, 'æ™®é€šæ¨¡å¼': 0},
            'dailyCounts': {}
        }
        
        with open(csv_file, 'r', encoding='utf-8-sig') as f:
            reader = csv_module.DictReader(f)
            total_ai_time = 0
            
            for row in reader:
                # åº”ç”¨ç­›é€‰
                row_text = '|'.join(row.values()).lower()
                if search and search.lower() not in row_text:
                    continue
                if question_type and row.get('é¢˜å‹', '') != question_type:
                    continue
                if reasoning and row.get('æ€è€ƒæ¨¡å¼', '') != reasoning:
                    continue
                # TODO: æ—¥æœŸç­›é€‰
                
                # ç»Ÿè®¡
                stats['total'] += 1
                
                # AIè€—æ—¶
                ai_time = float(row.get('AIè€—æ—¶(ç§’)', 0) or 0)
                total_ai_time += ai_time
                
                # æ€»è€—æ—¶
                stats['totalTime'] += float(row.get('æ€»è€—æ—¶(ç§’)', 0) or 0)
                
                # è´¹ç”¨
                stats['totalCost'] += float(row.get('è´¹ç”¨(å…ƒ)', 0) or 0)
                
                # Tokenç»Ÿè®¡
                stats['totalTokens'] += int(row.get('æ€»Token', 0) or 0)
                stats['inputTokens'] += int(row.get('è¾“å…¥Token', 0) or 0)
                stats['outputTokens'] += int(row.get('è¾“å‡ºToken', 0) or 0)
                
                # æ€è€ƒæ¨¡å¼
                if row.get('æ€è€ƒæ¨¡å¼', '') == 'æ˜¯':
                    stats['reasoningCount'] += 1
                    stats['reasoningCounts']['æ€è€ƒæ¨¡å¼'] += 1
                else:
                    stats['reasoningCounts']['æ™®é€šæ¨¡å¼'] += 1
                
                # é¢˜å‹åˆ†å¸ƒ
                q_type = row.get('é¢˜å‹', 'æœªçŸ¥')
                stats['typeCounts'][q_type] = stats['typeCounts'].get(q_type, 0) + 1
                
                # è€—æ—¶åˆ†å¸ƒ
                if ai_time <= 2:
                    stats['timeRanges']['0-2ç§’'] += 1
                elif ai_time <= 5:
                    stats['timeRanges']['2-5ç§’'] += 1
                elif ai_time <= 10:
                    stats['timeRanges']['5-10ç§’'] += 1
                else:
                    stats['timeRanges']['10ç§’ä»¥ä¸Š'] += 1
                
                # æ¯æ—¥ç­”é¢˜é‡
                timestamp = row.get('æ—¶é—´æˆ³', '')
                if timestamp:
                    date = timestamp.split(' ')[0]
                    stats['dailyCounts'][date] = stats['dailyCounts'].get(date, 0) + 1
        
        # è®¡ç®—å¹³å‡å€¼
        if stats['total'] > 0:
            stats['avgTime'] = total_ai_time / stats['total']
            stats['totalTime'] = stats['totalTime'] / 60  # è½¬æ¢ä¸ºåˆ†é’Ÿ
        
        return jsonify(stats)
        
    except Exception as e:
        logger.error(f"è·å–ç»Ÿè®¡æ•°æ®å¤±è´¥: {str(e)}")
        return jsonify({"error": f"è·å–ç»Ÿè®¡æ•°æ®å¤±è´¥: {str(e)}"}), 500


@app.route('/api/csv', methods=['GET'])
def get_csv():
    """è·å–CSVæ—¥å¿—æ–‡ä»¶ï¼ˆè¿”å›JSONæ ¼å¼ï¼Œæ”¯æŒåˆ†é¡µå’Œç­›é€‰ï¼Œæ—¶é—´å€’åºï¼‰"""
    csv_file = os.getenv('CSV_LOG_FILE', 'ocs_answers_log.csv')
    
    # è·å–åˆ†é¡µå‚æ•°
    page = request.args.get('page', type=int)
    page_size = request.args.get('page_size', type=int)
    export_all = request.args.get('export', '') == 'true'  # æ˜¯å¦å¯¼å‡ºå…¨éƒ¨æ•°æ®
    
    # è·å–ç­›é€‰å‚æ•°
    search = request.args.get('search', '')
    question_type = request.args.get('type', '')
    reasoning = request.args.get('reasoning', '')
    date_filter = request.args.get('date', 'all')
    custom_date = request.args.get('custom_date', '')
    
    try:
        if not os.path.exists(csv_file):
            return jsonify({"error": "CSVæ–‡ä»¶ä¸å­˜åœ¨"}), 404
        
        # ä½¿ç”¨DictReaderè§£æCSVä¸ºå­—å…¸åˆ—è¡¨
        all_data = []
        with open(csv_file, 'r', encoding='utf-8-sig') as f:
            reader = csv.DictReader(f)
            for row in reader:
                # åº”ç”¨ç­›é€‰
                if search and search.lower() not in str(row).lower():
                    continue
                if question_type and row.get('é¢˜å‹', '') != question_type:
                    continue
                if reasoning:
                    if reasoning == 'æ€è€ƒæ¨¡å¼':
                        if row.get('æ€è€ƒæ¨¡å¼', 'å¦') == 'å¦':
                            continue
                    elif reasoning == 'æ™®é€šæ¨¡å¼':
                        if row.get('æ€è€ƒæ¨¡å¼', 'å¦') != 'å¦':
                            continue
                
                # æ—¥æœŸç­›é€‰
                if date_filter != 'all':
                    timestamp = row.get('æ—¶é—´æˆ³', '')
                    if timestamp:
                        try:
                            from datetime import datetime, timedelta
                            record_date = datetime.strptime(timestamp.split()[0], '%Y-%m-%d')
                            today = datetime.now().replace(hour=0, minute=0, second=0, microsecond=0)
                            
                            if date_filter == 'today':
                                if record_date.date() != today.date():
                                    continue
                            elif date_filter == 'week':
                                week_ago = today - timedelta(days=7)
                                if record_date < week_ago:
                                    continue
                            elif date_filter == 'month':
                                month_ago = today - timedelta(days=30)
                                if record_date < month_ago:
                                    continue
                            elif date_filter == 'custom' and custom_date:
                                date_range = custom_date.split(',')
                                if len(date_range) == 2:
                                    start_date = datetime.strptime(date_range[0], '%Y-%m-%d')
                                    end_date = datetime.strptime(date_range[1], '%Y-%m-%d')
                                    if not (start_date <= record_date <= end_date):
                                        continue
                        except:
                            pass
                
                all_data.append(row)
        
        # æŒ‰æ—¶é—´æˆ³å€’åºæ’åºï¼ˆæœ€æ–°çš„åœ¨å‰é¢ï¼‰
        all_data.sort(key=lambda x: x.get('æ—¶é—´æˆ³', ''), reverse=True)
        
        total = len(all_data)
        
        # å¦‚æœæ˜¯å¯¼å‡ºå…¨éƒ¨æ•°æ®
        if export_all:
            return jsonify({
                "data": all_data,
                "total": total
            })
        
        # å¦‚æœæ²¡æœ‰åˆ†é¡µå‚æ•°ï¼Œè¿”å›å…¨éƒ¨æ•°æ®
        if page is None or page_size is None:
            return jsonify({
                "data": all_data,
                "total": total
            })
        
        # åˆ†é¡µå¤„ç†
        total_pages = (total + page_size - 1) // page_size if total > 0 else 0
        start = (page - 1) * page_size
        end = min(start + page_size, total)
        
        if start >= total or start < 0:
            paginated_data = []
        else:
            paginated_data = all_data[start:end]
        
        return jsonify({
            "data": paginated_data,
            "total": total,
            "page": page,
            "page_size": page_size,
            "total_pages": total_pages
        })
        
    except Exception as e:
        logger.error(f"è¯»å–CSVæ–‡ä»¶å¤±è´¥: {str(e)}")
        return jsonify({"error": f"è¯»å–CSVæ–‡ä»¶å¤±è´¥: {str(e)}"}), 500


@app.route('/api/csv/clear', methods=['POST'])
@require_auth
def clear_csv():
    """æ¸…ç©ºCSVæ—¥å¿—æ–‡ä»¶ï¼ˆä¿ç•™è¡¨å¤´ï¼Œéœ€è¦è®¤è¯ï¼‰"""
    csv_file = os.getenv('CSV_LOG_FILE', 'ocs_answers_log.csv')
    
    try:
        # CSVè¡¨å¤´
        headers = [
            'æ—¶é—´æˆ³', 'é¢˜å‹', 'é¢˜ç›®', 'é€‰é¡¹', 'åŸå§‹å›ç­”', 'æ€è€ƒè¿‡ç¨‹', 
            'å¤„ç†åç­”æ¡ˆ', 'AIè€—æ—¶(ç§’)', 'æ€»è€—æ—¶(ç§’)', 'æ¨¡å‹', 'æ€è€ƒæ¨¡å¼',
            'è¾“å…¥Token', 'è¾“å‡ºToken', 'æ€»Token', 'è´¹ç”¨(å…ƒ)', 'æä¾›å•†'
        ]
        
        # å†™å…¥ç©ºæ–‡ä»¶ï¼ˆåªä¿ç•™è¡¨å¤´ï¼‰
        with open(csv_file, 'w', newline='', encoding='utf-8-sig') as f:
            writer = csv.writer(f)
            writer.writerow(headers)
        
        logger.info(f"CSVæ–‡ä»¶å·²æ¸…ç©º: {csv_file}")
        return jsonify({
            "success": True,
            "message": "CSVæ–‡ä»¶å·²æ¸…ç©ºï¼ˆä¿ç•™è¡¨å¤´ï¼‰",
            "file": csv_file
        })
    except Exception as e:
        logger.error(f"æ¸…ç©ºCSVæ–‡ä»¶å¤±è´¥: {str(e)}")
        return jsonify({"success": False, "error": f"æ¸…ç©ºCSVæ–‡ä»¶å¤±è´¥: {str(e)}"}), 500


# ==================== è‡ªå®šä¹‰æ¨¡å‹ç®¡ç†API ====================

@app.route('/api/models', methods=['GET'])
@require_auth
def get_custom_models():
    """
    è·å–æ‰€æœ‰è‡ªå®šä¹‰æ¨¡å‹åˆ—è¡¨ï¼ˆéœ€è¦è®¤è¯ï¼‰
    
    æŸ¥è¯¢å‚æ•°:
        enabled_only: æ˜¯å¦åªè¿”å›å¯ç”¨çš„æ¨¡å‹ï¼ˆtrue/falseï¼‰
    
    å“åº”:
        {
            "success": true,
            "models": {
                "model_id": {...},
                ...
            },
            "question_type_models": {...}
        }
    """
    try:
        enabled_only = request.args.get('enabled_only', 'false').lower() == 'true'
        models = custom_model_manager.get_all_models(enabled_only=enabled_only)
        
        # ç§»é™¤æ•æ„Ÿä¿¡æ¯ï¼ˆAPIå¯†é’¥åªè¿”å›éƒ¨åˆ†ï¼‰
        safe_models = {}
        for model_id, config in models.items():
            safe_config = config.copy()
            if 'api_key' in safe_config and safe_config['api_key']:
                # åªæ˜¾ç¤ºå‰4ä½å’Œå4ä½
                key = safe_config['api_key']
                if len(key) > 8:
                    safe_config['api_key'] = key[:4] + '*' * (len(key) - 8) + key[-4:]
            safe_models[model_id] = safe_config
        
        return jsonify({
            "success": True,
            "models": safe_models,
            "question_type_models": custom_model_manager.question_type_models
        })
    except Exception as e:
        logger.error(f"è·å–è‡ªå®šä¹‰æ¨¡å‹åˆ—è¡¨å¤±è´¥: {str(e)}")
        return jsonify({"success": False, "error": str(e)}), 500


@app.route('/api/models/<model_id>', methods=['GET'])
@require_auth
def get_custom_model(model_id):
    """è·å–å•ä¸ªè‡ªå®šä¹‰æ¨¡å‹è¯¦æƒ…ï¼ˆéœ€è¦è®¤è¯ï¼‰"""
    try:
        model = custom_model_manager.get_model(model_id)
        if not model:
            return jsonify({"success": False, "error": "æ¨¡å‹ä¸å­˜åœ¨"}), 404
        
        # ç§»é™¤æ•æ„Ÿä¿¡æ¯
        safe_model = model.copy()
        if 'api_key' in safe_model and safe_model['api_key']:
            key = safe_model['api_key']
            if len(key) > 8:
                safe_model['api_key'] = key[:4] + '*' * (len(key) - 8) + key[-4:]
        
        return jsonify({
            "success": True,
            "model": safe_model
        })
    except Exception as e:
        logger.error(f"è·å–æ¨¡å‹è¯¦æƒ…å¤±è´¥: {str(e)}")
        return jsonify({"success": False, "error": str(e)}), 500


@app.route('/api/models', methods=['POST'])
@require_auth
def add_custom_model():
    """
    æ·»åŠ è‡ªå®šä¹‰æ¨¡å‹ï¼ˆéœ€è¦è®¤è¯ï¼‰
    
    è¯·æ±‚ä½“:
        {
            "model_id": "my_model",
            "name": "æˆ‘çš„æ¨¡å‹",
            "provider": "openai",
            "api_key": "sk-xxx",
            "base_url": "https://api.example.com/v1",
            "model_name": "gpt-4",
            "is_multimodal": false,
            "max_tokens": 2000,
            "temperature": 0.1,
            "top_p": 0.95,
            "supports_reasoning": false
        }
    """
    try:
        data = request.get_json()
        if not data:
            return jsonify({"success": False, "error": "æ— æ•ˆçš„è¯·æ±‚æ•°æ®"}), 400
        
        model_id = data.get('model_id')
        if not model_id:
            return jsonify({"success": False, "error": "ç¼ºå°‘model_id"}), 400
        
        # ç§»é™¤model_idï¼Œå› ä¸ºå®ƒä½œä¸ºé”®ä½¿ç”¨
        model_config = {k: v for k, v in data.items() if k != 'model_id'}
        
        success, message = custom_model_manager.add_model(model_id, model_config)
        
        if success:
            return jsonify({"success": True, "message": message})
        else:
            return jsonify({"success": False, "error": message}), 400
    except Exception as e:
        logger.error(f"æ·»åŠ è‡ªå®šä¹‰æ¨¡å‹å¤±è´¥: {str(e)}")
        return jsonify({"success": False, "error": str(e)}), 500


@app.route('/api/models/<model_id>', methods=['PUT'])
@require_auth
def update_custom_model(model_id):
    """
    æ›´æ–°è‡ªå®šä¹‰æ¨¡å‹ï¼ˆéœ€è¦è®¤è¯ï¼‰
    
    è¯·æ±‚ä½“: åŒæ·»åŠ æ¨¡å‹ï¼Œä½†æ‰€æœ‰å­—æ®µéƒ½æ˜¯å¯é€‰çš„
    """
    try:
        data = request.get_json()
        if not data:
            return jsonify({"success": False, "error": "æ— æ•ˆçš„è¯·æ±‚æ•°æ®"}), 400
        
        success, message = custom_model_manager.update_model(model_id, data)
        
        if success:
            return jsonify({"success": True, "message": message})
        else:
            return jsonify({"success": False, "error": message}), 400
    except Exception as e:
        logger.error(f"æ›´æ–°è‡ªå®šä¹‰æ¨¡å‹å¤±è´¥: {str(e)}")
        return jsonify({"success": False, "error": str(e)}), 500


@app.route('/api/models/<model_id>', methods=['DELETE'])
@require_auth
def delete_custom_model(model_id):
    """åˆ é™¤è‡ªå®šä¹‰æ¨¡å‹ï¼ˆéœ€è¦è®¤è¯ï¼‰"""
    try:
        success, message = custom_model_manager.delete_model(model_id)
        
        if success:
            return jsonify({"success": True, "message": message})
        else:
            return jsonify({"success": False, "error": message}), 400
    except Exception as e:
        logger.error(f"åˆ é™¤è‡ªå®šä¹‰æ¨¡å‹å¤±è´¥: {str(e)}")
        return jsonify({"success": False, "error": str(e)}), 500


@app.route('/api/models/question-types/<question_type>', methods=['GET'])
@require_auth
def get_question_type_models(question_type):
    """
    è·å–æŒ‡å®šé¢˜å‹ä½¿ç”¨çš„æ¨¡å‹åˆ—è¡¨ï¼ˆéœ€è¦è®¤è¯ï¼‰
    
    è·¯å¾„å‚æ•°:
        question_type: single/multiple/judgement/completion/image
    """
    try:
        model_ids = custom_model_manager.get_question_type_models(question_type)
        return jsonify({
            "success": True,
            "question_type": question_type,
            "model_ids": model_ids
        })
    except Exception as e:
        logger.error(f"è·å–é¢˜å‹æ¨¡å‹åˆ—è¡¨å¤±è´¥: {str(e)}")
        return jsonify({"success": False, "error": str(e)}), 500


@app.route('/api/models/question-types/<question_type>', methods=['PUT'])
@require_auth
def set_question_type_models(question_type):
    """
    è®¾ç½®æŒ‡å®šé¢˜å‹ä½¿ç”¨çš„æ¨¡å‹åˆ—è¡¨å’Œæ€è€ƒé…ç½®ï¼ˆéœ€è¦è®¤è¯ï¼‰
    
    è¯·æ±‚ä½“:
        {
            "model_ids": ["model1", "model2", ...],
            "enable_reasoning": true/false  // å¯é€‰ï¼Œæ˜¯å¦å¯ç”¨æ€è€ƒæ¨¡å¼
        }
    
    è¯´æ˜:
        - åˆ—è¡¨æŒ‰ä¼˜å…ˆçº§æ’åºï¼Œç³»ç»Ÿä¼šä¼˜å…ˆä½¿ç”¨é å‰çš„æ¨¡å‹
        - å¯¹äºå›¾ç‰‡é¢˜ï¼Œä¼šè‡ªåŠ¨é€‰æ‹©æ”¯æŒå¤šæ¨¡æ€çš„æ¨¡å‹
        - enable_reasoning: ä¸ºè¯¥é¢˜å‹å¯ç”¨æ€è€ƒæ¨¡å¼ï¼ˆåŸç”Ÿæ€è€ƒæ¨¡å‹ä¼šè‡ªåŠ¨å¯ç”¨ï¼Œæ— éœ€é…ç½®ï¼‰
    """
    try:
        data = request.get_json()
        if not data:
            return jsonify({"success": False, "error": "æ— æ•ˆçš„è¯·æ±‚æ•°æ®"}), 400
        
        model_ids = data.get('model_ids', [])
        if not isinstance(model_ids, list):
            return jsonify({"success": False, "error": "model_idså¿…é¡»æ˜¯æ•°ç»„"}), 400
        
        # è·å–æ€è€ƒæ¨¡å¼é…ç½®ï¼ˆå¯é€‰ï¼‰
        enable_reasoning = data.get('enable_reasoning', None)
        
        success, message = custom_model_manager.set_question_type_models(
            question_type, 
            model_ids,
            enable_reasoning
        )
        
        if success:
            return jsonify({"success": True, "message": message})
        else:
            return jsonify({"success": False, "error": message}), 400
    except Exception as e:
        logger.error(f"è®¾ç½®é¢˜å‹æ¨¡å‹åˆ—è¡¨å¤±è´¥: {str(e)}")
        return jsonify({"success": False, "error": str(e)}), 500


@app.route('/api/models/test/<model_id>', methods=['POST'])
@require_auth
def test_custom_model(model_id):
    """
    æµ‹è¯•è‡ªå®šä¹‰æ¨¡å‹è¿æ¥ï¼ˆéœ€è¦è®¤è¯ï¼‰
    
    è¯·æ±‚ä½“:
        {
            "test_prompt": "ä½ å¥½"  // å¯é€‰ï¼Œé»˜è®¤ä¸ºç®€å•æµ‹è¯•
        }
    
    å“åº”:
        {
            "success": true,
            "response": "æ¨¡å‹è¿”å›å†…å®¹",
            "latency": 1.23,
            "tokens": {...}
        }
    """
    try:
        model = custom_model_manager.get_model(model_id)
        if not model:
            return jsonify({"success": False, "error": "æ¨¡å‹ä¸å­˜åœ¨"}), 404
        
        data = request.get_json() or {}
        test_prompt = data.get('test_prompt', 'è¯·ç”¨ä¸€å¥è¯ä»‹ç»ä½ è‡ªå·±')
        
        # åˆ›å»ºä¸´æ—¶å®¢æˆ·ç«¯æµ‹è¯•è¿æ¥
        import httpx
        from openai import OpenAI
        
        start_time = time.time()
        
        try:
            test_client = OpenAI(
                api_key=model['api_key'],
                base_url=model['base_url'],
                http_client=httpx.Client(timeout=30.0),
                max_retries=1
            )
            
            response = test_client.chat.completions.create(
                model=model['model_name'],
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªæœ‰å¸®åŠ©çš„AIåŠ©æ‰‹ã€‚"},
                    {"role": "user", "content": test_prompt}
                ],
                max_tokens=100,
                temperature=0.7
            )
            
            latency = time.time() - start_time
            
            result = {
                "success": True,
                "response": response.choices[0].message.content.strip(),
                "latency": round(latency, 2),
                "tokens": {
                    "prompt": response.usage.prompt_tokens if hasattr(response.usage, 'prompt_tokens') else 0,
                    "completion": response.usage.completion_tokens if hasattr(response.usage, 'completion_tokens') else 0,
                    "total": response.usage.total_tokens if hasattr(response.usage, 'total_tokens') else 0
                }
            }
            
            logger.info(f"âœ… æ¨¡å‹æµ‹è¯•æˆåŠŸ: {model_id}, å»¶è¿Ÿ: {latency:.2f}ç§’")
            return jsonify(result)
            
        except Exception as e:
            error_msg = str(e)
            logger.error(f"âŒ æ¨¡å‹æµ‹è¯•å¤±è´¥: {model_id}, é”™è¯¯: {error_msg}")
            return jsonify({
                "success": False,
                "error": f"è¿æ¥æµ‹è¯•å¤±è´¥: {error_msg}"
            }), 400
            
    except Exception as e:
        logger.error(f"æµ‹è¯•æ¨¡å‹å¤±è´¥: {str(e)}")
        return jsonify({"success": False, "error": str(e)}), 500


# ==================== å®‰å…¨è®¤è¯API ====================

@app.route('/api/auth/verify', methods=['POST'])
def verify_auth():
    """éªŒè¯APIå¯†é’¥æ˜¯å¦æœ‰æ•ˆ"""
    try:
        data = request.get_json()
        api_key = data.get('api_key', '')
        
        if not api_key:
            return jsonify({"valid": False, "error": "ç¼ºå°‘APIå¯†é’¥"}), 400
        
        # éªŒè¯å¯†é’¥
        is_valid = security_manager.verify_key(api_key)
        
        if is_valid:
            return jsonify({"valid": True})
        else:
            return jsonify({"valid": False, "error": "å¯†é’¥æ— æ•ˆ"}), 403
    except Exception as e:
        logger.error(f"éªŒè¯å¯†é’¥å¤±è´¥: {str(e)}")
        return jsonify({"valid": False, "error": str(e)}), 500


@app.route('/api/auth/update-key', methods=['POST'])
@require_auth
def update_secret_key():
    """æ›´æ–°è®¿é—®å¯†é’¥ï¼ˆéœ€è¦æ—§å¯†é’¥è®¤è¯ï¼‰"""
    try:
        data = request.get_json()
        old_key = data.get('old_key', '')
        new_key = data.get('new_key', '')
        
        if not old_key or not new_key:
            return jsonify({"success": False, "error": "ç¼ºå°‘å¿…è¦å‚æ•°"}), 400
        
        # æ›´æ–°å¯†é’¥
        success, message = security_manager.update_key(old_key, new_key)
        
        if success:
            return jsonify({"success": True, "message": message})
        else:
            return jsonify({"success": False, "error": message}), 400
    except Exception as e:
        logger.error(f"æ›´æ–°å¯†é’¥å¤±è´¥: {str(e)}")
        return jsonify({"success": False, "error": str(e)}), 500


@app.route('/api/auth/status', methods=['GET'])
def auth_status():
    """è·å–è®¤è¯çŠ¶æ€ï¼ˆä¸éœ€è¦å¯†é’¥ï¼Œç”¨äºæ£€æŸ¥æ˜¯å¦å¯ç”¨äº†è®¤è¯ï¼‰"""
    return jsonify({
        "auth_enabled": True,
        "message": "æ­¤æœåŠ¡éœ€è¦APIå¯†é’¥æ‰èƒ½è®¿é—®æ•æ„Ÿæ¥å£"
    })


# ==================== Vue SPA é™æ€æ–‡ä»¶æœåŠ¡ ====================

@app.route('/assets/<path:filename>')
def serve_assets(filename):
    """æä¾›Vueæ‰“åŒ…åçš„é™æ€èµ„æº"""
    dist_dir = os.path.join(os.path.dirname(__file__), 'dist', 'assets')
    return send_from_directory(dist_dir, filename)


@app.route('/', defaults={'path': ''})
@app.route('/<path:path>')
def serve_spa(path):
    """
    æœåŠ¡ Vue SPA åº”ç”¨
    - å¦‚æœè¯·æ±‚çš„æ˜¯ API è·¯å¾„ï¼Œè·³è¿‡ï¼ˆç”±å…¶ä»–è·¯ç”±å¤„ç†ï¼‰
    - å¦‚æœè¯·æ±‚æœ‰æ—¶é—´æˆ³å‚æ•° (?t=...)ï¼Œä½œä¸ºå»¶è¿Ÿæµ‹è¯•
    - å¦åˆ™è¿”å› Vue åº”ç”¨çš„ index.html
    """
    # API è·¯å¾„å·²ç»è¢«ä¸Šé¢çš„è·¯ç”±å¤„ç†ï¼Œè¿™é‡Œä¸åº”è¯¥è¢«è§¦å‘
    if path.startswith('api/'):
        return jsonify({"error": "API endpoint not found"}), 404
    
    # å»¶è¿Ÿæµ‹è¯•ï¼ˆå‘åå…¼å®¹æ—§çš„ OCS è„šæœ¬ï¼‰
    timestamp = request.args.get('t', None)
    if timestamp and request.method in ['HEAD', 'GET']:
        response = make_response('', 200)
        response.headers['Content-Type'] = 'text/plain; charset=utf-8'
        response.headers['X-Service'] = 'OCS AI Answerer'
        response.headers['X-Version'] = '3.0.0'
        
        try:
            client_timestamp = int(timestamp) / 1000
            server_timestamp = time.time()
            latency = (server_timestamp - client_timestamp) * 1000
            response.headers['X-Latency'] = f"{latency:.2f}ms"
        except (ValueError, TypeError):
            pass
        
        if request.method == 'GET':
            response.set_data('OK')
        
        return response
    
    # æœåŠ¡ Vue SPA
    dist_dir = os.path.join(os.path.dirname(__file__), 'dist')
    index_file = os.path.join(dist_dir, 'index.html')
    
    # å¦‚æœ dist ç›®å½•ä¸å­˜åœ¨ï¼Œæç¤ºéœ€è¦æ„å»ºå‰ç«¯
    if not os.path.exists(dist_dir) or not os.path.exists(index_file):
        return jsonify({
            "error": "å‰ç«¯åº”ç”¨æœªæ„å»º",
            "message": "è¯·å…ˆæ„å»ºå‰ç«¯åº”ç”¨ï¼šcd frontend && npm install && npm run build",
            "note": "æˆ–è€…ä½¿ç”¨æ—§ç‰ˆHTMLç•Œé¢ï¼Œè®¿é—® /config_legacy"
        }), 503
    
    # è¿”å› Vue åº”ç”¨çš„ index.html
    try:
        with open(index_file, 'r', encoding='utf-8') as f:
            html_content = f.read()
        response = make_response(html_content)
        response.headers['Content-Type'] = 'text/html; charset=utf-8'
        return response
    except Exception as e:
        logger.error(f"åŠ è½½Vueåº”ç”¨å¤±è´¥: {str(e)}")
        return jsonify({"error": f"åŠ è½½å‰ç«¯åº”ç”¨å¤±è´¥: {str(e)}"}), 500


# ==================== æ—§ç‰ˆHTMLé¡µé¢è·¯ç”±(å‘åå…¼å®¹) ====================

@app.route('/config_legacy', methods=['GET'])
def config_panel_legacy():
    """é…ç½®ç®¡ç†é¢æ¿ (æ—§ç‰ˆHTML)"""
    html_file = os.path.join(os.path.dirname(__file__), 'config_panel.html')
    
    try:
        if os.path.exists(html_file):
            with open(html_file, 'r', encoding='utf-8') as f:
                html_content = f.read()
            
            response = make_response(html_content)
            response.headers['Content-Type'] = 'text/html; charset=utf-8'
            return response
        else:
            return jsonify({"error": "é…ç½®é¢æ¿æ–‡ä»¶ä¸å­˜åœ¨"}), 404
    except Exception as e:
        logger.error(f"åŠ è½½é…ç½®é¢æ¿å¤±è´¥: {str(e)}")
        return jsonify({"error": f"åŠ è½½é…ç½®é¢æ¿å¤±è´¥: {str(e)}"}), 500


@app.route('/viewer_legacy', methods=['GET'])
def viewer_legacy():
    """ç­”é¢˜è®°å½•å¯è§†åŒ–é¡µé¢ (æ—§ç‰ˆHTML)"""
    html_file = os.path.join(os.path.dirname(__file__), 'ocs_answers_viewer.html')
    
    try:
        if os.path.exists(html_file):
            with open(html_file, 'r', encoding='utf-8') as f:
                html_content = f.read()
            
            # ä¿®æ”¹HTMLä¸­çš„fetchè·¯å¾„ï¼Œä½¿å…¶æŒ‡å‘Flask API
            html_content = html_content.replace(
                "fetch('ocs_answers_log.csv')",
                "fetch('/api/csv')"
            )
            html_content = html_content.replace(
                'fetch("ocs_answers_log.csv")',
                'fetch("/api/csv")'
            )
            html_content = html_content.replace(
                '<script src="chart.js.min.js"></script>',
                '<script src="https://cdn.jsdelivr.net/npm/chart.js@4.4.0/dist/chart.umd.min.js"></script>'
            )
            
            response = make_response(html_content)
            response.headers['Content-Type'] = 'text/html; charset=utf-8'
            return response
        else:
            return jsonify({"error": "å¯è§†åŒ–é¡µé¢æ–‡ä»¶ä¸å­˜åœ¨"}), 404
    except Exception as e:
        logger.error(f"åŠ è½½å¯è§†åŒ–é¡µé¢å¤±è´¥: {str(e)}")
        return jsonify({"error": f"åŠ è½½å¯è§†åŒ–é¡µé¢å¤±è´¥: {str(e)}"}), 500


@app.route('/docs_legacy', methods=['GET'])
def api_docs_legacy():
    """APIæ–‡æ¡£é¡µé¢ (æ—§ç‰ˆHTML)"""
    html_file = os.path.join(os.path.dirname(__file__), 'api_docs.html')
    
    try:
        if os.path.exists(html_file):
            with open(html_file, 'r', encoding='utf-8') as f:
                html_content = f.read()
            
            response = make_response(html_content)
            response.headers['Content-Type'] = 'text/html; charset=utf-8'
            return response
        else:
            return jsonify({"error": "APIæ–‡æ¡£æ–‡ä»¶ä¸å­˜åœ¨"}), 404
    except Exception as e:
        logger.error(f"åŠ è½½APIæ–‡æ¡£å¤±è´¥: {str(e)}")
        return jsonify({"error": f"åŠ è½½APIæ–‡æ¡£å¤±è´¥: {str(e)}"}), 500


if __name__ == '__main__':
    # æ˜¾ç¤ºæ¨¡å‹ä¿¡æ¯
    if model_client and model_client.is_auto_mode:
        model_info = f"AUTO (æ™ºèƒ½é€‰æ‹©)"
        models_list = ", ".join(model_client.clients.keys())
        model_detail = f"å·²é…ç½®: {models_list}"
    elif model_client:
        model_info = f"{MODEL_PROVIDER.upper()} - {model_client.model}"
        model_detail = "å›ºå®šæ¨¡å¼"
    else:
        model_info = "æœªé…ç½®"
        model_detail = ""
    
    print(f"""
    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
    â•‘       OCSæ™ºèƒ½ç­”é¢˜APIæœåŠ¡ - å¤šæ¨¡å‹æ”¯æŒç‰ˆæœ¬ v3.0              â•‘
    â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
    â•‘  ï¿½ Vue3 å‰ç«¯: http://{HOST}:{PORT}/                    
    â•‘  ğŸ“Š æ•°æ®å¯è§†åŒ–: http://{HOST}:{PORT}/viewer             
    â•‘  ğŸ“– APIæ–‡æ¡£: http://{HOST}:{PORT}/docs                  
    â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
    â•‘  æ¥å£åœ°å€: http://{HOST}:{PORT}/api/answer              
    â•‘  å¥åº·æ£€æŸ¥: http://{HOST}:{PORT}/api/health              
    â•‘  é…ç½®æŸ¥è¯¢: http://{HOST}:{PORT}/api/config              
    â•‘  CSVæ•°æ®: http://{HOST}:{PORT}/api/csv                  
    â•‘  å»¶è¿Ÿæµ‹è¯•: http://{HOST}:{PORT}/?t=æ—¶é—´æˆ³ (HEAD/GET)    
    â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
    â•‘  å½“å‰æ¨¡å¼: {model_info:<48s}â•‘
    â•‘  {'  ' + model_detail if model_detail else '':<60s}â•‘
    â•‘  æ€è€ƒæ¨¡å¼: {'âœ… å·²å¯ç”¨' if ENABLE_REASONING else 'âŒ æœªå¯ç”¨':<40s}â•‘
    â•‘  å¤šé€‰é¢˜æ€è€ƒ: {'âœ… è‡ªåŠ¨å¯ç”¨' if AUTO_REASONING_FOR_MULTIPLE else 'âŒ å…³é—­':<38s}â•‘
    â•‘  å›¾ç‰‡é¢˜æ€è€ƒ: {'âœ… è‡ªåŠ¨å¯ç”¨' if AUTO_REASONING_FOR_IMAGES else 'âŒ å…³é—­':<38s}â•‘
    â•‘  æ”¯æŒé¢˜å‹: å•é€‰ã€å¤šé€‰ã€åˆ¤æ–­ã€å¡«ç©º                        â•‘
    â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
    â•‘  ğŸ’¡ æ—§ç‰ˆHTML: http://{HOST}:{PORT}/config_legacy         
    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)
    
    if not model_client:
        print("\n" + "="*80)
        print("âŒ æ¨¡å‹å®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥")
        if init_error:
            print(f"é”™è¯¯ä¿¡æ¯: {init_error}")
        print("\nğŸ’¡ è§£å†³æ–¹æ¡ˆ:")
        if MODEL_PROVIDER == 'auto':
            print("   æ™ºèƒ½æ¨¡å¼éœ€è¦è‡³å°‘é…ç½®ä¸€ä¸ªæ¨¡å‹:")
            print("   1. åˆ›å»ºæˆ–ç¼–è¾‘ .env æ–‡ä»¶")
            print("   2. è®¾ç½® MODEL_PROVIDER=auto")
            print("   3. é…ç½®è‡³å°‘ä¸€ä¸ªæ¨¡å‹çš„APIå¯†é’¥:")
            print("      - DEEPSEEK_API_KEY=your_key (è·å–: https://platform.deepseek.com/api_keys)")
            print("      - DOUBAO_API_KEY=your_key + DOUBAO_MODEL=your_endpoint_id")
            print("        (è·å–: https://console.volcengine.com/ark)")
            print("   4. å»ºè®®é…ç½®ä¸¤ä¸ªæ¨¡å‹ä»¥è·å¾—æœ€ä½³æ•ˆæœ")
        elif MODEL_PROVIDER == 'deepseek':
            print("   1. åˆ›å»ºæˆ–ç¼–è¾‘ .env æ–‡ä»¶")
            print("   2. è®¾ç½® DEEPSEEK_API_KEY=your_api_key")
            print("   3. è·å–APIå¯†é’¥: https://platform.deepseek.com/api_keys")
        elif MODEL_PROVIDER == 'doubao':
            print("   1. åˆ›å»ºæˆ–ç¼–è¾‘ .env æ–‡ä»¶")
            print("   2. è®¾ç½® DOUBAO_API_KEY=your_api_key")
            print("   3. è®¾ç½® DOUBAO_MODEL=your_endpoint_id")
            print("   4. è·å–APIå¯†é’¥: https://console.volcengine.com/ark")
        print("="*80 + "\n")
    else:
        if model_client.is_auto_mode:
            print("âœ… æ™ºèƒ½æ¨¡å‹é€‰æ‹©å·²å¯ç”¨ï¼\n")
            print("ğŸ’¡ å·¥ä½œåŸç†:")
            print(f"   ğŸ“· æœ‰å›¾ç‰‡ â†’ è‡ªåŠ¨ä½¿ç”¨ {model_client.image_model}")
            print(f"   ğŸ“„ çº¯æ–‡æœ¬ â†’ è‡ªåŠ¨ä½¿ç”¨ {model_client.prefer_model} (æˆæœ¬æ›´ä½)")
            print(f"   ğŸ”§ å·²é…ç½®æ¨¡å‹: {', '.join(model_client.clients.keys())}\n")
        else:
            print("âœ… æœåŠ¡å¯åŠ¨æˆåŠŸï¼\n")
    
    # æ£€æŸ¥å‰ç«¯æ˜¯å¦å·²æ„å»º
    dist_dir = os.path.join(os.path.dirname(__file__), 'dist')
    if not os.path.exists(dist_dir):
        print("âš ï¸  è­¦å‘Š: å‰ç«¯åº”ç”¨æœªæ„å»º")
        print("   è®¿é—® Web ç•Œé¢éœ€è¦å…ˆæ„å»ºå‰ç«¯ï¼š")
        print("   æ‰§è¡Œ: build_frontend.bat")
        print("   æˆ–è®¿é—®æ—§ç‰ˆç•Œé¢: http://{}:{}/config_legacy\n".format(HOST, PORT))
    
    app.run(host=HOST, port=PORT, debug=DEBUG)


